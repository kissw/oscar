{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Activation, LeakyReLU, Dropout, BatchNormalization, MaxPooling2D, Lambda\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from progressbar import ProgressBar\n",
    "from image_process import ImageProcess\n",
    "import const, cv2\n",
    "from drive_data import DriveData\n",
    "from config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.setrecursionlimit(10**7)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% |##########################################################              |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-25-01.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Dataset\n",
    "\"\"\"\n",
    "image_process = ImageProcess()\n",
    "config = Config.neural_net\n",
    "# data_path = \"/mnt/exData/internal_simulation/test/2022-03-08-17-18-14/\"\n",
    "data_path = \"/home2/kdh/vae/2022-12-08-14-25-28\"\n",
    "if data_path[-1] == '/':\n",
    "    data_path = data_path[:-1]\n",
    "\n",
    "    loc_slash = data_path.rfind('/')\n",
    "    if loc_slash != -1: # there is '/' in the data path\n",
    "        model_name = data_path[loc_slash + 1:] # get folder name\n",
    "        #model_name = model_name.strip('/')\n",
    "    else:\n",
    "        model_name = data_path\n",
    "# csv_path = data_path + '/' + model_name + const.DATA_EXT \n",
    "csv_path = \"/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-25-01.csv\"\n",
    "\n",
    "# data = DriveData(csv_path)\n",
    "print(csv_path)\n",
    "# data_path = data_path\n",
    "# data.read()\n",
    "\n",
    "csv_header = ['image_fname', \n",
    "                'steering_angle', 'throttle', 'brake', \n",
    "                'linux_time', \n",
    "                'vel', 'vel_x', 'vel_y', 'vel_z',\n",
    "                'pos_x', 'pos_y', 'pos_z', 'tar_image_fname', 'tar_steering_angle', 'tar_vel', 'tar_time',\n",
    "                't1_image_fname', 't1_steering_angle', 't1_vel', 't1_time']\n",
    "\n",
    "df = pd.read_csv(csv_path, names=csv_header, index_col=False)\n",
    "num_data = len(df)\n",
    "\n",
    "bar = ProgressBar()\n",
    "df_image_names = []\n",
    "df_measurements = []\n",
    "df_time_stamps= []\n",
    "df_velocities= []\n",
    "df_velocities_xyz= []\n",
    "df_positions_xyz= []\n",
    "df_tar_image_names= []\n",
    "df_tar_steering_angle= []\n",
    "df_tar_vel= []\n",
    "df_tar_time= []\n",
    "df_t1_image_names= []\n",
    "df_t1_steering_angle= []\n",
    "df_t1_vel= []\n",
    "df_t1_time= []\n",
    "for i in bar(range(num_data)): # we don't have a title\n",
    "    df_image_names.append(df.loc[i]['image_fname'])\n",
    "    # if Config.data_collection['brake'] is True:\n",
    "    df_measurements.append((float(df.loc[i]['steering_angle']),\n",
    "                            float(df.loc[i]['throttle']), \n",
    "                            float(df.loc[i]['brake'])))\n",
    "    df_time_stamps.append(float(df.loc[i]['linux_time']))\n",
    "    df_velocities.append(float(df.loc[i]['vel']))\n",
    "    df_velocities_xyz.append((float(df.loc[i]['vel_x']), \n",
    "                                float(df.loc[i]['vel_y']), \n",
    "                                float(df.loc[i]['vel_z'])))\n",
    "    df_positions_xyz.append((float(df.loc[i]['pos_x']), \n",
    "                                float(df.loc[i]['pos_y']), \n",
    "                                float(df.loc[i]['pos_z'])))\n",
    "    df_tar_image_names.append(df.loc[i]['tar_image_fname'])\n",
    "    df_tar_steering_angle.append(float(df.loc[i]['tar_steering_angle']))\n",
    "    df_tar_vel.append(float(df.loc[i]['tar_vel']))\n",
    "    df_tar_time.append(float(df.loc[i]['tar_time']))\n",
    "    df_t1_image_names.append(df.loc[i]['t1_image_fname'])\n",
    "    df_t1_steering_angle.append(float(df.loc[i]['t1_steering_angle']))\n",
    "    df_t1_vel.append(float(df.loc[i]['t1_vel']))\n",
    "    df_t1_time.append(float(df.loc[i]['t1_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(zip( df_image_names, df_velocities, df_measurements, \n",
    "                    df_tar_image_names, df_tar_steering_angle, df_tar_vel, df_tar_time,\n",
    "                    df_t1_image_names, df_t1_steering_angle, df_t1_vel, df_t1_time\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpu_config = tf.compat.v1.ConfigProto()\n",
    "gpu_config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=gpu_config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7862898906035393474\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23122477056\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15593660721392362369\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "sys.setrecursionlimit(10**7)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vae_batch_samples(batch_samples):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    vels = []\n",
    "    tar_images = []\n",
    "    tar_steering_angles = []\n",
    "    tar_vels = []\n",
    "    tar_times = []\n",
    "    t1_images = []\n",
    "    t1_steering_angles = []\n",
    "    t1_vels = []\n",
    "    t1_times = []\n",
    "        \n",
    "    for image_name, velocity, measurement, tar_image_name, tar_steering_angle, tar_vel, tar_time, t1_iname, t1_str, t1_vel, t1_t in batch_samples:\n",
    "        # self.data.image_names, self.data.velocities, self.data.measurements, \n",
    "        # self.data.tar_image_names, self.data.tar_steering_angle, self.data.tar_vel, self.data.tar_time\n",
    "        \n",
    "        image_path = data_path + '/' + image_name\n",
    "        # print(data_path, tar_image_name)\n",
    "        tar_image_path = data_path + '/' + tar_image_name\n",
    "        t1_image_path = data_path + '/' + t1_iname\n",
    "        image = cv2.imread(image_path)\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "        t1_image = cv2.imread(t1_image_path)\n",
    "\n",
    "        # if collected data is not cropped then crop here\n",
    "        # otherwise do not crop.\n",
    "        if Config.data_collection['crop'] is not True:\n",
    "            image = image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "            tar_image = tar_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "            t1_image = t1_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        image = cv2.resize(image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        tar_image = cv2.resize(tar_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        t1_image = cv2.resize(t1_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        image = image_process.process(image)\n",
    "        tar_image = image_process.process(tar_image)\n",
    "        t1_image = image_process.process(t1_image)\n",
    "\n",
    "        vels.append(velocity)\n",
    "        tar_vels.append(tar_vel)\n",
    "        tar_times.append(tar_time)\n",
    "        tar_steering_angles.append(tar_steering_angle)\n",
    "        t1_vels.append(t1_vel)\n",
    "        t1_times.append(t1_t)\n",
    "        t1_steering_angles.append(t1_str)\n",
    "        # if no brake data in collected data, brake values are dummy\n",
    "        steering_angle, throttle, brake = measurement\n",
    "        steering_angles.append(steering_angle)\n",
    "        images.append(image)\n",
    "        tar_images.append(tar_image)\n",
    "        t1_images.append(t1_image)\n",
    "\n",
    "\n",
    "    return images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times, t1_images, t1_steering_angles, t1_vels, t1_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Encoder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "## Encoder main\n",
    "encoder_inputs_img = tf.keras.Input(shape=(160, 160, 3))\n",
    "encoder_inputs_str = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_vel = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_time = tf.keras.Input(shape=(1))\n",
    "x = layers.Conv2D(24, (5, 5), padding='same', name='conv2d_1')(encoder_inputs_img)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_1')(x)\n",
    "\n",
    "x = layers.Conv2D(36, (5, 5), padding='same', name='conv2d_2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_2')(x)\n",
    "\n",
    "x = layers.Conv2D(48, (5, 5), padding='same', name='conv2d_3')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_5')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "latent = layers.Flatten()(x)\n",
    "fc_s1  = layers.Dense(100)(encoder_inputs_str)\n",
    "fc_s1  = layers.Activation('elu')(fc_s1)\n",
    "fc_s2  = layers.Dense(50)(fc_s1)\n",
    "fc_s2  = layers.Activation('elu')(fc_s2)\n",
    "fc_v1  = layers.Dense(100)(encoder_inputs_vel)\n",
    "fc_v1  = layers.Activation('elu')(fc_v1)\n",
    "fc_v2  = layers.Dense(50)(fc_v1)\n",
    "fc_v2  = layers.Activation('elu')(fc_v2)\n",
    "fc_t1  = layers.Dense(100)(encoder_inputs_time)\n",
    "fc_t1  = layers.Activation('elu')(fc_t1)\n",
    "fc_t2  = layers.Dense(50)(fc_t1)\n",
    "fc_t2  = layers.Activation('elu')(fc_t2)\n",
    "conc_1 = layers.concatenate([latent, fc_s2, fc_v2, fc_t2])\n",
    "fc_1   = layers.Dense(100)(conc_1)\n",
    "x   = layers.Activation('elu')(fc_1)\n",
    "\n",
    "z_mean = layers.Dense(50, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(50, name=\"z_log_var\")(x)\n",
    "encoder_output = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "## Encoder 2\n",
    "encoder_inputs_img2 = tf.keras.Input(shape=(160, 160, 3))\n",
    "encoder_inputs_str2 = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_vel2 = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_time2 = tf.keras.Input(shape=(1))\n",
    "x2 = layers.Conv2D(24, (5, 5), padding='same', name='conv2d_12')(encoder_inputs_img2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('elu')(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_12')(x2)\n",
    "\n",
    "x2 = layers.Conv2D(36, (5, 5), padding='same', name='conv2d_22')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('elu')(x2)\n",
    "x2 = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_22')(x2)\n",
    "\n",
    "x2 = layers.Conv2D(48, (5, 5), padding='same', name='conv2d_32')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('elu')(x2)\n",
    "\n",
    "x2 = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_42')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('elu')(x2)\n",
    "\n",
    "x2 = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_52')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Activation('elu')(x2)\n",
    "latent2 = layers.Flatten()(x2)\n",
    "\n",
    "fc_s12  = layers.Dense(100)(encoder_inputs_str2)\n",
    "fc_s12  = layers.Activation('elu')(fc_s12)\n",
    "fc_s22  = layers.Dense(50)(fc_s12)\n",
    "fc_s22  = layers.Activation('elu')(fc_s22)\n",
    "\n",
    "fc_v12  = layers.Dense(100)(encoder_inputs_vel2)\n",
    "fc_v12  = layers.Activation('elu')(fc_v12)\n",
    "fc_v22  = layers.Dense(50)(fc_v12)\n",
    "fc_v22  = layers.Activation('elu')(fc_v22)\n",
    "\n",
    "fc_t12  = layers.Dense(100)(encoder_inputs_time2)\n",
    "fc_t12  = layers.Activation('elu')(fc_t12)\n",
    "fc_t22  = layers.Dense(50)(fc_t12)\n",
    "fc_t22  = layers.Activation('elu')(fc_t22)\n",
    "\n",
    "conc_12 = layers.concatenate([latent2, fc_s22, fc_v22, fc_t22])\n",
    "fc_12   = layers.Dense(100)(conc_12)\n",
    "x2   = layers.Activation('elu')(fc_12)\n",
    "\n",
    "z_mean2 = layers.Dense(50, name=\"z_mean2\")(x2)\n",
    "z_log_var2 = layers.Dense(50, name=\"z_log_var2\")(x2)\n",
    "encoder_output2 = Sampling()([z_mean2, z_log_var2])\n",
    "\n",
    "\n",
    "encoder = tf.keras.Model([ encoder_inputs_img, encoder_inputs_str,\n",
    "                        encoder_inputs_vel, encoder_inputs_time,\n",
    "                        encoder_inputs_img2, encoder_inputs_str2,\n",
    "                        encoder_inputs_vel2, encoder_inputs_time2\n",
    "                        ], \n",
    "                        [z_mean, z_log_var, encoder_output,\n",
    "                        z_mean2, z_log_var2, encoder_output2\n",
    "                        ], \n",
    "                        name=\"encoder\")\n",
    "\n",
    "# encoder2 = tf.keras.Model([ encoder_inputs_img2, encoder_inputs_str2,\n",
    "#                         encoder_inputs_vel2, encoder_inputs_time2], \n",
    "#                         [z_mean2, z_log_var2, encoder_output2], \n",
    "#                         name=\"encoder2\")\n",
    "\n",
    "# encoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 102400)       5222400     input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 102400)       5222400     input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 40, 40, 64)   0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 40, 40, 64)   0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 40, 40, 64)   36928       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DTran (None, 40, 40, 64)   36928       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DTran (None, 80, 80, 36)   20772       conv2d_transpose_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 80, 80, 36)   20772       conv2d_transpose_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_26 (Conv2DTran (None, 160, 160, 24) 7800        conv2d_transpose_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 160, 160, 24) 7800        conv2d_transpose_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DTran (None, 160, 160, 3)  651         conv2d_transpose_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 160, 160, 3)  651         conv2d_transpose_30[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 10,577,102\n",
      "Trainable params: 10,577,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Decoder\n",
    "\"\"\"\n",
    "\n",
    "latent_inputs = tf.keras.Input(shape=(50,))\n",
    "# x = layers.Dense(100, activation=\"elu\")(latent_inputs)\n",
    "x = layers.Dense(40 * 40 * 64, activation=\"elu\")(latent_inputs)\n",
    "x = layers.Reshape((40, 40, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"elu\",  padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(48, 3, activation=\"elu\",  padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(36, 3, activation=\"elu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(24, 3, activation=\"elu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "\"\"\"\n",
    "## Decoder\n",
    "\"\"\"\n",
    "\n",
    "latent_inputs2 = tf.keras.Input(shape=(50,))\n",
    "# x = layers.Dense(100, activation=\"elu\")(latent_inputs)\n",
    "x2 = layers.Dense(40 * 40 * 64, activation=\"elu\")(latent_inputs2)\n",
    "x2 = layers.Reshape((40, 40, 64))(x2)\n",
    "x2 = layers.Conv2DTranspose(64, 3, activation=\"elu\",  padding=\"same\")(x2)\n",
    "# x = layers.Conv2DTranspose(48, 3, activation=\"elu\",  padding=\"same\")(x)\n",
    "x2 = layers.Conv2DTranspose(36, 3, activation=\"elu\", strides=2, padding=\"same\")(x2)\n",
    "x2 = layers.Conv2DTranspose(24, 3, activation=\"elu\", strides=2, padding=\"same\")(x2)\n",
    "decoder_outputs2 = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x2)\n",
    "\n",
    "\n",
    "decoder = tf.keras.Model([latent_inputs, latent_inputs2], [decoder_outputs, decoder_outputs2], name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 160, 160, 24) 1824        input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 160, 160, 24) 1824        input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 160, 160, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 160, 160, 24) 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 160, 160, 24) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 160, 160, 24) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_1 (MaxPooling2D)         (None, 80, 80, 24)   0           activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_12 (MaxPooling2D)        (None, 80, 80, 24)   0           activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 80, 80, 36)   21636       pool2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 80, 80, 36)   21636       pool2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 80, 80, 36)   144         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 80, 80, 36)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 80, 80, 36)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 80, 80, 36)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_2 (MaxPooling2D)         (None, 40, 40, 36)   0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_22 (MaxPooling2D)        (None, 40, 40, 36)   0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 40, 40, 48)   43248       pool2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 40, 40, 48)   43248       pool2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 40, 40, 48)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 40, 40, 48)   192         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 40, 40, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 40, 40, 48)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 40, 64)   27712       activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 40, 40, 64)   27712       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 40, 40, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 40, 40, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 40, 40, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_49 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 40, 40, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 40, 64)   36928       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 100)          200         input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 100)          200         input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 100)          200         input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 40, 40, 64)   36928       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 100)          200         input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 100)          200         input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 100)          200         input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 40, 40, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 100)          0           dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 100)          0           dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 100)          0           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 40, 40, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 100)          0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 100)          0           dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 100)          0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 40, 40, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 50)           5050        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 50)           5050        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 50)           5050        activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 40, 40, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 50)           5050        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 50)           5050        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 50)           5050        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 102400)       0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 50)           0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 50)           0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 50)           0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 102400)       0           activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 50)           0           dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 50)           0           dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 50)           0           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 102550)       0           flatten_10[0][0]                 \n",
      "                                                                 activation_130[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 102550)       0           flatten_11[0][0]                 \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "                                                                 activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 100)          10255100    concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 100)          10255100    concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 100)          0           dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 100)          0           dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 50)           5050        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 50)           5050        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z_mean2 (Dense)                 (None, 50)           5050        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var2 (Dense)              (None, 50)           5050        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sampling_14 (Sampling)          (None, 50)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sampling_15 (Sampling)          (None, 50)           0           z_mean2[0][0]                    \n",
      "                                                                 z_log_var2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            [(None, 160, 160, 3) 10577102    sampling_14[0][0]                \n",
      "                                                                 sampling_15[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 31,403,586\n",
      "Trainable params: 31,402,642\n",
      "Non-trainable params: 944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## VAE\n",
    "\"\"\"\n",
    "model_input = [ encoder_inputs_img, encoder_inputs_str,\n",
    "                encoder_inputs_vel, encoder_inputs_time,\n",
    "                encoder_inputs_img2, encoder_inputs_str2,\n",
    "                encoder_inputs_vel2, encoder_inputs_time2,\n",
    "                ]\n",
    "model_output = decoder([encoder_output, encoder_output2])\n",
    "\n",
    "# model_input2 = [ encoder_inputs_img2, encoder_inputs_str2,\n",
    "#                         encoder_inputs_vel2, encoder_inputs_time2]\n",
    "# model_output2 = decoder2(encoder_output2)\n",
    "\n",
    "VarAE=Model(model_input, model_output)\n",
    "# VarAE2=Model(model_input2, model_output2)\n",
    "# VarAE.run_eagerly = True\n",
    "VarAE.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data generator\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _generator(samples, batch_size=config['batch_size']):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, (num_samples//batch_size)*batch_size, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times, t1_images, t1_steering_angles, t1_vels, t1_times = prepare_vae_batch_samples(batch_samples)\n",
    "\n",
    "            X_img = np.array(images).astype(\"float32\")/255.0\n",
    "            X_tvel = np.array(tar_vels).astype(\"float32\")\n",
    "            X_tstr = np.array(tar_steering_angles).astype(\"float32\")\n",
    "            X_ttime = np.array(tar_times).astype(\"float32\")\n",
    "\n",
    "            X_img_t1 = np.array(t1_images).astype(\"float32\")/255.0\n",
    "            X_tvel_t1 = np.array(t1_vels).astype(\"float32\")\n",
    "            X_tstr_t1 = np.array(t1_steering_angles).astype(\"float32\")\n",
    "            X_ttime_t1 = np.array(t1_times).astype(\"float32\")\n",
    "\n",
    "            y_train1 = np.array(tar_images).astype(\"float32\")/255.0\n",
    "            y_train2 = np.array(tar_images).astype(\"float32\")/255.0\n",
    "            # if config['num_outputs'] == 1:\n",
    "            # y_train = np.array(segimg)\n",
    "            # print(y_train.max())\n",
    "            # y_train = np.repeat(y_train[..., np.newaxis], 1, -1)/y_train.max()\n",
    "            X_train = [X_img, X_tstr, X_tvel, X_ttime, X_img_t1, X_tstr_t1, X_tvel_t1, X_ttime_t1]\n",
    "            y_train = [y_train1, y_train2]\n",
    "\n",
    "            # print(X_tstr, X_tvel, X_ttime)\n",
    "            # print(y_train)\n",
    "            # print(np.array(y_train).shape)\n",
    "            yield X_train, y_train\n",
    "\n",
    "train_data, valid_data = train_test_split(samples, test_size=config['validation_rate'])\n",
    "\n",
    "train_generator = _generator(train_data, config['batch_size'])\n",
    "valid_generator = _generator(valid_data, config['batch_size'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 160, 160, 3)\n",
      "(None, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VAE loss\n",
    "\"\"\"\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005, decay=0.0000001)\n",
    "# optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005, decay=0.00000001)\n",
    "#                                  learning_rate=0.000005,decay=0.0000000001\n",
    "r_loss_factor=160*160*100   # This is a Hyperparameter\n",
    "e_loss_factor=10000\n",
    "def vae_r_loss(y_true, y_pred):    ## MSE\n",
    "    r_loss = tf.keras.backend.mean(tf.keras.backend.square(y_true-y_pred), axis=[1,2,3])\n",
    "    return r_loss_factor * r_loss\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):   ## KL-Divergence\n",
    "    kl_loss=( -0.5 * tf.keras.backend.sum(1+z_log_var \n",
    "                - tf.keras.backend.square(z_mean) \n",
    "                - tf.keras.backend.exp(z_log_var), axis=1)\n",
    "    )\n",
    "    return kl_loss\n",
    "def vae_eachother_mse_loss(y_true, y_pred):\n",
    "    # print(y_pred.shape)\n",
    "    e_mse_loss = tf.keras.backend.mean(tf.keras.backend.square(y_pred-y_pred), axis=[1,2,3])\n",
    "    return e_mse_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred): \n",
    "    r_loss=vae_r_loss(y_true, y_pred) #Loss of Decoder\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred) #Loss of Encoder\n",
    "    e_loss=vae_eachother_mse_loss(y_true, y_pred)\n",
    "    return (r_loss + kl_loss) #* e_loss * e_loss_factor\n",
    "\n",
    "\n",
    "VarAE.compile(optimizer=optimizer,\n",
    "                loss= vae_loss, \n",
    "                metrics=[vae_r_loss, vae_kl_loss])\n",
    "                # metrics=[vae_r_loss, vae_kl_loss, vae_eachother_mse_loss])\n",
    "# VarAE.summary()\n",
    "#  vae_r_loss: 12.6586 - vae_kl_loss: 2251744.5000 \n",
    "#  val_loss: 50649853.6174 \n",
    "#  val_vae_r_loss: 28.6742 - val_vae_kl_loss: 50649896.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "Epoch 1/100000\n",
      "2/2 [==============================] - ETA: 0s - batch: 0.5000 - size: 32.0000 - loss: 439947.9062 - decoder_loss: 222924.4688 - decoder_1_loss: 217023.4375 - decoder_vae_r_loss: 222505.2188 - decoder_vae_kl_loss: 419.2639 - decoder_1_vae_r_loss: 216604.1875 - decoder_1_vae_kl_loss: 419.2639    WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-25e3a2c11ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                         )\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vae/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Train the VAE\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "        # checkpoint\n",
    "callbacks = []\n",
    "#weight_filename = self.data_path + '_' + Config.config_yaml_name \\\n",
    "#    + '_N' + str(config['network_type']) + '_ckpt'\n",
    "model_ckpt_name = \"vae_kdh_loss\"\n",
    "checkpoint = ModelCheckpoint(model_ckpt_name +'_ckpt.{epoch:02d}-{val_loss:.3f}.h5',\n",
    "                                monitor='val_loss', \n",
    "                                verbose=1, save_best_only=True, mode='min')\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "# early stopping\n",
    "patience = 1000\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, \n",
    "                            verbose=1, mode='min')\n",
    "# callbacks.append(earlystop)\n",
    "\n",
    "validation_steps = len(valid_data)//2\n",
    "print(validation_steps)\n",
    "train_hist = VarAE.fit( train_generator,  \n",
    "                        steps_per_epoch=len(train_data)//config['batch_size'], \n",
    "                        epochs=100000, \n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=len(valid_data)//2,\n",
    "                        # shuffle=True,\n",
    "                        verbose=1, \n",
    "                        callbacks=callbacks, \n",
    "                        use_multiprocessing=True,\n",
    "                        workers=48\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def plot_latent_space(trained_decoder, pimage, n=50, figsize=15):\n",
    "\n",
    "\n",
    "    image = pimage[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "    image = cv2.resize(image, \n",
    "                        (config['input_image_width'],\n",
    "                        config['input_image_height']))\n",
    "    image = np.array(image).astype(\"float32\")/255.0\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # vel = np.array()\n",
    "\n",
    "\n",
    "    X_tvel = np.array([14.5])\n",
    "    X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "    X_tstr = np.array([0.3])\n",
    "    X_tvel = np.expand_dims(X_tstr, axis=0)\n",
    "    X_ttime = np.array([0.1])\n",
    "    X_tvel = np.expand_dims(X_ttime, axis=0)\n",
    "    # print(X_tvel.shape)\n",
    "    X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "    x_encoded = VarAE.predict(X_train)*255.0\n",
    "    # print(x_encoded)\n",
    "    x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "    # pred_image = np.zeros([160,160,3], np.uint8)\n",
    "    pred_image = array_to_img(x_encoded_out)\n",
    "    pred_image = np.array(pred_image)\n",
    "    pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "    # pred_img = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "    # print(type(pred_img))\n",
    "    # print(pred_image.shape)\n",
    "    plt.imshow(pred_image)\n",
    "    # plt.imshow(cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    origin_image_name = '/home2/kdh/vae/vae_test/2022-12-08-14-30-12-332957.jpg'\n",
    "    cv2.imwrite('/')\n",
    "    # plt.xticks(pixel_range, sample_range_x)\n",
    "    # plt.yticks(pixel_range, sample_range_y)\n",
    "    # plt.xlabel(\"z[0]\")\n",
    "    # plt.ylabel(\"z[1]\")\n",
    "\n",
    "# test_img = cv2.imread('/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-30-12-332957.jpg')\n",
    "# plot_latent_space(decoder, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def save_latent_space(trained_decoder, valid_data, n=50, figsize=15):\n",
    "        \n",
    "    for image_name, velocity, measurement, tar_image_name, tar_steering_angle, tar_vel, tar_time in valid_data:\n",
    "        # self.data.image_names, self.data.velocities, self.data.measurements, \n",
    "        # self.data.tar_image_names, self.data.tar_steering_angle, self.data.tar_vel, self.data.tar_time\n",
    "        \n",
    "        image_path = data_path + '/' + image_name\n",
    "        # print(data_path, tar_image_name)\n",
    "        tar_image_path = data_path + '/' + tar_image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "\n",
    "        # if collected data is not cropped then crop here\n",
    "        # otherwise do not crop.\n",
    "        image = image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                    Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        image = cv2.resize(image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        tar_image = tar_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                    Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        tar_image = cv2.resize(tar_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "\n",
    "        cv2.imwrite('/home2/kdh/vae/vae_test/'+image_name, image)\n",
    "        image = np.array(image).astype(\"float32\")/255.0\n",
    "        # image = image_process.process(image)\n",
    "        steering_angle, throttle, brake = measurement\n",
    "        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        X_tvel = np.array([velocity])\n",
    "        X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "        X_tstr = np.array([steering_angle])\n",
    "        X_tstr = np.expand_dims(X_tstr, axis=0)\n",
    "        X_ttime = np.array([tar_time])\n",
    "        X_ttime = np.expand_dims(X_ttime, axis=0)\n",
    "        \n",
    "        X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "        x_encoded = VarAE.predict(X_train)*255.0\n",
    "        x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "        pred_image = array_to_img(x_encoded_out)\n",
    "        pred_image = np.array(pred_image)\n",
    "        # pred_image = cv2.cvtColor(pred_image)\n",
    "        # plt.imshow(pred_image)\n",
    "        # plt.show()\n",
    "\n",
    "        # image_name = '/home2/kdh/vae/vae_test/'+image_name\n",
    "        pred_image_name = '/home2/kdh/vae/vae_test/'+image_name[:-4]+'_'+str(int(steering_angle*1000))+'_'+str(int(velocity))+'_'+str(tar_time)[:4]+'.jpg'\n",
    "        gt_tar_image_name = '/home2/kdh/vae/vae_test/'+image_name[:-4]+'_'+str(int(steering_angle*1000))+'_'+str(int(velocity))+'_'+str(tar_time)[:4]+'_gt.jpg'\n",
    "        cv2.imwrite(pred_image_name, pred_image)\n",
    "        cv2.imwrite(gt_tar_image_name, tar_image)\n",
    "\n",
    "        # print(pred_image_name,' done')\n",
    "        # cv2.imwrite('/')\n",
    "\n",
    "\n",
    "# save_latent_space(decoder, valid_data[3423:4422])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def save_latent_space_diff_steer(trained_decoder, pimage, save_image_name, n=50, figsize=15):\n",
    "\n",
    "\n",
    "    image = pimage[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "    image = cv2.resize(image, \n",
    "                        (config['input_image_width'],\n",
    "                        config['input_image_height']))\n",
    "    cv2.imwrite('/home2/kdh/vae/vae_diff_steer_test/'+save_image_name+'.jpg', image)\n",
    "    image = np.array(image).astype(\"float32\")/255.0\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.show()\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # vel = np.array()\n",
    "\n",
    "\n",
    "    X_tvel = np.array([14.85])\n",
    "    X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "    X_ttime = np.array([0.8])\n",
    "    X_ttime = np.expand_dims(X_ttime, axis=0)\n",
    "    # print(X_tvel.shape)\n",
    "    for s in np.arange(0, 0.8, 0.0125):\n",
    "        X_tstr = np.array([s-0.4])\n",
    "        X_tstr = np.expand_dims(X_tstr, axis=0)\n",
    "        X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "        x_encoded = VarAE.predict(X_train)*255.0\n",
    "        x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "        pred_image = array_to_img(x_encoded_out)\n",
    "        pred_image = np.array(pred_image)\n",
    "        # pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "        s_str = \"{:.3f}\".format(s)\n",
    "        pred_image_name = ('/home2/kdh/vae/vae_diff_steer_test/'\n",
    "                            +save_image_name\n",
    "                            +'_'+str(s_str)\n",
    "                            +'.jpg'\n",
    "        )\n",
    "        cv2.imwrite(pred_image_name, pred_image)\n",
    "    \n",
    "        \n",
    "\n",
    "# test_img = cv2.imread('/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-35-43-708754.jpg')\n",
    "# save_latent_space_diff_steer(decoder, test_img, '2022-12-08-14-35-43-708754')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06e874fbf5df5387c03d37e60b157d9aec9842d39ece54c5a1a7aaa8e8f1e8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
