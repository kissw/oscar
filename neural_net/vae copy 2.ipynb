{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "               Configuration Settings\n",
      "=======================================================\n",
      "Neural Net:     \tfusion_kdh_jaerock3\n",
      "Data Collection:\tfusion_kdh_jaerock3\n",
      "Run Neural:     \tfusion_kdh_jaerock3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Activation, LeakyReLU, Dropout, BatchNormalization, MaxPooling2D, Lambda\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from progressbar import ProgressBar\n",
    "from image_process import ImageProcess\n",
    "import const, cv2\n",
    "from drive_data import DriveData\n",
    "from config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.setrecursionlimit(10**7)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-25-28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Dataset\n",
    "\"\"\"\n",
    "image_process = ImageProcess()\n",
    "config = Config.neural_net\n",
    "# data_path = \"/mnt/exData/internal_simulation/test/2022-03-08-17-18-14/\"\n",
    "data_path = \"/home2/kdh/vae/2022-12-08-14-25-28/\"\n",
    "if data_path[-1] == '/':\n",
    "    data_path = data_path[:-1]\n",
    "\n",
    "    loc_slash = data_path.rfind('/')\n",
    "    if loc_slash != -1: # there is '/' in the data path\n",
    "        model_name = data_path[loc_slash + 1:] # get folder name\n",
    "        #model_name = model_name.strip('/')\n",
    "    else:\n",
    "        model_name = data_path\n",
    "csv_path = data_path + '/' + model_name + const.DATA_EXT \n",
    "# data = DriveData(csv_path)\n",
    "print(csv_path)\n",
    "# data_path = data_path\n",
    "# data.read()\n",
    "\n",
    "csv_header = ['image_fname', \n",
    "                  'steering_angle', 'throttle', 'brake', 'linux_time', \n",
    "                  'vel', 'vel_x', 'vel_y', 'vel_z', \n",
    "                  'pos_x', 'pos_y', 'pos_z', \n",
    "                  'tar_image_fname', 'tar_steering_angle', 'tar_vel', 'tar_time']\n",
    "\n",
    "df = pd.read_csv(csv_path, names=csv_header, index_col=False)\n",
    "num_data = len(df)\n",
    "\n",
    "bar = ProgressBar()\n",
    "df_image_names = []\n",
    "df_measurements = []\n",
    "df_time_stamps= []\n",
    "df_velocities= []\n",
    "df_velocities_xyz= []\n",
    "df_positions_xyz= []\n",
    "df_tar_image_names= []\n",
    "df_tar_steering_angle= []\n",
    "df_tar_vel= []\n",
    "df_tar_time= []\n",
    "for i in bar(range(num_data)): # we don't have a title\n",
    "    df_image_names.append(df.loc[i]['image_fname'])\n",
    "    # if Config.data_collection['brake'] is True:\n",
    "    df_measurements.append((float(df.loc[i]['steering_angle']),\n",
    "                            float(df.loc[i]['throttle']), \n",
    "                            float(df.loc[i]['brake'])))\n",
    "    df_time_stamps.append(float(df.loc[i]['linux_time']))\n",
    "    df_velocities.append(float(df.loc[i]['vel']))\n",
    "    df_velocities_xyz.append((float(df.loc[i]['vel_x']), \n",
    "                                float(df.loc[i]['vel_y']), \n",
    "                                float(df.loc[i]['vel_z'])))\n",
    "    df_positions_xyz.append((float(df.loc[i]['pos_x']), \n",
    "                                float(df.loc[i]['pos_y']), \n",
    "                                float(df.loc[i]['pos_z'])))\n",
    "    df_tar_image_names.append(df.loc[i]['tar_image_fname'])\n",
    "    df_tar_steering_angle.append(float(df.loc[i]['tar_steering_angle']))\n",
    "    df_tar_vel.append(float(df.loc[i]['tar_vel']))\n",
    "    df_tar_time.append(float(df.loc[i]['tar_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(zip( df_image_names, df_velocities, df_measurements, \n",
    "                    df_tar_image_names, df_tar_steering_angle, df_tar_vel, df_tar_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vae_batch_samples(batch_samples):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    vels = []\n",
    "    tar_images = []\n",
    "    tar_steering_angles = []\n",
    "    tar_vels = []\n",
    "    tar_times = []\n",
    "        \n",
    "    for image_name, velocity, measurement, tar_image_name, tar_steering_angle, tar_vel, tar_time in batch_samples:\n",
    "        # self.data.image_names, self.data.velocities, self.data.measurements, \n",
    "        # self.data.tar_image_names, self.data.tar_steering_angle, self.data.tar_vel, self.data.tar_time\n",
    "        \n",
    "        image_path = data_path + '/' + image_name\n",
    "        # print(data_path, tar_image_name)\n",
    "        tar_image_path = data_path + '/' + tar_image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "\n",
    "        # if collected data is not cropped then crop here\n",
    "        # otherwise do not crop.\n",
    "        if Config.data_collection['crop'] is not True:\n",
    "            image = image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "            tar_image = tar_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        image = cv2.resize(image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        tar_image = cv2.resize(tar_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        image = image_process.process(image)\n",
    "        tar_image = image_process.process(tar_image)\n",
    "\n",
    "        vels.append(tar_vels)\n",
    "        tar_vels.append(tar_vel)\n",
    "        tar_times.append(tar_time)\n",
    "        tar_steering_angles.append(tar_steering_angle)\n",
    "        # if no brake data in collected data, brake values are dummy\n",
    "        steering_angle, throttle, brake = measurement\n",
    "        steering_angles.append(steering_angle)\n",
    "        # cv2.imwrite('/home2/kdh/vae/oscar/test/image/'+image_name, image)\n",
    "        # cv2.imwrite('/home2/kdh/vae/oscar/test/tar_image/'+tar_image_name, tar_image)\n",
    "        # if data == 'train':\n",
    "        #     cv2.imwrite('/mnt/Data/oscar/train_data/'+image_name, image)\n",
    "        # print(image.shape)\n",
    "        images.append(image)\n",
    "        tar_images.append(tar_image)\n",
    "        # segimgs.append(segimg)\n",
    "\n",
    "\n",
    "    return images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home2/kdh/anaconda3/envs/vae/lib/python3.6/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 160, 160, 24) 1824        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 160, 160, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 160, 160, 24) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_1 (MaxPooling2D)         (None, 80, 80, 24)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 80, 80, 36)   21636       pool2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 80, 36)   144         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 80, 80, 36)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pool2d_2 (MaxPooling2D)         (None, 40, 40, 36)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 40, 40, 48)   43248       pool2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 40, 40, 48)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 40, 40, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 40, 64)   27712       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 40, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 40, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          200         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          200         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 40, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 40, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           5050        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           5050        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 102400)       0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 50)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 102550)       0           flatten[0][0]                    \n",
      "                                                                 activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100)          10255100    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 50)           5050        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 50)           5050        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 50)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,413,242\n",
      "Trainable params: 10,412,770\n",
      "Non-trainable params: 472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Encoder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "encoder_inputs_img = tf.keras.Input(shape=(160, 160, 3))\n",
    "encoder_inputs_str = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_vel = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_time = tf.keras.Input(shape=(1))\n",
    "x = layers.Conv2D(24, (5, 5), padding='same', name='conv2d_1')(encoder_inputs_img)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_1')(x)\n",
    "\n",
    "x = layers.Conv2D(36, (5, 5), padding='same', name='conv2d_2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_2')(x)\n",
    "\n",
    "x = layers.Conv2D(48, (5, 5), padding='same', name='conv2d_3')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_5')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "latent = layers.Flatten()(x)\n",
    "fc_s1  = layers.Dense(100)(encoder_inputs_str)\n",
    "fc_s1  = layers.Activation('elu')(fc_s1)\n",
    "fc_s2  = layers.Dense(50)(fc_s1)\n",
    "fc_s2  = layers.Activation('elu')(fc_s2)\n",
    "fc_v1  = layers.Dense(100)(encoder_inputs_vel)\n",
    "fc_v1  = layers.Activation('elu')(fc_v1)\n",
    "fc_v2  = layers.Dense(50)(fc_v1)\n",
    "fc_v2  = layers.Activation('elu')(fc_v2)\n",
    "fc_t1  = layers.Dense(100)(encoder_inputs_time)\n",
    "fc_t1  = layers.Activation('elu')(fc_t1)\n",
    "fc_t2  = layers.Dense(50)(fc_t1)\n",
    "fc_t2  = layers.Activation('elu')(fc_t2)\n",
    "conc_1 = layers.concatenate([latent, fc_s2, fc_v2, fc_t2])\n",
    "fc_1   = layers.Dense(100)(conc_1)\n",
    "x   = layers.Activation('elu')(fc_1)\n",
    "\n",
    "z_mean = layers.Dense(100, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(100, name=\"z_log_var\")(x)\n",
    "encoder_output = Sampling()([z_mean, z_log_var])\n",
    "encoder = tf.keras.Model([ encoder_inputs_img, encoder_inputs_str,\n",
    "                        encoder_inputs_vel, encoder_inputs_time], \n",
    "                        [z_mean, z_log_var, encoder_output], \n",
    "                        name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 102400)            10342400  \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 40, 40, 48)        27696     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 80, 80, 36)        15588     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 160, 160, 24)      7800      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 160, 160, 3)       651       \n",
      "=================================================================\n",
      "Total params: 10,441,163\n",
      "Trainable params: 10,441,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Decoder\n",
    "\"\"\"\n",
    "\n",
    "latent_inputs = tf.keras.Input(shape=(100,))\n",
    "x = layers.Dense(100, activation=\"elu\")(latent_inputs)\n",
    "x = layers.Dense(40 * 40 * 64, activation=\"elu\")(x)\n",
    "x = layers.Reshape((40, 40, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"elu\",  padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(48, 3, activation=\"elu\",  padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(36, 3, activation=\"elu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(24, 3, activation=\"elu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## VAE\n",
    "\"\"\"\n",
    "model_input = [ encoder_inputs_img, encoder_inputs_str,\n",
    "                        encoder_inputs_vel, encoder_inputs_time]\n",
    "model_output = decoder(encoder_output)\n",
    "\n",
    "VarAE=Model(model_input, model_output)\n",
    "# VarAE.run_eagerly = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data generator\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _generator(samples, batch_size=config['batch_size']):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, (num_samples//batch_size)*batch_size, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times = prepare_vae_batch_samples(batch_samples)\n",
    "\n",
    "            X_img = np.array(images).astype(\"float32\")/255.0\n",
    "            X_tvel = np.array(tar_vels).astype(\"float32\")/15.0\n",
    "            X_tstr = np.array(tar_steering_angles)*config['steering_angle_scale']\n",
    "            X_ttime = np.array(tar_times)*config['time_scale']\n",
    "\n",
    "            y_train = np.array(tar_images).astype(\"float32\")/255.0\n",
    "            # if config['num_outputs'] == 1:\n",
    "            # y_train = np.array(segimg)\n",
    "            # print(y_train.max())\n",
    "            # y_train = np.repeat(y_train[..., np.newaxis], 1, -1)/y_train.max()\n",
    "            X_train = [X_img, X_tstr, X_tvel, X_ttime]\n",
    "            # print(y_train)\n",
    "            # print(y_train.shape)\n",
    "            yield X_train, y_train\n",
    "\n",
    "train_data, valid_data = train_test_split(samples, test_size=config['validation_rate'])\n",
    "\n",
    "train_generator = _generator(train_data, config['batch_size'])\n",
    "valid_generator = _generator(valid_data, config['batch_size'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VAE loss\n",
    "\"\"\"\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005, decay=0.0000000001)\n",
    "r_loss_factor=160*160*100   # This is a Hyperparameter\n",
    "\n",
    "def vae_r_loss(y_true, y_pred):    ## MSE\n",
    "    r_loss = tf.keras.backend.mean(tf.keras.backend.square(y_true-y_pred), axis=[1,2,3])\n",
    "    return r_loss_factor * r_loss\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):   ## KL-Divergence\n",
    "    kl_loss=( -0.5 * tf.keras.backend.sum(1+z_log_var \n",
    "                - tf.keras.backend.square(z_mean) \n",
    "                - tf.keras.backend.exp(z_log_var), axis=1)\n",
    "    )\n",
    "    return kl_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred): \n",
    "    r_loss=vae_r_loss(y_true, y_pred) #Loss of Decoder\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred) #Loss of Encoder\n",
    "    return r_loss + kl_loss #Sum of these two\n",
    "\n",
    "\n",
    "VarAE.compile(optimizer=optimizer,\n",
    "                loss= vae_loss, \n",
    "                metrics=[vae_r_loss, vae_kl_loss])\n",
    "# VarAE.summary()\n",
    "#  vae_r_loss: 12.6586 - vae_kl_loss: 2251744.5000 \n",
    "#  val_loss: 50649853.6174 \n",
    "#  val_vae_r_loss: 28.6742 - val_vae_kl_loss: 50649896.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "Epoch 1/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 721.7138 - vae_r_loss: 673.4619 - vae_kl_loss: 48.2519WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1627.11260, saving model to vae_kdh_ckpt.01-1627.113.h5\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 721.7541 - vae_r_loss: 673.5018 - vae_kl_loss: 48.2522 - val_loss: 1627.1126 - val_vae_r_loss: 1578.8192 - val_vae_kl_loss: 48.2940\n",
      "Epoch 2/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 714.4264 - vae_r_loss: 656.1094 - vae_kl_loss: 58.3167WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 714.4264 - vae_r_loss: 656.1094 - vae_kl_loss: 58.3167 - val_loss: 1654.9194 - val_vae_r_loss: 1595.3284 - val_vae_kl_loss: 59.5922\n",
      "Epoch 3/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 671.4335 - vae_r_loss: 608.6780 - vae_kl_loss: 62.7562WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 671.4026 - vae_r_loss: 608.6478 - vae_kl_loss: 62.7556 - val_loss: 1650.4533 - val_vae_r_loss: 1587.6681 - val_vae_kl_loss: 62.7855\n",
      "Epoch 4/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 654.3927 - vae_r_loss: 588.5127 - vae_kl_loss: 65.8795WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 654.3927 - vae_r_loss: 588.5127 - vae_kl_loss: 65.8795 - val_loss: 1641.5135 - val_vae_r_loss: 1576.7944 - val_vae_kl_loss: 64.7186\n",
      "Epoch 5/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 635.3529 - vae_r_loss: 567.2493 - vae_kl_loss: 68.1037WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 635.3153 - vae_r_loss: 567.2133 - vae_kl_loss: 68.1021 - val_loss: 1677.6349 - val_vae_r_loss: 1611.0529 - val_vae_kl_loss: 66.5820\n",
      "Epoch 6/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 638.7533 - vae_r_loss: 570.0502 - vae_kl_loss: 68.7027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 638.7533 - vae_r_loss: 570.0502 - vae_kl_loss: 68.7027 - val_loss: 1683.6751 - val_vae_r_loss: 1615.7249 - val_vae_kl_loss: 67.9499\n",
      "Epoch 7/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 628.9065 - vae_r_loss: 558.3391 - vae_kl_loss: 70.5671WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 628.8669 - vae_r_loss: 558.3009 - vae_kl_loss: 70.5658 - val_loss: 1699.9284 - val_vae_r_loss: 1630.7461 - val_vae_kl_loss: 69.1823\n",
      "Epoch 8/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 627.9122 - vae_r_loss: 556.8479 - vae_kl_loss: 71.0639WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 627.9938 - vae_r_loss: 556.9296 - vae_kl_loss: 71.0638 - val_loss: 1675.0728 - val_vae_r_loss: 1603.3696 - val_vae_kl_loss: 71.7027\n",
      "Epoch 9/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 616.8911 - vae_r_loss: 545.2348 - vae_kl_loss: 71.6568WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 616.8911 - vae_r_loss: 545.2348 - vae_kl_loss: 71.6568 - val_loss: 1687.2954 - val_vae_r_loss: 1613.8392 - val_vae_kl_loss: 73.4548\n",
      "Epoch 10/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 614.5905 - vae_r_loss: 542.6063 - vae_kl_loss: 71.9845WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 614.5661 - vae_r_loss: 542.5826 - vae_kl_loss: 71.9838 - val_loss: 1658.6283 - val_vae_r_loss: 1587.0212 - val_vae_kl_loss: 71.6061\n",
      "Epoch 11/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 620.6371 - vae_r_loss: 547.4332 - vae_kl_loss: 73.2039WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1627.11260\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 620.6371 - vae_r_loss: 547.4332 - vae_kl_loss: 73.2039 - val_loss: 1650.4887 - val_vae_r_loss: 1579.4778 - val_vae_kl_loss: 71.0107\n",
      "Epoch 12/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 621.7448 - vae_r_loss: 548.9854 - vae_kl_loss: 72.7595WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00012: val_loss improved from 1627.11260 to 1625.52241, saving model to vae_kdh_ckpt.12-1625.522.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 621.6795 - vae_r_loss: 548.9194 - vae_kl_loss: 72.7601 - val_loss: 1625.5224 - val_vae_r_loss: 1552.9254 - val_vae_kl_loss: 72.5966\n",
      "Epoch 13/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 576.0455 - vae_r_loss: 503.0112 - vae_kl_loss: 73.0338WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00013: val_loss improved from 1625.52241 to 1607.80625, saving model to vae_kdh_ckpt.13-1607.806.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 576.0455 - vae_r_loss: 503.0112 - vae_kl_loss: 73.0338 - val_loss: 1607.8063 - val_vae_r_loss: 1534.7267 - val_vae_kl_loss: 73.0801\n",
      "Epoch 14/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 574.1576 - vae_r_loss: 500.1956 - vae_kl_loss: 73.9617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 574.1576 - vae_r_loss: 500.1956 - vae_kl_loss: 73.9617 - val_loss: 1658.5610 - val_vae_r_loss: 1584.8986 - val_vae_kl_loss: 73.6635\n",
      "Epoch 15/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 599.4746 - vae_r_loss: 525.0031 - vae_kl_loss: 74.4717WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 599.4746 - vae_r_loss: 525.0031 - vae_kl_loss: 74.4717 - val_loss: 1648.2179 - val_vae_r_loss: 1574.2711 - val_vae_kl_loss: 73.9463\n",
      "Epoch 16/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 569.3482 - vae_r_loss: 495.1549 - vae_kl_loss: 74.1936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 569.2967 - vae_r_loss: 495.1039 - vae_kl_loss: 74.1930 - val_loss: 1656.6324 - val_vae_r_loss: 1582.0999 - val_vae_kl_loss: 74.5328\n",
      "Epoch 17/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 551.0041 - vae_r_loss: 475.5263 - vae_kl_loss: 75.4778WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 550.9673 - vae_r_loss: 475.4907 - vae_kl_loss: 75.4766 - val_loss: 1674.3272 - val_vae_r_loss: 1601.1913 - val_vae_kl_loss: 73.1349\n",
      "Epoch 18/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 567.3204 - vae_r_loss: 492.0701 - vae_kl_loss: 75.2501WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 567.3204 - vae_r_loss: 492.0701 - vae_kl_loss: 75.2501 - val_loss: 1634.1527 - val_vae_r_loss: 1559.3761 - val_vae_kl_loss: 74.7767\n",
      "Epoch 19/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 554.0773 - vae_r_loss: 477.9788 - vae_kl_loss: 76.0989WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 554.0773 - vae_r_loss: 477.9788 - vae_kl_loss: 76.0989 - val_loss: 1703.7882 - val_vae_r_loss: 1628.7821 - val_vae_kl_loss: 75.0067\n",
      "Epoch 20/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 552.5882 - vae_r_loss: 477.0203 - vae_kl_loss: 75.5690WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 552.5882 - vae_r_loss: 477.0203 - vae_kl_loss: 75.5690 - val_loss: 1708.8024 - val_vae_r_loss: 1632.9838 - val_vae_kl_loss: 75.8172\n",
      "Epoch 21/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 518.2737 - vae_r_loss: 442.5575 - vae_kl_loss: 75.7168WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 518.2804 - vae_r_loss: 442.5639 - vae_kl_loss: 75.7169 - val_loss: 1689.0178 - val_vae_r_loss: 1612.9679 - val_vae_kl_loss: 76.0505\n",
      "Epoch 22/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 630.2847 - vae_r_loss: 554.1482 - vae_kl_loss: 76.1367WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 630.2526 - vae_r_loss: 554.1156 - vae_kl_loss: 76.1372 - val_loss: 1712.0893 - val_vae_r_loss: 1634.1006 - val_vae_kl_loss: 77.9879\n",
      "Epoch 23/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 627.9826 - vae_r_loss: 551.7676 - vae_kl_loss: 76.2146WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 627.9826 - vae_r_loss: 551.7676 - vae_kl_loss: 76.2146 - val_loss: 1672.0920 - val_vae_r_loss: 1595.3093 - val_vae_kl_loss: 76.7816\n",
      "Epoch 24/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 623.8815 - vae_r_loss: 547.7093 - vae_kl_loss: 76.1722WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 623.8815 - vae_r_loss: 547.7093 - vae_kl_loss: 76.1722 - val_loss: 1658.6518 - val_vae_r_loss: 1583.6067 - val_vae_kl_loss: 75.0448\n",
      "Epoch 25/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 632.4692 - vae_r_loss: 555.8253 - vae_kl_loss: 76.6433WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 632.4692 - vae_r_loss: 555.8253 - vae_kl_loss: 76.6433 - val_loss: 1655.2572 - val_vae_r_loss: 1580.2114 - val_vae_kl_loss: 75.0477\n",
      "Epoch 26/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 617.6075 - vae_r_loss: 540.1302 - vae_kl_loss: 77.4779WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1607.80625\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 617.6075 - vae_r_loss: 540.1302 - vae_kl_loss: 77.4779 - val_loss: 1614.0953 - val_vae_r_loss: 1535.7960 - val_vae_kl_loss: 78.2986\n",
      "Epoch 27/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 607.8537 - vae_r_loss: 530.1887 - vae_kl_loss: 77.6650WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00027: val_loss improved from 1607.80625 to 1602.59539, saving model to vae_kdh_ckpt.27-1602.595.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 607.8537 - vae_r_loss: 530.1887 - vae_kl_loss: 77.6650 - val_loss: 1602.5954 - val_vae_r_loss: 1525.2860 - val_vae_kl_loss: 77.3092\n",
      "Epoch 28/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 597.3124 - vae_r_loss: 519.7414 - vae_kl_loss: 77.5715WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1602.59539\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 597.3970 - vae_r_loss: 519.8268 - vae_kl_loss: 77.5706 - val_loss: 1603.0024 - val_vae_r_loss: 1524.5848 - val_vae_kl_loss: 78.4152\n",
      "Epoch 29/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 595.2410 - vae_r_loss: 517.1386 - vae_kl_loss: 78.1023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00029: val_loss improved from 1602.59539 to 1589.06812, saving model to vae_kdh_ckpt.29-1589.068.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 595.2410 - vae_r_loss: 517.1386 - vae_kl_loss: 78.1023 - val_loss: 1589.0681 - val_vae_r_loss: 1512.5293 - val_vae_kl_loss: 76.5389\n",
      "Epoch 30/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 584.4201 - vae_r_loss: 505.8236 - vae_kl_loss: 78.5961WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00030: val_loss improved from 1589.06812 to 1553.50478, saving model to vae_kdh_ckpt.30-1553.505.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 584.4201 - vae_r_loss: 505.8236 - vae_kl_loss: 78.5961 - val_loss: 1553.5048 - val_vae_r_loss: 1475.3711 - val_vae_kl_loss: 78.1346\n",
      "Epoch 31/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 565.1507 - vae_r_loss: 486.7955 - vae_kl_loss: 78.3551WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1553.50478\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 565.1507 - vae_r_loss: 486.7955 - vae_kl_loss: 78.3551 - val_loss: 1576.4205 - val_vae_r_loss: 1498.2965 - val_vae_kl_loss: 78.1227\n",
      "Epoch 32/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 578.8623 - vae_r_loss: 499.5592 - vae_kl_loss: 79.3030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1553.50478\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 578.8623 - vae_r_loss: 499.5592 - vae_kl_loss: 79.3030 - val_loss: 1582.7814 - val_vae_r_loss: 1502.2701 - val_vae_kl_loss: 80.5127\n",
      "Epoch 33/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 568.9015 - vae_r_loss: 489.3585 - vae_kl_loss: 79.5429WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1553.50478\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 568.9015 - vae_r_loss: 489.3585 - vae_kl_loss: 79.5429 - val_loss: 1556.3054 - val_vae_r_loss: 1476.1689 - val_vae_kl_loss: 80.1376\n",
      "Epoch 34/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 582.1855 - vae_r_loss: 501.6710 - vae_kl_loss: 80.5142WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1553.50478\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 582.1420 - vae_r_loss: 501.6289 - vae_kl_loss: 80.5128 - val_loss: 1554.6884 - val_vae_r_loss: 1475.0723 - val_vae_kl_loss: 79.6161\n",
      "Epoch 35/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 568.3890 - vae_r_loss: 488.4653 - vae_kl_loss: 79.9241WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00035: val_loss improved from 1553.50478 to 1511.76041, saving model to vae_kdh_ckpt.35-1511.760.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 568.3890 - vae_r_loss: 488.4653 - vae_kl_loss: 79.9241 - val_loss: 1511.7604 - val_vae_r_loss: 1431.8131 - val_vae_kl_loss: 79.9476\n",
      "Epoch 36/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 547.1687 - vae_r_loss: 466.5823 - vae_kl_loss: 80.5857WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1511.76041\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 547.1135 - vae_r_loss: 466.5267 - vae_kl_loss: 80.5862 - val_loss: 1523.9057 - val_vae_r_loss: 1443.8424 - val_vae_kl_loss: 80.0636\n",
      "Epoch 37/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 559.3231 - vae_r_loss: 478.8861 - vae_kl_loss: 80.4369WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00037: val_loss improved from 1511.76041 to 1491.40156, saving model to vae_kdh_ckpt.37-1491.402.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 559.2585 - vae_r_loss: 478.8211 - vae_kl_loss: 80.4373 - val_loss: 1491.4016 - val_vae_r_loss: 1411.7111 - val_vae_kl_loss: 79.6917\n",
      "Epoch 38/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 560.2454 - vae_r_loss: 479.8271 - vae_kl_loss: 80.4181WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1491.40156\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 560.1927 - vae_r_loss: 479.7745 - vae_kl_loss: 80.4181 - val_loss: 1504.8985 - val_vae_r_loss: 1425.2886 - val_vae_kl_loss: 79.6102\n",
      "Epoch 39/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 550.2081 - vae_r_loss: 469.1927 - vae_kl_loss: 81.0151WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1491.40156\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 550.1349 - vae_r_loss: 469.1204 - vae_kl_loss: 81.0143 - val_loss: 1492.2256 - val_vae_r_loss: 1412.0315 - val_vae_kl_loss: 80.1938\n",
      "Epoch 40/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 534.7583 - vae_r_loss: 453.3363 - vae_kl_loss: 81.4224WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00040: val_loss improved from 1491.40156 to 1441.38280, saving model to vae_kdh_ckpt.40-1441.383.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 534.7583 - vae_r_loss: 453.3363 - vae_kl_loss: 81.4224 - val_loss: 1441.3828 - val_vae_r_loss: 1361.3406 - val_vae_kl_loss: 80.0423\n",
      "Epoch 41/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 550.9326 - vae_r_loss: 470.4043 - vae_kl_loss: 80.5289WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1441.38280\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 550.9069 - vae_r_loss: 470.3790 - vae_kl_loss: 80.5284 - val_loss: 1447.5699 - val_vae_r_loss: 1366.7249 - val_vae_kl_loss: 80.8452\n",
      "Epoch 42/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 535.8209 - vae_r_loss: 454.7127 - vae_kl_loss: 81.1079WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1441.38280\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 535.8209 - vae_r_loss: 454.7127 - vae_kl_loss: 81.1079 - val_loss: 1445.9942 - val_vae_r_loss: 1364.4355 - val_vae_kl_loss: 81.5591\n",
      "Epoch 43/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 535.5902 - vae_r_loss: 453.9746 - vae_kl_loss: 81.6157WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1441.38280\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 535.5902 - vae_r_loss: 453.9746 - vae_kl_loss: 81.6157 - val_loss: 1443.7391 - val_vae_r_loss: 1361.8956 - val_vae_kl_loss: 81.8418\n",
      "Epoch 44/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 537.5672 - vae_r_loss: 456.0066 - vae_kl_loss: 81.5610WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00044: val_loss improved from 1441.38280 to 1425.68620, saving model to vae_kdh_ckpt.44-1425.686.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 537.5672 - vae_r_loss: 456.0066 - vae_kl_loss: 81.5610 - val_loss: 1425.6862 - val_vae_r_loss: 1342.9669 - val_vae_kl_loss: 82.7183\n",
      "Epoch 45/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 535.8924 - vae_r_loss: 454.2586 - vae_kl_loss: 81.6335WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00045: val_loss improved from 1425.68620 to 1403.34268, saving model to vae_kdh_ckpt.45-1403.343.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 535.8924 - vae_r_loss: 454.2586 - vae_kl_loss: 81.6335 - val_loss: 1403.3427 - val_vae_r_loss: 1320.6395 - val_vae_kl_loss: 82.7015\n",
      "Epoch 46/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 537.1297 - vae_r_loss: 455.0404 - vae_kl_loss: 82.0893WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00046: val_loss improved from 1403.34268 to 1403.15055, saving model to vae_kdh_ckpt.46-1403.151.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 537.1534 - vae_r_loss: 455.0635 - vae_kl_loss: 82.0900 - val_loss: 1403.1505 - val_vae_r_loss: 1319.2451 - val_vae_kl_loss: 83.9062\n",
      "Epoch 47/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 533.1743 - vae_r_loss: 449.8678 - vae_kl_loss: 83.3064WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00047: val_loss improved from 1403.15055 to 1400.91703, saving model to vae_kdh_ckpt.47-1400.917.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 533.1743 - vae_r_loss: 449.8678 - vae_kl_loss: 83.3064 - val_loss: 1400.9170 - val_vae_r_loss: 1317.3453 - val_vae_kl_loss: 83.5711\n",
      "Epoch 48/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 515.8830 - vae_r_loss: 432.3120 - vae_kl_loss: 83.5710WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00048: val_loss improved from 1400.91703 to 1366.67332, saving model to vae_kdh_ckpt.48-1366.673.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 515.8250 - vae_r_loss: 432.2542 - vae_kl_loss: 83.5707 - val_loss: 1366.6733 - val_vae_r_loss: 1283.0032 - val_vae_kl_loss: 83.6704\n",
      "Epoch 49/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 493.7350 - vae_r_loss: 410.4924 - vae_kl_loss: 83.2425WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1366.67332\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 493.7350 - vae_r_loss: 410.4924 - vae_kl_loss: 83.2425 - val_loss: 1379.7550 - val_vae_r_loss: 1297.1949 - val_vae_kl_loss: 82.5589\n",
      "Epoch 50/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 473.6607 - vae_r_loss: 390.1101 - vae_kl_loss: 83.5501WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1366.67332\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 473.6607 - vae_r_loss: 390.1101 - vae_kl_loss: 83.5501 - val_loss: 1380.5254 - val_vae_r_loss: 1297.7059 - val_vae_kl_loss: 82.8192\n",
      "Epoch 51/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 466.5913 - vae_r_loss: 383.7352 - vae_kl_loss: 82.8560WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1366.67332\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 466.5913 - vae_r_loss: 383.7352 - vae_kl_loss: 82.8560 - val_loss: 1379.0402 - val_vae_r_loss: 1295.7047 - val_vae_kl_loss: 83.3357\n",
      "Epoch 52/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 463.4721 - vae_r_loss: 379.7436 - vae_kl_loss: 83.7281WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1366.67332\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 463.4326 - vae_r_loss: 379.7039 - vae_kl_loss: 83.7283 - val_loss: 1397.9834 - val_vae_r_loss: 1314.6674 - val_vae_kl_loss: 83.3159\n",
      "Epoch 53/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 457.2267 - vae_r_loss: 373.8878 - vae_kl_loss: 83.3387WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1366.67332\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 457.2267 - vae_r_loss: 373.8878 - vae_kl_loss: 83.3387 - val_loss: 1368.2117 - val_vae_r_loss: 1285.1409 - val_vae_kl_loss: 83.0695\n",
      "Epoch 54/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 456.4996 - vae_r_loss: 373.1584 - vae_kl_loss: 83.3418WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00054: val_loss improved from 1366.67332 to 1362.51384, saving model to vae_kdh_ckpt.54-1362.514.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 456.5025 - vae_r_loss: 373.1615 - vae_kl_loss: 83.3416 - val_loss: 1362.5138 - val_vae_r_loss: 1280.2473 - val_vae_kl_loss: 82.2663\n",
      "Epoch 55/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 458.2537 - vae_r_loss: 374.4922 - vae_kl_loss: 83.7611WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1362.51384\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 458.2040 - vae_r_loss: 374.4438 - vae_kl_loss: 83.7599 - val_loss: 1389.6812 - val_vae_r_loss: 1307.0634 - val_vae_kl_loss: 82.6189\n",
      "Epoch 56/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 452.1622 - vae_r_loss: 369.0231 - vae_kl_loss: 83.1389WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1362.51384\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 452.1355 - vae_r_loss: 368.9957 - vae_kl_loss: 83.1396 - val_loss: 1370.7870 - val_vae_r_loss: 1287.3518 - val_vae_kl_loss: 83.4355\n",
      "Epoch 57/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 444.8901 - vae_r_loss: 361.1745 - vae_kl_loss: 83.7155WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1362.51384\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 444.8901 - vae_r_loss: 361.1745 - vae_kl_loss: 83.7155 - val_loss: 1386.6061 - val_vae_r_loss: 1303.1245 - val_vae_kl_loss: 83.4793\n",
      "Epoch 58/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 444.1236 - vae_r_loss: 360.8527 - vae_kl_loss: 83.2707WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00058: val_loss improved from 1362.51384 to 1330.67655, saving model to vae_kdh_ckpt.58-1330.677.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 444.1177 - vae_r_loss: 360.8476 - vae_kl_loss: 83.2699 - val_loss: 1330.6765 - val_vae_r_loss: 1247.3657 - val_vae_kl_loss: 83.3104\n",
      "Epoch 59/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 442.5531 - vae_r_loss: 358.6324 - vae_kl_loss: 83.9203WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1330.67655\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 442.5877 - vae_r_loss: 358.6671 - vae_kl_loss: 83.9202 - val_loss: 1342.1127 - val_vae_r_loss: 1259.4950 - val_vae_kl_loss: 82.6167\n",
      "Epoch 60/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 444.6550 - vae_r_loss: 361.2960 - vae_kl_loss: 83.3593WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1330.67655\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 444.6266 - vae_r_loss: 361.2670 - vae_kl_loss: 83.3599 - val_loss: 1345.8132 - val_vae_r_loss: 1263.3800 - val_vae_kl_loss: 82.4342\n",
      "Epoch 61/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 418.8105 - vae_r_loss: 335.7841 - vae_kl_loss: 83.0266WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1330.67655\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 418.8353 - vae_r_loss: 335.8090 - vae_kl_loss: 83.0264 - val_loss: 1333.8131 - val_vae_r_loss: 1250.9993 - val_vae_kl_loss: 82.8146\n",
      "Epoch 62/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 424.3231 - vae_r_loss: 341.2094 - vae_kl_loss: 83.1137WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1330.67655\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 424.3231 - vae_r_loss: 341.2094 - vae_kl_loss: 83.1137 - val_loss: 1358.2804 - val_vae_r_loss: 1274.9427 - val_vae_kl_loss: 83.3379\n",
      "Epoch 63/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 437.2327 - vae_r_loss: 353.4834 - vae_kl_loss: 83.7488WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00063: val_loss improved from 1330.67655 to 1319.54790, saving model to vae_kdh_ckpt.63-1319.548.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 437.2327 - vae_r_loss: 353.4834 - vae_kl_loss: 83.7488 - val_loss: 1319.5479 - val_vae_r_loss: 1236.3214 - val_vae_kl_loss: 83.2254\n",
      "Epoch 64/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 416.2540 - vae_r_loss: 332.9700 - vae_kl_loss: 83.2845WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 416.2540 - vae_r_loss: 332.9700 - vae_kl_loss: 83.2845 - val_loss: 1334.7922 - val_vae_r_loss: 1251.8851 - val_vae_kl_loss: 82.9063\n",
      "Epoch 65/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 411.6644 - vae_r_loss: 327.7758 - vae_kl_loss: 83.8889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 411.6644 - vae_r_loss: 327.7758 - vae_kl_loss: 83.8889 - val_loss: 1350.4965 - val_vae_r_loss: 1268.1707 - val_vae_kl_loss: 82.3263\n",
      "Epoch 66/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 424.4189 - vae_r_loss: 340.7950 - vae_kl_loss: 83.6240WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 424.4189 - vae_r_loss: 340.7950 - vae_kl_loss: 83.6240 - val_loss: 1334.9058 - val_vae_r_loss: 1252.8080 - val_vae_kl_loss: 82.0975\n",
      "Epoch 67/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 415.9900 - vae_r_loss: 332.2628 - vae_kl_loss: 83.7276WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 415.9900 - vae_r_loss: 332.2628 - vae_kl_loss: 83.7276 - val_loss: 1363.6383 - val_vae_r_loss: 1281.0544 - val_vae_kl_loss: 82.5841\n",
      "Epoch 68/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 422.0139 - vae_r_loss: 338.5095 - vae_kl_loss: 83.5044WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 422.0009 - vae_r_loss: 338.4968 - vae_kl_loss: 83.5040 - val_loss: 1354.6941 - val_vae_r_loss: 1272.2952 - val_vae_kl_loss: 82.4003\n",
      "Epoch 69/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 396.2574 - vae_r_loss: 313.6262 - vae_kl_loss: 82.6314WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 396.2574 - vae_r_loss: 313.6262 - vae_kl_loss: 82.6314 - val_loss: 1342.6000 - val_vae_r_loss: 1259.2092 - val_vae_kl_loss: 83.3899\n",
      "Epoch 70/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 427.5590 - vae_r_loss: 344.5162 - vae_kl_loss: 83.0431WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 427.5590 - vae_r_loss: 344.5162 - vae_kl_loss: 83.0431 - val_loss: 1353.8641 - val_vae_r_loss: 1270.3396 - val_vae_kl_loss: 83.5242\n",
      "Epoch 71/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 429.5691 - vae_r_loss: 346.2338 - vae_kl_loss: 83.3359 ETA: 1s - batch: 1535.5000 - size: 32.0000 - WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1319.54790\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 429.5691 - vae_r_loss: 346.2338 - vae_kl_loss: 83.3359 - val_loss: 1341.9510 - val_vae_r_loss: 1258.4680 - val_vae_kl_loss: 83.4826\n",
      "Epoch 72/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 421.4726 - vae_r_loss: 338.2643 - vae_kl_loss: 83.2084WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00072: val_loss improved from 1319.54790 to 1312.99334, saving model to vae_kdh_ckpt.72-1312.993.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 421.4726 - vae_r_loss: 338.2643 - vae_kl_loss: 83.2084 - val_loss: 1312.9933 - val_vae_r_loss: 1230.7224 - val_vae_kl_loss: 82.2704\n",
      "Epoch 73/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 429.2411 - vae_r_loss: 345.9941 - vae_kl_loss: 83.2471WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00073: val_loss improved from 1312.99334 to 1307.47651, saving model to vae_kdh_ckpt.73-1307.477.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 429.2411 - vae_r_loss: 345.9941 - vae_kl_loss: 83.2471 - val_loss: 1307.4765 - val_vae_r_loss: 1224.6699 - val_vae_kl_loss: 82.8052\n",
      "Epoch 74/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 433.6070 - vae_r_loss: 350.1018 - vae_kl_loss: 83.5055WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00074: val_loss improved from 1307.47651 to 1300.73958, saving model to vae_kdh_ckpt.74-1300.740.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 433.6070 - vae_r_loss: 350.1018 - vae_kl_loss: 83.5055 - val_loss: 1300.7396 - val_vae_r_loss: 1216.9397 - val_vae_kl_loss: 83.7989\n",
      "Epoch 75/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 420.6256 - vae_r_loss: 337.0109 - vae_kl_loss: 83.6146WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00075: val_loss improved from 1300.73958 to 1281.20215, saving model to vae_kdh_ckpt.75-1281.202.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 420.6256 - vae_r_loss: 337.0109 - vae_kl_loss: 83.6146 - val_loss: 1281.2021 - val_vae_r_loss: 1197.8998 - val_vae_kl_loss: 83.3018\n",
      "Epoch 76/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 420.2057 - vae_r_loss: 336.8547 - vae_kl_loss: 83.3511WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00076: val_loss improved from 1281.20215 to 1272.57231, saving model to vae_kdh_ckpt.76-1272.572.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 420.2057 - vae_r_loss: 336.8547 - vae_kl_loss: 83.3511 - val_loss: 1272.5723 - val_vae_r_loss: 1189.3287 - val_vae_kl_loss: 83.2432\n",
      "Epoch 77/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 405.6570 - vae_r_loss: 322.1268 - vae_kl_loss: 83.5305WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00077: val_loss improved from 1272.57231 to 1258.63937, saving model to vae_kdh_ckpt.77-1258.639.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 405.6570 - vae_r_loss: 322.1268 - vae_kl_loss: 83.5305 - val_loss: 1258.6394 - val_vae_r_loss: 1175.6672 - val_vae_kl_loss: 82.9723\n",
      "Epoch 78/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 415.5999 - vae_r_loss: 331.8571 - vae_kl_loss: 83.7429WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00078: val_loss improved from 1258.63937 to 1258.08963, saving model to vae_kdh_ckpt.78-1258.090.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 415.5715 - vae_r_loss: 331.8289 - vae_kl_loss: 83.7427 - val_loss: 1258.0896 - val_vae_r_loss: 1174.6509 - val_vae_kl_loss: 83.4389\n",
      "Epoch 79/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 402.2071 - vae_r_loss: 319.1997 - vae_kl_loss: 83.0074WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1258.08963\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 402.1804 - vae_r_loss: 319.1740 - vae_kl_loss: 83.0065 - val_loss: 1263.4273 - val_vae_r_loss: 1179.7754 - val_vae_kl_loss: 83.6524\n",
      "Epoch 80/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 408.0240 - vae_r_loss: 324.2713 - vae_kl_loss: 83.7522WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1258.08963\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 408.0336 - vae_r_loss: 324.2809 - vae_kl_loss: 83.7522 - val_loss: 1283.0885 - val_vae_r_loss: 1198.6354 - val_vae_kl_loss: 84.4532\n",
      "Epoch 81/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 400.3851 - vae_r_loss: 316.5884 - vae_kl_loss: 83.7968WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1258.08963\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 400.3758 - vae_r_loss: 316.5789 - vae_kl_loss: 83.7969 - val_loss: 1274.2783 - val_vae_r_loss: 1190.6124 - val_vae_kl_loss: 83.6658\n",
      "Epoch 82/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 413.2388 - vae_r_loss: 328.9262 - vae_kl_loss: 84.3128WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00082: val_loss improved from 1258.08963 to 1252.32997, saving model to vae_kdh_ckpt.82-1252.330.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 413.2205 - vae_r_loss: 328.9062 - vae_kl_loss: 84.3145 - val_loss: 1252.3300 - val_vae_r_loss: 1169.1725 - val_vae_kl_loss: 83.1579\n",
      "Epoch 83/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 408.7501 - vae_r_loss: 325.0334 - vae_kl_loss: 83.7167WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00083: val_loss improved from 1252.32997 to 1242.00791, saving model to vae_kdh_ckpt.83-1242.008.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 408.7261 - vae_r_loss: 325.0084 - vae_kl_loss: 83.7177 - val_loss: 1242.0079 - val_vae_r_loss: 1158.1073 - val_vae_kl_loss: 83.9015\n",
      "Epoch 84/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 393.5030 - vae_r_loss: 309.5369 - vae_kl_loss: 83.9660WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1242.00791\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 393.5030 - vae_r_loss: 309.5369 - vae_kl_loss: 83.9660 - val_loss: 1260.4465 - val_vae_r_loss: 1177.1592 - val_vae_kl_loss: 83.2870\n",
      "Epoch 85/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 403.2536 - vae_r_loss: 319.5649 - vae_kl_loss: 83.6887WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1242.00791\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 403.2536 - vae_r_loss: 319.5649 - vae_kl_loss: 83.6887 - val_loss: 1242.0279 - val_vae_r_loss: 1159.1196 - val_vae_kl_loss: 82.9088\n",
      "Epoch 86/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 408.9293 - vae_r_loss: 325.4278 - vae_kl_loss: 83.5015WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1242.00791\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 408.9293 - vae_r_loss: 325.4278 - vae_kl_loss: 83.5015 - val_loss: 1263.8527 - val_vae_r_loss: 1180.7539 - val_vae_kl_loss: 83.0977\n",
      "Epoch 87/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 399.1170 - vae_r_loss: 315.3221 - vae_kl_loss: 83.7949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1242.00791\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 399.0982 - vae_r_loss: 315.3037 - vae_kl_loss: 83.7945 - val_loss: 1246.9322 - val_vae_r_loss: 1163.8230 - val_vae_kl_loss: 83.1102\n",
      "Epoch 88/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 390.8739 - vae_r_loss: 306.8344 - vae_kl_loss: 84.0396WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00088: val_loss improved from 1242.00791 to 1219.22695, saving model to vae_kdh_ckpt.88-1219.227.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 390.8739 - vae_r_loss: 306.8344 - vae_kl_loss: 84.0396 - val_loss: 1219.2270 - val_vae_r_loss: 1136.1945 - val_vae_kl_loss: 83.0343\n",
      "Epoch 89/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 398.7984 - vae_r_loss: 315.2774 - vae_kl_loss: 83.5211WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00089: val_loss improved from 1219.22695 to 1216.56578, saving model to vae_kdh_ckpt.89-1216.566.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 398.7984 - vae_r_loss: 315.2774 - vae_kl_loss: 83.5211 - val_loss: 1216.5658 - val_vae_r_loss: 1132.7616 - val_vae_kl_loss: 83.8045\n",
      "Epoch 90/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 392.3508 - vae_r_loss: 308.9133 - vae_kl_loss: 83.4377WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00090: val_loss improved from 1216.56578 to 1211.19876, saving model to vae_kdh_ckpt.90-1211.199.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 392.3102 - vae_r_loss: 308.8732 - vae_kl_loss: 83.4372 - val_loss: 1211.1988 - val_vae_r_loss: 1127.0580 - val_vae_kl_loss: 84.1405\n",
      "Epoch 91/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 392.2327 - vae_r_loss: 308.6100 - vae_kl_loss: 83.6224WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1211.19876\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 392.1944 - vae_r_loss: 308.5709 - vae_kl_loss: 83.6232 - val_loss: 1216.2321 - val_vae_r_loss: 1132.7126 - val_vae_kl_loss: 83.5194\n",
      "Epoch 92/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 396.3526 - vae_r_loss: 312.6360 - vae_kl_loss: 83.7164WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00092: val_loss improved from 1211.19876 to 1203.05773, saving model to vae_kdh_ckpt.92-1203.058.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 396.3454 - vae_r_loss: 312.6287 - vae_kl_loss: 83.7165 - val_loss: 1203.0577 - val_vae_r_loss: 1119.7006 - val_vae_kl_loss: 83.3567\n",
      "Epoch 93/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 393.1820 - vae_r_loss: 309.6203 - vae_kl_loss: 83.5620WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1203.05773\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 393.3574 - vae_r_loss: 309.7962 - vae_kl_loss: 83.5616 - val_loss: 1204.0975 - val_vae_r_loss: 1120.3801 - val_vae_kl_loss: 83.7180\n",
      "Epoch 94/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 403.6961 - vae_r_loss: 320.0739 - vae_kl_loss: 83.6219WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00094: val_loss improved from 1203.05773 to 1191.93459, saving model to vae_kdh_ckpt.94-1191.935.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 403.6961 - vae_r_loss: 320.0739 - vae_kl_loss: 83.6219 - val_loss: 1191.9346 - val_vae_r_loss: 1107.2323 - val_vae_kl_loss: 84.7018\n",
      "Epoch 95/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 396.5565 - vae_r_loss: 312.2329 - vae_kl_loss: 84.3236WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1191.93459\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 396.5299 - vae_r_loss: 312.2065 - vae_kl_loss: 84.3235 - val_loss: 1216.3084 - val_vae_r_loss: 1132.3934 - val_vae_kl_loss: 83.9148\n",
      "Epoch 96/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 386.4584 - vae_r_loss: 302.1104 - vae_kl_loss: 84.3482WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00096: val_loss improved from 1191.93459 to 1174.63200, saving model to vae_kdh_ckpt.96-1174.632.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 386.4584 - vae_r_loss: 302.1104 - vae_kl_loss: 84.3482 - val_loss: 1174.6320 - val_vae_r_loss: 1091.0884 - val_vae_kl_loss: 83.5432\n",
      "Epoch 97/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 377.9880 - vae_r_loss: 294.1794 - vae_kl_loss: 83.8088WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 377.9783 - vae_r_loss: 294.1697 - vae_kl_loss: 83.8086 - val_loss: 1192.4418 - val_vae_r_loss: 1109.0444 - val_vae_kl_loss: 83.3974\n",
      "Epoch 98/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 377.8829 - vae_r_loss: 293.8987 - vae_kl_loss: 83.9840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 377.8466 - vae_r_loss: 293.8619 - vae_kl_loss: 83.9845 - val_loss: 1190.5381 - val_vae_r_loss: 1107.1841 - val_vae_kl_loss: 83.3544\n",
      "Epoch 99/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 366.1536 - vae_r_loss: 282.7916 - vae_kl_loss: 83.3617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 366.1536 - vae_r_loss: 282.7916 - vae_kl_loss: 83.3617 - val_loss: 1197.4209 - val_vae_r_loss: 1113.1649 - val_vae_kl_loss: 84.2552\n",
      "Epoch 100/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 366.2778 - vae_r_loss: 282.3631 - vae_kl_loss: 83.9150WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 366.2602 - vae_r_loss: 282.3459 - vae_kl_loss: 83.9145 - val_loss: 1210.7870 - val_vae_r_loss: 1127.8390 - val_vae_kl_loss: 82.9495\n",
      "Epoch 101/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 359.5886 - vae_r_loss: 276.0145 - vae_kl_loss: 83.5741WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 359.5886 - vae_r_loss: 276.0145 - vae_kl_loss: 83.5741 - val_loss: 1203.8217 - val_vae_r_loss: 1120.3805 - val_vae_kl_loss: 83.4408\n",
      "Epoch 102/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 362.8929 - vae_r_loss: 279.1947 - vae_kl_loss: 83.6985WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 362.8929 - vae_r_loss: 279.1947 - vae_kl_loss: 83.6985 - val_loss: 1192.6558 - val_vae_r_loss: 1109.6185 - val_vae_kl_loss: 83.0383\n",
      "Epoch 103/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 362.8393 - vae_r_loss: 278.4993 - vae_kl_loss: 84.3398WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 362.8393 - vae_r_loss: 278.4993 - vae_kl_loss: 84.3398 - val_loss: 1214.0641 - val_vae_r_loss: 1130.9395 - val_vae_kl_loss: 83.1239\n",
      "Epoch 104/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 361.3026 - vae_r_loss: 277.6711 - vae_kl_loss: 83.6317WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 361.3231 - vae_r_loss: 277.6917 - vae_kl_loss: 83.6315 - val_loss: 1210.5108 - val_vae_r_loss: 1126.9395 - val_vae_kl_loss: 83.5716\n",
      "Epoch 105/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 364.8143 - vae_r_loss: 281.0823 - vae_kl_loss: 83.7321WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1174.63200\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 364.7947 - vae_r_loss: 281.0622 - vae_kl_loss: 83.7326 - val_loss: 1205.6181 - val_vae_r_loss: 1122.4037 - val_vae_kl_loss: 83.2147\n",
      "Epoch 106/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 354.9184 - vae_r_loss: 271.3641 - vae_kl_loss: 83.5539WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00106: val_loss improved from 1174.63200 to 1163.37026, saving model to vae_kdh_ckpt.106-1163.370.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 354.9184 - vae_r_loss: 271.3641 - vae_kl_loss: 83.5539 - val_loss: 1163.3703 - val_vae_r_loss: 1079.6163 - val_vae_kl_loss: 83.7538\n",
      "Epoch 107/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 356.5631 - vae_r_loss: 272.3513 - vae_kl_loss: 84.2120WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 356.5307 - vae_r_loss: 272.3198 - vae_kl_loss: 84.2112 - val_loss: 1192.0780 - val_vae_r_loss: 1109.2415 - val_vae_kl_loss: 82.8369\n",
      "Epoch 108/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 360.0234 - vae_r_loss: 276.4577 - vae_kl_loss: 83.5663WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 359.9934 - vae_r_loss: 276.4278 - vae_kl_loss: 83.5661 - val_loss: 1203.2239 - val_vae_r_loss: 1119.3772 - val_vae_kl_loss: 83.8452\n",
      "Epoch 109/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 341.1350 - vae_r_loss: 258.0488 - vae_kl_loss: 83.0864WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 341.1151 - vae_r_loss: 258.0287 - vae_kl_loss: 83.0866 - val_loss: 1188.0410 - val_vae_r_loss: 1105.3121 - val_vae_kl_loss: 82.7294\n",
      "Epoch 110/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 347.7987 - vae_r_loss: 264.7729 - vae_kl_loss: 83.0255WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 347.8065 - vae_r_loss: 264.7787 - vae_kl_loss: 83.0276 - val_loss: 1216.7416 - val_vae_r_loss: 1133.4595 - val_vae_kl_loss: 83.2807\n",
      "Epoch 111/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 358.2513 - vae_r_loss: 274.4277 - vae_kl_loss: 83.8236WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 358.2513 - vae_r_loss: 274.4277 - vae_kl_loss: 83.8236 - val_loss: 1166.8476 - val_vae_r_loss: 1084.3315 - val_vae_kl_loss: 82.5165\n",
      "Epoch 112/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 350.5100 - vae_r_loss: 267.5841 - vae_kl_loss: 82.9257WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 350.5164 - vae_r_loss: 267.5903 - vae_kl_loss: 82.9259 - val_loss: 1190.0971 - val_vae_r_loss: 1107.5149 - val_vae_kl_loss: 82.5821\n",
      "Epoch 113/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 342.0772 - vae_r_loss: 258.9113 - vae_kl_loss: 83.1662WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 342.0814 - vae_r_loss: 258.9164 - vae_kl_loss: 83.1654 - val_loss: 1204.2573 - val_vae_r_loss: 1122.1675 - val_vae_kl_loss: 82.0889\n",
      "Epoch 114/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 350.5707 - vae_r_loss: 267.4297 - vae_kl_loss: 83.1408WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 350.5457 - vae_r_loss: 267.4051 - vae_kl_loss: 83.1403 - val_loss: 1197.2492 - val_vae_r_loss: 1115.6953 - val_vae_kl_loss: 81.5546\n",
      "Epoch 115/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 344.2527 - vae_r_loss: 260.9898 - vae_kl_loss: 83.2632WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 344.2592 - vae_r_loss: 260.9955 - vae_kl_loss: 83.2640 - val_loss: 1215.4448 - val_vae_r_loss: 1133.1276 - val_vae_kl_loss: 82.3174\n",
      "Epoch 116/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 344.2037 - vae_r_loss: 260.9850 - vae_kl_loss: 83.2188WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 344.1983 - vae_r_loss: 260.9807 - vae_kl_loss: 83.2177 - val_loss: 1204.0684 - val_vae_r_loss: 1122.1229 - val_vae_kl_loss: 81.9458\n",
      "Epoch 117/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 326.1435 - vae_r_loss: 244.0574 - vae_kl_loss: 82.0863WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 326.1658 - vae_r_loss: 244.0809 - vae_kl_loss: 82.0850 - val_loss: 1202.5760 - val_vae_r_loss: 1120.1165 - val_vae_kl_loss: 82.4594\n",
      "Epoch 118/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 344.5303 - vae_r_loss: 261.5873 - vae_kl_loss: 82.9428WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 344.4954 - vae_r_loss: 261.5522 - vae_kl_loss: 82.9430 - val_loss: 1211.6964 - val_vae_r_loss: 1128.4768 - val_vae_kl_loss: 83.2209\n",
      "Epoch 119/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 340.1164 - vae_r_loss: 257.1283 - vae_kl_loss: 82.9884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 340.1164 - vae_r_loss: 257.1283 - vae_kl_loss: 82.9884 - val_loss: 1198.9656 - val_vae_r_loss: 1116.1228 - val_vae_kl_loss: 82.8430\n",
      "Epoch 120/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 338.6600 - vae_r_loss: 255.8163 - vae_kl_loss: 82.8434WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.6694 - vae_r_loss: 255.8240 - vae_kl_loss: 82.8451 - val_loss: 1178.3537 - val_vae_r_loss: 1096.5057 - val_vae_kl_loss: 81.8476\n",
      "Epoch 121/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 343.9240 - vae_r_loss: 261.1305 - vae_kl_loss: 82.7938WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 344.0380 - vae_r_loss: 261.2464 - vae_kl_loss: 82.7918 - val_loss: 1192.2134 - val_vae_r_loss: 1109.8553 - val_vae_kl_loss: 82.3582\n",
      "Epoch 122/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 346.6964 - vae_r_loss: 263.6855 - vae_kl_loss: 83.0112WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1163.37026\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 346.6681 - vae_r_loss: 263.6580 - vae_kl_loss: 83.0103 - val_loss: 1170.2125 - val_vae_r_loss: 1087.5668 - val_vae_kl_loss: 82.6459\n",
      "Epoch 123/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 342.8908 - vae_r_loss: 259.9496 - vae_kl_loss: 82.9414WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00123: val_loss improved from 1163.37026 to 1151.21896, saving model to vae_kdh_ckpt.123-1151.219.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 342.8728 - vae_r_loss: 259.9319 - vae_kl_loss: 82.9411 - val_loss: 1151.2190 - val_vae_r_loss: 1068.6647 - val_vae_kl_loss: 82.5544\n",
      "Epoch 124/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 338.2653 - vae_r_loss: 255.7746 - vae_kl_loss: 82.4904WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1151.21896\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.2653 - vae_r_loss: 255.7746 - vae_kl_loss: 82.4904 - val_loss: 1155.6276 - val_vae_r_loss: 1073.3344 - val_vae_kl_loss: 82.2931\n",
      "Epoch 125/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 332.3340 - vae_r_loss: 249.6426 - vae_kl_loss: 82.6914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00125: val_loss improved from 1151.21896 to 1137.89903, saving model to vae_kdh_ckpt.125-1137.899.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 332.3340 - vae_r_loss: 249.6426 - vae_kl_loss: 82.6914 - val_loss: 1137.8990 - val_vae_r_loss: 1055.8682 - val_vae_kl_loss: 82.0306\n",
      "Epoch 126/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 345.5900 - vae_r_loss: 262.6441 - vae_kl_loss: 82.9459WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00126: val_loss improved from 1137.89903 to 1136.21834, saving model to vae_kdh_ckpt.126-1136.218.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 345.5900 - vae_r_loss: 262.6441 - vae_kl_loss: 82.9459 - val_loss: 1136.2183 - val_vae_r_loss: 1053.5714 - val_vae_kl_loss: 82.6465\n",
      "Epoch 127/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 330.4568 - vae_r_loss: 248.1818 - vae_kl_loss: 82.2750WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 330.4605 - vae_r_loss: 248.1861 - vae_kl_loss: 82.2744 - val_loss: 1149.0012 - val_vae_r_loss: 1066.1682 - val_vae_kl_loss: 82.8322\n",
      "Epoch 128/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 338.8270 - vae_r_loss: 255.8878 - vae_kl_loss: 82.9389WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.7997 - vae_r_loss: 255.8610 - vae_kl_loss: 82.9385 - val_loss: 1163.8738 - val_vae_r_loss: 1080.7321 - val_vae_kl_loss: 83.1423\n",
      "Epoch 129/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 338.3228 - vae_r_loss: 255.3880 - vae_kl_loss: 82.9346WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.3300 - vae_r_loss: 255.3951 - vae_kl_loss: 82.9347 - val_loss: 1155.9757 - val_vae_r_loss: 1073.3617 - val_vae_kl_loss: 82.6141\n",
      "Epoch 130/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 343.4298 - vae_r_loss: 260.1432 - vae_kl_loss: 83.2861WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 343.4298 - vae_r_loss: 260.1432 - vae_kl_loss: 83.2861 - val_loss: 1157.8537 - val_vae_r_loss: 1075.4738 - val_vae_kl_loss: 82.3797\n",
      "Epoch 131/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 339.3225 - vae_r_loss: 256.5604 - vae_kl_loss: 82.7622WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 339.3097 - vae_r_loss: 256.5478 - vae_kl_loss: 82.7620 - val_loss: 1151.7556 - val_vae_r_loss: 1068.3113 - val_vae_kl_loss: 83.4448\n",
      "Epoch 132/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 332.7137 - vae_r_loss: 249.6924 - vae_kl_loss: 83.0215WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 332.7137 - vae_r_loss: 249.6924 - vae_kl_loss: 83.0215 - val_loss: 1161.8820 - val_vae_r_loss: 1079.3641 - val_vae_kl_loss: 82.5180\n",
      "Epoch 133/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 341.9712 - vae_r_loss: 259.1793 - vae_kl_loss: 82.7920WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 341.9712 - vae_r_loss: 259.1793 - vae_kl_loss: 82.7920 - val_loss: 1137.9309 - val_vae_r_loss: 1056.1306 - val_vae_kl_loss: 81.8020\n",
      "Epoch 134/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 344.4957 - vae_r_loss: 261.7565 - vae_kl_loss: 82.7395WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 344.6808 - vae_r_loss: 261.9404 - vae_kl_loss: 82.7407 - val_loss: 1158.9857 - val_vae_r_loss: 1076.5928 - val_vae_kl_loss: 82.3924\n",
      "Epoch 135/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 334.1663 - vae_r_loss: 251.3747 - vae_kl_loss: 82.7915WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1136.21834\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 334.1663 - vae_r_loss: 251.3747 - vae_kl_loss: 82.7915 - val_loss: 1144.1205 - val_vae_r_loss: 1061.7463 - val_vae_kl_loss: 82.3728\n",
      "Epoch 136/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 338.2935 - vae_r_loss: 255.3792 - vae_kl_loss: 82.9146WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00136: val_loss improved from 1136.21834 to 1133.79512, saving model to vae_kdh_ckpt.136-1133.795.h5\n",
      "3127/3127 [==============================] - 161s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.2935 - vae_r_loss: 255.3792 - vae_kl_loss: 82.9146 - val_loss: 1133.7951 - val_vae_r_loss: 1051.9717 - val_vae_kl_loss: 81.8235\n",
      "Epoch 137/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 334.0970 - vae_r_loss: 251.7145 - vae_kl_loss: 82.3823WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00137: val_loss improved from 1133.79512 to 1125.22493, saving model to vae_kdh_ckpt.137-1125.225.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 334.0970 - vae_r_loss: 251.7145 - vae_kl_loss: 82.3823 - val_loss: 1125.2249 - val_vae_r_loss: 1042.6027 - val_vae_kl_loss: 82.6225\n",
      "Epoch 138/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 327.1708 - vae_r_loss: 244.8839 - vae_kl_loss: 82.2871WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00138: val_loss improved from 1125.22493 to 1117.66684, saving model to vae_kdh_ckpt.138-1117.667.h5\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 327.1708 - vae_r_loss: 244.8839 - vae_kl_loss: 82.2871 - val_loss: 1117.6668 - val_vae_r_loss: 1035.4417 - val_vae_kl_loss: 82.2256\n",
      "Epoch 139/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 331.9703 - vae_r_loss: 249.3958 - vae_kl_loss: 82.5745WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1117.66684\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 331.9703 - vae_r_loss: 249.3958 - vae_kl_loss: 82.5745 - val_loss: 1134.9434 - val_vae_r_loss: 1051.8005 - val_vae_kl_loss: 83.1423\n",
      "Epoch 140/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 340.2960 - vae_r_loss: 257.5886 - vae_kl_loss: 82.7074WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00140: val_loss improved from 1117.66684 to 1116.91745, saving model to vae_kdh_ckpt.140-1116.917.h5\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 340.2960 - vae_r_loss: 257.5886 - vae_kl_loss: 82.7074 - val_loss: 1116.9175 - val_vae_r_loss: 1034.3636 - val_vae_kl_loss: 82.5540\n",
      "Epoch 141/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 335.2391 - vae_r_loss: 252.7840 - vae_kl_loss: 82.4552WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00141: val_loss improved from 1116.91745 to 1110.90759, saving model to vae_kdh_ckpt.141-1110.908.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 335.2391 - vae_r_loss: 252.7840 - vae_kl_loss: 82.4552 - val_loss: 1110.9076 - val_vae_r_loss: 1028.3943 - val_vae_kl_loss: 82.5133\n",
      "Epoch 142/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 337.7600 - vae_r_loss: 255.2573 - vae_kl_loss: 82.5030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00142: val_loss improved from 1110.90759 to 1108.17222, saving model to vae_kdh_ckpt.142-1108.172.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 337.7600 - vae_r_loss: 255.2573 - vae_kl_loss: 82.5030 - val_loss: 1108.1722 - val_vae_r_loss: 1025.3198 - val_vae_kl_loss: 82.8528\n",
      "Epoch 143/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 338.1142 - vae_r_loss: 254.9558 - vae_kl_loss: 83.1589WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1108.17222\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 338.1031 - vae_r_loss: 254.9441 - vae_kl_loss: 83.1594 - val_loss: 1136.3882 - val_vae_r_loss: 1053.1576 - val_vae_kl_loss: 83.2298\n",
      "Epoch 144/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 334.5523 - vae_r_loss: 251.5643 - vae_kl_loss: 82.9880WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00144: val_loss improved from 1108.17222 to 1107.01956, saving model to vae_kdh_ckpt.144-1107.020.h5\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 334.5865 - vae_r_loss: 251.5977 - vae_kl_loss: 82.9887 - val_loss: 1107.0196 - val_vae_r_loss: 1024.2834 - val_vae_kl_loss: 82.7365\n",
      "Epoch 145/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 327.0130 - vae_r_loss: 244.7549 - vae_kl_loss: 82.2584WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1107.01956\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 327.0130 - vae_r_loss: 244.7549 - vae_kl_loss: 82.2584 - val_loss: 1113.0201 - val_vae_r_loss: 1031.2212 - val_vae_kl_loss: 81.7987\n",
      "Epoch 146/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 329.3123 - vae_r_loss: 246.8335 - vae_kl_loss: 82.4789WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00146: val_loss improved from 1107.01956 to 1106.42100, saving model to vae_kdh_ckpt.146-1106.421.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 329.3123 - vae_r_loss: 246.8335 - vae_kl_loss: 82.4789 - val_loss: 1106.4210 - val_vae_r_loss: 1024.7860 - val_vae_kl_loss: 81.6351\n",
      "Epoch 147/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 323.1997 - vae_r_loss: 241.2097 - vae_kl_loss: 81.9902WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1106.42100\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 323.1875 - vae_r_loss: 241.1975 - vae_kl_loss: 81.9901 - val_loss: 1109.6736 - val_vae_r_loss: 1027.1025 - val_vae_kl_loss: 82.5705\n",
      "Epoch 148/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 321.7998 - vae_r_loss: 239.2728 - vae_kl_loss: 82.5268WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1106.42100\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 321.7876 - vae_r_loss: 239.2601 - vae_kl_loss: 82.5273 - val_loss: 1122.0370 - val_vae_r_loss: 1040.2574 - val_vae_kl_loss: 81.7795\n",
      "Epoch 149/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 316.2061 - vae_r_loss: 234.0376 - vae_kl_loss: 82.1682WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1106.42100\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 316.2061 - vae_r_loss: 234.0376 - vae_kl_loss: 82.1682 - val_loss: 1122.5369 - val_vae_r_loss: 1040.4464 - val_vae_kl_loss: 82.0913\n",
      "Epoch 150/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 318.1838 - vae_r_loss: 235.9100 - vae_kl_loss: 82.2737WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00150: val_loss improved from 1106.42100 to 1104.00619, saving model to vae_kdh_ckpt.150-1104.006.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 318.1838 - vae_r_loss: 235.9100 - vae_kl_loss: 82.2737 - val_loss: 1104.0062 - val_vae_r_loss: 1022.8771 - val_vae_kl_loss: 81.1284\n",
      "Epoch 151/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 320.4554 - vae_r_loss: 237.6483 - vae_kl_loss: 82.8073WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1104.00619\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 320.6151 - vae_r_loss: 237.8094 - vae_kl_loss: 82.8059 - val_loss: 1136.1029 - val_vae_r_loss: 1054.3816 - val_vae_kl_loss: 81.7202\n",
      "Epoch 152/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 315.8828 - vae_r_loss: 233.7224 - vae_kl_loss: 82.1604WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1104.00619\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 315.8896 - vae_r_loss: 233.7296 - vae_kl_loss: 82.1600 - val_loss: 1146.9413 - val_vae_r_loss: 1064.8767 - val_vae_kl_loss: 82.0641\n",
      "Epoch 153/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 316.8162 - vae_r_loss: 234.5358 - vae_kl_loss: 82.2802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1104.00619\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 316.8000 - vae_r_loss: 234.5194 - vae_kl_loss: 82.2804 - val_loss: 1133.0121 - val_vae_r_loss: 1051.4146 - val_vae_kl_loss: 81.5976\n",
      "Epoch 154/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 309.1904 - vae_r_loss: 227.1056 - vae_kl_loss: 82.0851WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00154: val_loss improved from 1104.00619 to 1097.56353, saving model to vae_kdh_ckpt.154-1097.564.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 309.1774 - vae_r_loss: 227.0933 - vae_kl_loss: 82.0844 - val_loss: 1097.5635 - val_vae_r_loss: 1015.0321 - val_vae_kl_loss: 82.5322\n",
      "Epoch 155/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 317.0460 - vae_r_loss: 234.3963 - vae_kl_loss: 82.6494WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 317.0460 - vae_r_loss: 234.3963 - vae_kl_loss: 82.6494 - val_loss: 1117.3058 - val_vae_r_loss: 1035.8606 - val_vae_kl_loss: 81.4454\n",
      "Epoch 156/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 318.9486 - vae_r_loss: 236.7644 - vae_kl_loss: 82.1840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 318.9341 - vae_r_loss: 236.7489 - vae_kl_loss: 82.1849 - val_loss: 1133.0279 - val_vae_r_loss: 1050.4453 - val_vae_kl_loss: 82.5832\n",
      "Epoch 157/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 304.8919 - vae_r_loss: 223.3810 - vae_kl_loss: 81.5108WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 304.8889 - vae_r_loss: 223.3781 - vae_kl_loss: 81.5106 - val_loss: 1122.9961 - val_vae_r_loss: 1041.3495 - val_vae_kl_loss: 81.6466\n",
      "Epoch 158/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 308.1190 - vae_r_loss: 226.4682 - vae_kl_loss: 81.6509WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 308.1190 - vae_r_loss: 226.4682 - vae_kl_loss: 81.6509 - val_loss: 1147.9548 - val_vae_r_loss: 1066.0067 - val_vae_kl_loss: 81.9488\n",
      "Epoch 159/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 316.7899 - vae_r_loss: 234.0846 - vae_kl_loss: 82.7054WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 316.7899 - vae_r_loss: 234.0846 - vae_kl_loss: 82.7054 - val_loss: 1112.4123 - val_vae_r_loss: 1031.2748 - val_vae_kl_loss: 81.1386\n",
      "Epoch 160/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 306.1157 - vae_r_loss: 224.3371 - vae_kl_loss: 81.7785WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 306.1020 - vae_r_loss: 224.3233 - vae_kl_loss: 81.7786 - val_loss: 1129.0649 - val_vae_r_loss: 1047.5112 - val_vae_kl_loss: 81.5528\n",
      "Epoch 161/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 302.5700 - vae_r_loss: 220.6747 - vae_kl_loss: 81.8952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 302.5700 - vae_r_loss: 220.6747 - vae_kl_loss: 81.8952 - val_loss: 1138.4773 - val_vae_r_loss: 1056.8231 - val_vae_kl_loss: 81.6547\n",
      "Epoch 162/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 314.1054 - vae_r_loss: 231.9824 - vae_kl_loss: 82.1233WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 314.1054 - vae_r_loss: 231.9824 - vae_kl_loss: 82.1233 - val_loss: 1125.6183 - val_vae_r_loss: 1044.0693 - val_vae_kl_loss: 81.5488\n",
      "Epoch 163/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 312.2354 - vae_r_loss: 230.1205 - vae_kl_loss: 82.1147WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 312.2354 - vae_r_loss: 230.1205 - vae_kl_loss: 82.1147 - val_loss: 1136.4110 - val_vae_r_loss: 1054.9266 - val_vae_kl_loss: 81.4844\n",
      "Epoch 164/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 308.6307 - vae_r_loss: 226.4949 - vae_kl_loss: 82.1357WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 308.6307 - vae_r_loss: 226.4949 - vae_kl_loss: 82.1357 - val_loss: 1134.2010 - val_vae_r_loss: 1053.0117 - val_vae_kl_loss: 81.1890\n",
      "Epoch 165/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 294.4848 - vae_r_loss: 213.5790 - vae_kl_loss: 80.9056WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 294.4853 - vae_r_loss: 213.5793 - vae_kl_loss: 80.9058 - val_loss: 1126.1548 - val_vae_r_loss: 1045.2372 - val_vae_kl_loss: 80.9174\n",
      "Epoch 166/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 309.1145 - vae_r_loss: 227.2574 - vae_kl_loss: 81.8569WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 309.1145 - vae_r_loss: 227.2574 - vae_kl_loss: 81.8569 - val_loss: 1124.4098 - val_vae_r_loss: 1042.6077 - val_vae_kl_loss: 81.8028\n",
      "Epoch 167/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 306.1289 - vae_r_loss: 224.2329 - vae_kl_loss: 81.8958WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 306.1289 - vae_r_loss: 224.2329 - vae_kl_loss: 81.8958 - val_loss: 1117.8626 - val_vae_r_loss: 1036.3953 - val_vae_kl_loss: 81.4666\n",
      "Epoch 168/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 305.8889 - vae_r_loss: 224.3306 - vae_kl_loss: 81.5583WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 305.8807 - vae_r_loss: 224.3222 - vae_kl_loss: 81.5585 - val_loss: 1107.6135 - val_vae_r_loss: 1026.5729 - val_vae_kl_loss: 81.0409\n",
      "Epoch 169/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 308.2701 - vae_r_loss: 226.7452 - vae_kl_loss: 81.5253WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 308.2419 - vae_r_loss: 226.7174 - vae_kl_loss: 81.5250 - val_loss: 1120.7661 - val_vae_r_loss: 1039.0695 - val_vae_kl_loss: 81.6970\n",
      "Epoch 170/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 309.9001 - vae_r_loss: 228.1120 - vae_kl_loss: 81.7881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1097.56353\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 309.8951 - vae_r_loss: 228.1066 - vae_kl_loss: 81.7885 - val_loss: 1101.9511 - val_vae_r_loss: 1020.7742 - val_vae_kl_loss: 81.1771\n",
      "Epoch 171/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 308.6266 - vae_r_loss: 226.9499 - vae_kl_loss: 81.6765WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00171: val_loss improved from 1097.56353 to 1088.48500, saving model to vae_kdh_ckpt.171-1088.485.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 308.6039 - vae_r_loss: 226.9290 - vae_kl_loss: 81.6746 - val_loss: 1088.4850 - val_vae_r_loss: 1007.1473 - val_vae_kl_loss: 81.3380\n",
      "Epoch 172/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 303.8754 - vae_r_loss: 222.8007 - vae_kl_loss: 81.0747WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00172: val_loss improved from 1088.48500 to 1086.18663, saving model to vae_kdh_ckpt.172-1086.187.h5\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 303.8754 - vae_r_loss: 222.8007 - vae_kl_loss: 81.0747 - val_loss: 1086.1866 - val_vae_r_loss: 1005.3090 - val_vae_kl_loss: 80.8780\n",
      "Epoch 173/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 300.7446 - vae_r_loss: 219.3554 - vae_kl_loss: 81.3894WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00173: val_loss improved from 1086.18663 to 1077.15704, saving model to vae_kdh_ckpt.173-1077.157.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 300.7446 - vae_r_loss: 219.3554 - vae_kl_loss: 81.3894 - val_loss: 1077.1570 - val_vae_r_loss: 996.2915 - val_vae_kl_loss: 80.8661\n",
      "Epoch 174/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 313.8545 - vae_r_loss: 232.2636 - vae_kl_loss: 81.5911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00174: val_loss improved from 1077.15704 to 1069.73215, saving model to vae_kdh_ckpt.174-1069.732.h5\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 313.8588 - vae_r_loss: 232.2679 - vae_kl_loss: 81.5910 - val_loss: 1069.7322 - val_vae_r_loss: 988.2493 - val_vae_kl_loss: 81.4825\n",
      "Epoch 175/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 298.0239 - vae_r_loss: 217.1287 - vae_kl_loss: 80.8952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 298.0239 - vae_r_loss: 217.1287 - vae_kl_loss: 80.8952 - val_loss: 1080.6110 - val_vae_r_loss: 999.6837 - val_vae_kl_loss: 80.9277\n",
      "Epoch 176/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 305.4661 - vae_r_loss: 224.0239 - vae_kl_loss: 81.4419WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 305.4661 - vae_r_loss: 224.0239 - vae_kl_loss: 81.4419 - val_loss: 1094.3962 - val_vae_r_loss: 1013.0895 - val_vae_kl_loss: 81.3066\n",
      "Epoch 177/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 301.3189 - vae_r_loss: 219.7965 - vae_kl_loss: 81.5223WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 301.3052 - vae_r_loss: 219.7815 - vae_kl_loss: 81.5235 - val_loss: 1098.9127 - val_vae_r_loss: 1017.2280 - val_vae_kl_loss: 81.6847\n",
      "Epoch 178/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 308.6709 - vae_r_loss: 226.7075 - vae_kl_loss: 81.9629WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 308.6587 - vae_r_loss: 226.6956 - vae_kl_loss: 81.9627 - val_loss: 1095.2556 - val_vae_r_loss: 1014.0836 - val_vae_kl_loss: 81.1724\n",
      "Epoch 179/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 305.7080 - vae_r_loss: 224.1958 - vae_kl_loss: 81.5124WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 305.7080 - vae_r_loss: 224.1958 - vae_kl_loss: 81.5124 - val_loss: 1092.6937 - val_vae_r_loss: 1011.2057 - val_vae_kl_loss: 81.4877\n",
      "Epoch 180/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 302.8547 - vae_r_loss: 221.2030 - vae_kl_loss: 81.6515WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 302.8547 - vae_r_loss: 221.2030 - vae_kl_loss: 81.6515 - val_loss: 1098.6089 - val_vae_r_loss: 1017.2618 - val_vae_kl_loss: 81.3466\n",
      "Epoch 181/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 305.8584 - vae_r_loss: 224.3850 - vae_kl_loss: 81.4736WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 305.8584 - vae_r_loss: 224.3850 - vae_kl_loss: 81.4736 - val_loss: 1085.1245 - val_vae_r_loss: 1004.5922 - val_vae_kl_loss: 80.5325\n",
      "Epoch 182/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 302.6253 - vae_r_loss: 221.0709 - vae_kl_loss: 81.5546WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 302.6144 - vae_r_loss: 221.0601 - vae_kl_loss: 81.5544 - val_loss: 1099.6220 - val_vae_r_loss: 1018.1298 - val_vae_kl_loss: 81.4918\n",
      "Epoch 183/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 302.0222 - vae_r_loss: 220.6011 - vae_kl_loss: 81.4211WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 302.0222 - vae_r_loss: 220.6011 - vae_kl_loss: 81.4211 - val_loss: 1089.4018 - val_vae_r_loss: 1008.1160 - val_vae_kl_loss: 81.2860\n",
      "Epoch 184/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 300.9242 - vae_r_loss: 219.4158 - vae_kl_loss: 81.5082WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1069.73215\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 300.9242 - vae_r_loss: 219.4158 - vae_kl_loss: 81.5082 - val_loss: 1082.8939 - val_vae_r_loss: 1002.1197 - val_vae_kl_loss: 80.7733\n",
      "Epoch 185/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 302.5194 - vae_r_loss: 221.4474 - vae_kl_loss: 81.0720WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00185: val_loss improved from 1069.73215 to 1069.54816, saving model to vae_kdh_ckpt.185-1069.548.h5\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 302.5275 - vae_r_loss: 221.4546 - vae_kl_loss: 81.0730 - val_loss: 1069.5482 - val_vae_r_loss: 988.6031 - val_vae_kl_loss: 80.9448\n",
      "Epoch 186/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 296.9331 - vae_r_loss: 216.0119 - vae_kl_loss: 80.9213WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00186: val_loss improved from 1069.54816 to 1063.25578, saving model to vae_kdh_ckpt.186-1063.256.h5\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 296.9125 - vae_r_loss: 215.9917 - vae_kl_loss: 80.9210 - val_loss: 1063.2558 - val_vae_r_loss: 982.0925 - val_vae_kl_loss: 81.1635\n",
      "Epoch 187/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 303.3058 - vae_r_loss: 222.1921 - vae_kl_loss: 81.1136WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 303.3058 - vae_r_loss: 222.1921 - vae_kl_loss: 81.1136 - val_loss: 1080.7647 - val_vae_r_loss: 999.4785 - val_vae_kl_loss: 81.2867\n",
      "Epoch 188/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 306.8559 - vae_r_loss: 225.6562 - vae_kl_loss: 81.2000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 306.8559 - vae_r_loss: 225.6562 - vae_kl_loss: 81.2000 - val_loss: 1070.8456 - val_vae_r_loss: 990.1886 - val_vae_kl_loss: 80.6565\n",
      "Epoch 189/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 303.6522 - vae_r_loss: 222.6886 - vae_kl_loss: 80.9633WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 303.6324 - vae_r_loss: 222.6693 - vae_kl_loss: 80.9628 - val_loss: 1069.5916 - val_vae_r_loss: 988.8253 - val_vae_kl_loss: 80.7661\n",
      "Epoch 190/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 304.8592 - vae_r_loss: 223.8446 - vae_kl_loss: 81.0146WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 304.8592 - vae_r_loss: 223.8446 - vae_kl_loss: 81.0146 - val_loss: 1064.1261 - val_vae_r_loss: 982.5632 - val_vae_kl_loss: 81.5631\n",
      "Epoch 191/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 305.4394 - vae_r_loss: 223.8174 - vae_kl_loss: 81.6221WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 162s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 305.4158 - vae_r_loss: 223.7951 - vae_kl_loss: 81.6207 - val_loss: 1092.2716 - val_vae_r_loss: 1010.8563 - val_vae_kl_loss: 81.4158\n",
      "Epoch 192/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 297.7571 - vae_r_loss: 216.3481 - vae_kl_loss: 81.4089WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 297.7571 - vae_r_loss: 216.3481 - vae_kl_loss: 81.4089 - val_loss: 1065.3164 - val_vae_r_loss: 984.3521 - val_vae_kl_loss: 80.9638\n",
      "Epoch 193/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 294.6550 - vae_r_loss: 213.8006 - vae_kl_loss: 80.8542WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 294.6550 - vae_r_loss: 213.8006 - vae_kl_loss: 80.8542 - val_loss: 1069.3392 - val_vae_r_loss: 988.5333 - val_vae_kl_loss: 80.8074\n",
      "Epoch 194/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 295.7868 - vae_r_loss: 214.8141 - vae_kl_loss: 80.9727WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 295.7868 - vae_r_loss: 214.8141 - vae_kl_loss: 80.9727 - val_loss: 1067.6017 - val_vae_r_loss: 987.0127 - val_vae_kl_loss: 80.5891\n",
      "Epoch 195/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 292.4343 - vae_r_loss: 211.9526 - vae_kl_loss: 80.4816WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.4208 - vae_r_loss: 211.9393 - vae_kl_loss: 80.4813 - val_loss: 1064.2460 - val_vae_r_loss: 983.2744 - val_vae_kl_loss: 80.9709\n",
      "Epoch 196/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 292.2327 - vae_r_loss: 211.2924 - vae_kl_loss: 80.9403WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.2327 - vae_r_loss: 211.2924 - vae_kl_loss: 80.9403 - val_loss: 1079.7309 - val_vae_r_loss: 999.7480 - val_vae_kl_loss: 79.9820\n",
      "Epoch 197/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 289.8610 - vae_r_loss: 209.4102 - vae_kl_loss: 80.4506WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1063.25578\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 289.8353 - vae_r_loss: 209.3851 - vae_kl_loss: 80.4499 - val_loss: 1077.7034 - val_vae_r_loss: 997.3442 - val_vae_kl_loss: 80.3585\n",
      "Epoch 198/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 292.6415 - vae_r_loss: 211.9931 - vae_kl_loss: 80.6482WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00198: val_loss improved from 1063.25578 to 1061.20824, saving model to vae_kdh_ckpt.198-1061.208.h5\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.6415 - vae_r_loss: 211.9931 - vae_kl_loss: 80.6482 - val_loss: 1061.2082 - val_vae_r_loss: 981.4789 - val_vae_kl_loss: 79.7293\n",
      "Epoch 199/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 291.1668 - vae_r_loss: 210.0400 - vae_kl_loss: 81.1269WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1061.20824\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 291.1519 - vae_r_loss: 210.0258 - vae_kl_loss: 81.1262 - val_loss: 1098.5956 - val_vae_r_loss: 1018.2823 - val_vae_kl_loss: 80.3133\n",
      "Epoch 200/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 289.6922 - vae_r_loss: 209.1452 - vae_kl_loss: 80.5470WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1061.20824\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 289.6922 - vae_r_loss: 209.1452 - vae_kl_loss: 80.5470 - val_loss: 1091.6485 - val_vae_r_loss: 1011.0666 - val_vae_kl_loss: 80.5822\n",
      "Epoch 201/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 291.2451 - vae_r_loss: 210.7496 - vae_kl_loss: 80.4956WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1061.20824\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 291.2257 - vae_r_loss: 210.7303 - vae_kl_loss: 80.4954 - val_loss: 1084.3222 - val_vae_r_loss: 1003.9802 - val_vae_kl_loss: 80.3428\n",
      "Epoch 202/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 283.7459 - vae_r_loss: 203.1559 - vae_kl_loss: 80.5900WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00202: val_loss improved from 1061.20824 to 1058.04063, saving model to vae_kdh_ckpt.202-1058.041.h5\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.7664 - vae_r_loss: 203.1754 - vae_kl_loss: 80.5910 - val_loss: 1058.0406 - val_vae_r_loss: 977.2614 - val_vae_kl_loss: 80.7786\n",
      "Epoch 203/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 290.3581 - vae_r_loss: 209.2213 - vae_kl_loss: 81.1371WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 166s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 290.3764 - vae_r_loss: 209.2408 - vae_kl_loss: 81.1359 - val_loss: 1079.3218 - val_vae_r_loss: 998.9335 - val_vae_kl_loss: 80.3887\n",
      "Epoch 204/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 292.6882 - vae_r_loss: 211.9401 - vae_kl_loss: 80.7478WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 166s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.6882 - vae_r_loss: 211.9401 - vae_kl_loss: 80.7478 - val_loss: 1093.9248 - val_vae_r_loss: 1013.0323 - val_vae_kl_loss: 80.8929\n",
      "Epoch 205/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 280.8310 - vae_r_loss: 200.8669 - vae_kl_loss: 79.9640WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 280.8083 - vae_r_loss: 200.8449 - vae_kl_loss: 79.9633 - val_loss: 1080.3178 - val_vae_r_loss: 1000.3095 - val_vae_kl_loss: 80.0086\n",
      "Epoch 206/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 283.0888 - vae_r_loss: 202.8963 - vae_kl_loss: 80.1924WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.0874 - vae_r_loss: 202.8945 - vae_kl_loss: 80.1929 - val_loss: 1099.4276 - val_vae_r_loss: 1019.2491 - val_vae_kl_loss: 80.1785\n",
      "Epoch 207/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 291.8763 - vae_r_loss: 210.7234 - vae_kl_loss: 81.1529WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 170s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 291.8611 - vae_r_loss: 210.7087 - vae_kl_loss: 81.1525 - val_loss: 1074.4502 - val_vae_r_loss: 994.5112 - val_vae_kl_loss: 79.9379\n",
      "Epoch 208/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 285.2754 - vae_r_loss: 205.0070 - vae_kl_loss: 80.2683WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 285.2754 - vae_r_loss: 205.0070 - vae_kl_loss: 80.2683 - val_loss: 1088.3963 - val_vae_r_loss: 1008.4265 - val_vae_kl_loss: 79.9696\n",
      "Epoch 209/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 281.6187 - vae_r_loss: 201.3932 - vae_kl_loss: 80.2256WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 281.6187 - vae_r_loss: 201.3932 - vae_kl_loss: 80.2256 - val_loss: 1094.7307 - val_vae_r_loss: 1014.9548 - val_vae_kl_loss: 79.7763\n",
      "Epoch 210/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 292.4822 - vae_r_loss: 212.0113 - vae_kl_loss: 80.4712WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.4822 - vae_r_loss: 212.0113 - vae_kl_loss: 80.4712 - val_loss: 1088.6222 - val_vae_r_loss: 1009.0608 - val_vae_kl_loss: 79.5606\n",
      "Epoch 211/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 292.7978 - vae_r_loss: 212.3115 - vae_kl_loss: 80.4864WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 292.7892 - vae_r_loss: 212.3016 - vae_kl_loss: 80.4877 - val_loss: 1092.2741 - val_vae_r_loss: 1012.4295 - val_vae_kl_loss: 79.8451\n",
      "Epoch 212/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 286.1969 - vae_r_loss: 205.7040 - vae_kl_loss: 80.4928WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 286.2058 - vae_r_loss: 205.7132 - vae_kl_loss: 80.4924 - val_loss: 1090.3582 - val_vae_r_loss: 1011.1902 - val_vae_kl_loss: 79.1669\n",
      "Epoch 213/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 275.4093 - vae_r_loss: 196.0394 - vae_kl_loss: 79.3700WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 275.4093 - vae_r_loss: 196.0394 - vae_kl_loss: 79.3700 - val_loss: 1075.6745 - val_vae_r_loss: 995.8838 - val_vae_kl_loss: 79.7902\n",
      "Epoch 214/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 286.0694 - vae_r_loss: 205.7678 - vae_kl_loss: 80.3016WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 286.0432 - vae_r_loss: 205.7419 - vae_kl_loss: 80.3013 - val_loss: 1081.0509 - val_vae_r_loss: 1000.7147 - val_vae_kl_loss: 80.3360\n",
      "Epoch 215/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 282.3027 - vae_r_loss: 201.9475 - vae_kl_loss: 80.3551WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.3027 - vae_r_loss: 201.9475 - vae_kl_loss: 80.3551 - val_loss: 1076.7147 - val_vae_r_loss: 996.4241 - val_vae_kl_loss: 80.2898\n",
      "Epoch 216/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 281.5134 - vae_r_loss: 201.4486 - vae_kl_loss: 80.0645WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 281.4952 - vae_r_loss: 201.4294 - vae_kl_loss: 80.0654 - val_loss: 1064.6332 - val_vae_r_loss: 985.0429 - val_vae_kl_loss: 79.5895\n",
      "Epoch 217/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 284.8240 - vae_r_loss: 204.7552 - vae_kl_loss: 80.0689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.8240 - vae_r_loss: 204.7552 - vae_kl_loss: 80.0689 - val_loss: 1081.3362 - val_vae_r_loss: 1001.3974 - val_vae_kl_loss: 79.9386\n",
      "Epoch 218/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 284.3886 - vae_r_loss: 204.0337 - vae_kl_loss: 80.3548WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1058.04063\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.3886 - vae_r_loss: 204.0337 - vae_kl_loss: 80.3548 - val_loss: 1061.4044 - val_vae_r_loss: 981.8243 - val_vae_kl_loss: 79.5797\n",
      "Epoch 219/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 287.2667 - vae_r_loss: 207.0131 - vae_kl_loss: 80.2537WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00219: val_loss improved from 1058.04063 to 1046.95991, saving model to vae_kdh_ckpt.219-1046.960.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 287.2490 - vae_r_loss: 206.9961 - vae_kl_loss: 80.2529 - val_loss: 1046.9599 - val_vae_r_loss: 967.6314 - val_vae_kl_loss: 79.3288\n",
      "Epoch 220/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 284.0781 - vae_r_loss: 204.5219 - vae_kl_loss: 79.5561WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1046.95991\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.0635 - vae_r_loss: 204.5064 - vae_kl_loss: 79.5569 - val_loss: 1047.6128 - val_vae_r_loss: 968.2261 - val_vae_kl_loss: 79.3859\n",
      "Epoch 221/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 281.2024 - vae_r_loss: 201.2937 - vae_kl_loss: 79.9088WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00221: val_loss improved from 1046.95991 to 1039.90798, saving model to vae_kdh_ckpt.221-1039.908.h5\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 281.1883 - vae_r_loss: 201.2798 - vae_kl_loss: 79.9085 - val_loss: 1039.9080 - val_vae_r_loss: 960.6234 - val_vae_kl_loss: 79.2834\n",
      "Epoch 222/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 291.5118 - vae_r_loss: 211.4347 - vae_kl_loss: 80.0772WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00222: val_loss improved from 1039.90798 to 1031.48083, saving model to vae_kdh_ckpt.222-1031.481.h5\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 291.4971 - vae_r_loss: 211.4197 - vae_kl_loss: 80.0775 - val_loss: 1031.4808 - val_vae_r_loss: 951.5703 - val_vae_kl_loss: 79.9108\n",
      "Epoch 223/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 276.7772 - vae_r_loss: 197.3926 - vae_kl_loss: 79.3845WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.7772 - vae_r_loss: 197.3926 - vae_kl_loss: 79.3845 - val_loss: 1044.7549 - val_vae_r_loss: 965.4055 - val_vae_kl_loss: 79.3491\n",
      "Epoch 224/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 284.3841 - vae_r_loss: 204.3400 - vae_kl_loss: 80.0442WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.3700 - vae_r_loss: 204.3269 - vae_kl_loss: 80.0432 - val_loss: 1057.6855 - val_vae_r_loss: 977.5311 - val_vae_kl_loss: 80.1537\n",
      "Epoch 225/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 281.2490 - vae_r_loss: 201.2539 - vae_kl_loss: 79.9952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 281.2266 - vae_r_loss: 201.2318 - vae_kl_loss: 79.9950 - val_loss: 1058.1420 - val_vae_r_loss: 978.3775 - val_vae_kl_loss: 79.7647\n",
      "Epoch 226/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 287.1667 - vae_r_loss: 206.5750 - vae_kl_loss: 80.5914WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 287.1463 - vae_r_loss: 206.5561 - vae_kl_loss: 80.5900 - val_loss: 1051.4751 - val_vae_r_loss: 971.5366 - val_vae_kl_loss: 79.9385\n",
      "Epoch 227/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 283.0212 - vae_r_loss: 202.8421 - vae_kl_loss: 80.1792WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.0212 - vae_r_loss: 202.8421 - vae_kl_loss: 80.1792 - val_loss: 1059.4895 - val_vae_r_loss: 979.8288 - val_vae_kl_loss: 79.6612\n",
      "Epoch 228/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 282.4277 - vae_r_loss: 202.1152 - vae_kl_loss: 80.3126WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.4309 - vae_r_loss: 202.1184 - vae_kl_loss: 80.3126 - val_loss: 1062.3496 - val_vae_r_loss: 982.6769 - val_vae_kl_loss: 79.6721\n",
      "Epoch 229/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 282.0075 - vae_r_loss: 201.8989 - vae_kl_loss: 80.1087WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.0371 - vae_r_loss: 201.9284 - vae_kl_loss: 80.1088 - val_loss: 1055.7952 - val_vae_r_loss: 976.3644 - val_vae_kl_loss: 79.4305\n",
      "Epoch 230/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 283.1965 - vae_r_loss: 202.8498 - vae_kl_loss: 80.3465WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.1965 - vae_r_loss: 202.8498 - vae_kl_loss: 80.3465 - val_loss: 1067.0547 - val_vae_r_loss: 987.2691 - val_vae_kl_loss: 79.7857\n",
      "Epoch 231/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 282.1889 - vae_r_loss: 202.2036 - vae_kl_loss: 79.9852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.1889 - vae_r_loss: 202.2036 - vae_kl_loss: 79.9852 - val_loss: 1057.9466 - val_vae_r_loss: 977.9661 - val_vae_kl_loss: 79.9804\n",
      "Epoch 232/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 282.8758 - vae_r_loss: 202.7899 - vae_kl_loss: 80.0854WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.8703 - vae_r_loss: 202.7840 - vae_kl_loss: 80.0860 - val_loss: 1047.4279 - val_vae_r_loss: 967.5656 - val_vae_kl_loss: 79.8626\n",
      "Epoch 233/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 282.8018 - vae_r_loss: 203.1017 - vae_kl_loss: 79.7005WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 282.8018 - vae_r_loss: 203.1017 - vae_kl_loss: 79.7005 - val_loss: 1033.8477 - val_vae_r_loss: 954.2292 - val_vae_kl_loss: 79.6182\n",
      "Epoch 234/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 278.4705 - vae_r_loss: 198.9831 - vae_kl_loss: 79.4872WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 278.4705 - vae_r_loss: 198.9831 - vae_kl_loss: 79.4872 - val_loss: 1031.5420 - val_vae_r_loss: 951.6995 - val_vae_kl_loss: 79.8423\n",
      "Epoch 235/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 283.5789 - vae_r_loss: 203.7831 - vae_kl_loss: 79.7961WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.5727 - vae_r_loss: 203.7778 - vae_kl_loss: 79.7951 - val_loss: 1042.9815 - val_vae_r_loss: 963.3661 - val_vae_kl_loss: 79.6162\n",
      "Epoch 236/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 284.8214 - vae_r_loss: 204.8905 - vae_kl_loss: 79.9309WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.8129 - vae_r_loss: 204.8811 - vae_kl_loss: 79.9318 - val_loss: 1040.7118 - val_vae_r_loss: 960.9208 - val_vae_kl_loss: 79.7921\n",
      "Epoch 237/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 283.7565 - vae_r_loss: 204.1853 - vae_kl_loss: 79.5713WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 283.7565 - vae_r_loss: 204.1853 - vae_kl_loss: 79.5713 - val_loss: 1037.4001 - val_vae_r_loss: 957.7130 - val_vae_kl_loss: 79.6870\n",
      "Epoch 238/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 285.5124 - vae_r_loss: 205.7690 - vae_kl_loss: 79.7433WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 285.4931 - vae_r_loss: 205.7497 - vae_kl_loss: 79.7433 - val_loss: 1034.8019 - val_vae_r_loss: 954.8165 - val_vae_kl_loss: 79.9852\n",
      "Epoch 239/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 284.7939 - vae_r_loss: 204.4901 - vae_kl_loss: 80.3040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 284.7766 - vae_r_loss: 204.4737 - vae_kl_loss: 80.3032 - val_loss: 1057.3707 - val_vae_r_loss: 977.2866 - val_vae_kl_loss: 80.0843\n",
      "Epoch 240/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 280.3269 - vae_r_loss: 200.2225 - vae_kl_loss: 80.1045WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 280.3269 - vae_r_loss: 200.2225 - vae_kl_loss: 80.1045 - val_loss: 1035.3199 - val_vae_r_loss: 955.4929 - val_vae_kl_loss: 79.8279\n",
      "Epoch 241/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 276.8378 - vae_r_loss: 197.1465 - vae_kl_loss: 79.6912WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.8278 - vae_r_loss: 197.1358 - vae_kl_loss: 79.6919 - val_loss: 1034.2430 - val_vae_r_loss: 954.8470 - val_vae_kl_loss: 79.3954\n",
      "Epoch 242/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 281.3237 - vae_r_loss: 201.7016 - vae_kl_loss: 79.6221WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1031.48083\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 281.3237 - vae_r_loss: 201.7016 - vae_kl_loss: 79.6221 - val_loss: 1040.7229 - val_vae_r_loss: 961.3423 - val_vae_kl_loss: 79.3806\n",
      "Epoch 243/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 275.7628 - vae_r_loss: 196.4431 - vae_kl_loss: 79.3197WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00243: val_loss improved from 1031.48083 to 1030.37444, saving model to vae_kdh_ckpt.243-1030.374.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 275.7628 - vae_r_loss: 196.4431 - vae_kl_loss: 79.3197 - val_loss: 1030.3744 - val_vae_r_loss: 950.3727 - val_vae_kl_loss: 80.0013\n",
      "Epoch 244/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 277.6688 - vae_r_loss: 197.9992 - vae_kl_loss: 79.6697WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1030.37444\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 277.6688 - vae_r_loss: 197.9992 - vae_kl_loss: 79.6697 - val_loss: 1041.7837 - val_vae_r_loss: 962.7366 - val_vae_kl_loss: 79.0472\n",
      "Epoch 245/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 273.1533 - vae_r_loss: 194.0188 - vae_kl_loss: 79.1346WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1030.37444\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 273.1475 - vae_r_loss: 194.0112 - vae_kl_loss: 79.1364 - val_loss: 1039.8894 - val_vae_r_loss: 960.6139 - val_vae_kl_loss: 79.2771\n",
      "Epoch 246/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 276.8953 - vae_r_loss: 197.4447 - vae_kl_loss: 79.4506WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00246: val_loss improved from 1030.37444 to 1029.24758, saving model to vae_kdh_ckpt.246-1029.248.h5\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.8859 - vae_r_loss: 197.4352 - vae_kl_loss: 79.4508 - val_loss: 1029.2476 - val_vae_r_loss: 950.1269 - val_vae_kl_loss: 79.1203\n",
      "Epoch 247/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 277.7237 - vae_r_loss: 197.8505 - vae_kl_loss: 79.8732WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 277.7086 - vae_r_loss: 197.8361 - vae_kl_loss: 79.8725 - val_loss: 1061.3427 - val_vae_r_loss: 981.8104 - val_vae_kl_loss: 79.5320\n",
      "Epoch 248/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 276.2856 - vae_r_loss: 196.9975 - vae_kl_loss: 79.2884WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.2856 - vae_r_loss: 196.9975 - vae_kl_loss: 79.2884 - val_loss: 1068.4778 - val_vae_r_loss: 989.0331 - val_vae_kl_loss: 79.4451\n",
      "Epoch 249/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 279.3302 - vae_r_loss: 200.0836 - vae_kl_loss: 79.2464WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 279.3302 - vae_r_loss: 200.0836 - vae_kl_loss: 79.2464 - val_loss: 1049.0468 - val_vae_r_loss: 969.9961 - val_vae_kl_loss: 79.0503\n",
      "Epoch 250/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 270.0977 - vae_r_loss: 190.7295 - vae_kl_loss: 79.3683WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 270.0880 - vae_r_loss: 190.7205 - vae_kl_loss: 79.3677 - val_loss: 1034.0924 - val_vae_r_loss: 954.5325 - val_vae_kl_loss: 79.5596\n",
      "Epoch 251/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 276.3355 - vae_r_loss: 196.4758 - vae_kl_loss: 79.8597WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.3355 - vae_r_loss: 196.4758 - vae_kl_loss: 79.8597 - val_loss: 1054.2513 - val_vae_r_loss: 975.4069 - val_vae_kl_loss: 78.8444\n",
      "Epoch 252/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 276.9338 - vae_r_loss: 197.4011 - vae_kl_loss: 79.5327WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 276.9366 - vae_r_loss: 197.4036 - vae_kl_loss: 79.5330 - val_loss: 1062.8553 - val_vae_r_loss: 983.3091 - val_vae_kl_loss: 79.5464\n",
      "Epoch 253/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 267.6557 - vae_r_loss: 188.9411 - vae_kl_loss: 78.7145WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.6557 - vae_r_loss: 188.9411 - vae_kl_loss: 78.7145 - val_loss: 1040.6380 - val_vae_r_loss: 961.7161 - val_vae_kl_loss: 78.9222\n",
      "Epoch 254/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 268.9868 - vae_r_loss: 189.9751 - vae_kl_loss: 79.0121WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 269.0681 - vae_r_loss: 190.0563 - vae_kl_loss: 79.0121 - val_loss: 1058.1484 - val_vae_r_loss: 979.2906 - val_vae_kl_loss: 78.8575\n",
      "Epoch 255/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 277.3405 - vae_r_loss: 197.3999 - vae_kl_loss: 79.9408WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 277.3405 - vae_r_loss: 197.3999 - vae_kl_loss: 79.9408 - val_loss: 1039.2449 - val_vae_r_loss: 960.8284 - val_vae_kl_loss: 78.4161\n",
      "Epoch 256/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 271.3481 - vae_r_loss: 192.2729 - vae_kl_loss: 79.0751WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 271.3481 - vae_r_loss: 192.2729 - vae_kl_loss: 79.0751 - val_loss: 1053.5857 - val_vae_r_loss: 974.4316 - val_vae_kl_loss: 79.1542\n",
      "Epoch 257/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 267.6341 - vae_r_loss: 188.5677 - vae_kl_loss: 79.0665WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.6508 - vae_r_loss: 188.5846 - vae_kl_loss: 79.0663 - val_loss: 1055.0571 - val_vae_r_loss: 976.6404 - val_vae_kl_loss: 78.4173\n",
      "Epoch 258/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 273.6147 - vae_r_loss: 194.2995 - vae_kl_loss: 79.3155WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 273.6147 - vae_r_loss: 194.2995 - vae_kl_loss: 79.3155 - val_loss: 1053.8442 - val_vae_r_loss: 975.3154 - val_vae_kl_loss: 78.5283\n",
      "Epoch 259/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 274.1488 - vae_r_loss: 194.6369 - vae_kl_loss: 79.5119WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 274.1488 - vae_r_loss: 194.6369 - vae_kl_loss: 79.5119 - val_loss: 1053.5325 - val_vae_r_loss: 974.5001 - val_vae_kl_loss: 79.0330\n",
      "Epoch 260/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 273.1380 - vae_r_loss: 193.8352 - vae_kl_loss: 79.3027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 273.1380 - vae_r_loss: 193.8352 - vae_kl_loss: 79.3027 - val_loss: 1055.8572 - val_vae_r_loss: 977.0683 - val_vae_kl_loss: 78.7882\n",
      "Epoch 261/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 262.7759 - vae_r_loss: 184.5737 - vae_kl_loss: 78.2021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.7759 - vae_r_loss: 184.5737 - vae_kl_loss: 78.2021 - val_loss: 1046.3788 - val_vae_r_loss: 968.1225 - val_vae_kl_loss: 78.2566\n",
      "Epoch 262/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 271.3907 - vae_r_loss: 192.3013 - vae_kl_loss: 79.0892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 271.3793 - vae_r_loss: 192.2904 - vae_kl_loss: 79.0888 - val_loss: 1043.0192 - val_vae_r_loss: 964.1781 - val_vae_kl_loss: 78.8397\n",
      "Epoch 263/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 268.8194 - vae_r_loss: 189.6568 - vae_kl_loss: 79.1626WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 268.8052 - vae_r_loss: 189.6438 - vae_kl_loss: 79.1614 - val_loss: 1046.1961 - val_vae_r_loss: 967.2141 - val_vae_kl_loss: 78.9811\n",
      "Epoch 264/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 267.7727 - vae_r_loss: 188.9086 - vae_kl_loss: 78.8641WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.7727 - vae_r_loss: 188.9086 - vae_kl_loss: 78.8641 - val_loss: 1033.7274 - val_vae_r_loss: 955.5281 - val_vae_kl_loss: 78.1986\n",
      "Epoch 265/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 269.1441 - vae_r_loss: 190.2384 - vae_kl_loss: 78.9058WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 269.1262 - vae_r_loss: 190.2202 - vae_kl_loss: 78.9060 - val_loss: 1052.4346 - val_vae_r_loss: 973.9067 - val_vae_kl_loss: 78.5289\n",
      "Epoch 266/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 268.5141 - vae_r_loss: 189.3609 - vae_kl_loss: 79.1532WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 268.5141 - vae_r_loss: 189.3609 - vae_kl_loss: 79.1532 - val_loss: 1036.8663 - val_vae_r_loss: 958.2397 - val_vae_kl_loss: 78.6268\n",
      "Epoch 267/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 272.0867 - vae_r_loss: 192.9405 - vae_kl_loss: 79.1461WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1029.24758\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 272.0728 - vae_r_loss: 192.9268 - vae_kl_loss: 79.1458 - val_loss: 1032.7550 - val_vae_r_loss: 954.6647 - val_vae_kl_loss: 78.0903\n",
      "Epoch 268/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 267.1259 - vae_r_loss: 188.7217 - vae_kl_loss: 78.4042WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00268: val_loss improved from 1029.24758 to 1022.37715, saving model to vae_kdh_ckpt.268-1022.377.h5\n",
      "3127/3127 [==============================] - 166s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.1130 - vae_r_loss: 188.7081 - vae_kl_loss: 78.4050 - val_loss: 1022.3771 - val_vae_r_loss: 944.1322 - val_vae_kl_loss: 78.2453\n",
      "Epoch 269/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 266.3084 - vae_r_loss: 187.5453 - vae_kl_loss: 78.7631WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00269: val_loss improved from 1022.37715 to 1016.59719, saving model to vae_kdh_ckpt.269-1016.597.h5\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.3084 - vae_r_loss: 187.5453 - vae_kl_loss: 78.7631 - val_loss: 1016.5972 - val_vae_r_loss: 938.3474 - val_vae_kl_loss: 78.2486\n",
      "Epoch 270/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 275.4481 - vae_r_loss: 196.4071 - vae_kl_loss: 79.0407WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00270: val_loss improved from 1016.59719 to 1013.03861, saving model to vae_kdh_ckpt.270-1013.039.h5\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 275.4481 - vae_r_loss: 196.4071 - vae_kl_loss: 79.0407 - val_loss: 1013.0386 - val_vae_r_loss: 933.6107 - val_vae_kl_loss: 79.4279\n",
      "Epoch 271/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 262.2838 - vae_r_loss: 184.0379 - vae_kl_loss: 78.2460WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.2838 - vae_r_loss: 184.0379 - vae_kl_loss: 78.2460 - val_loss: 1019.3975 - val_vae_r_loss: 940.3241 - val_vae_kl_loss: 79.0738\n",
      "Epoch 272/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 268.7206 - vae_r_loss: 189.9645 - vae_kl_loss: 78.7560WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 268.7058 - vae_r_loss: 189.9502 - vae_kl_loss: 78.7556 - val_loss: 1029.2889 - val_vae_r_loss: 950.2527 - val_vae_kl_loss: 79.0367\n",
      "Epoch 273/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 266.6190 - vae_r_loss: 187.8139 - vae_kl_loss: 78.8055WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.6190 - vae_r_loss: 187.8139 - vae_kl_loss: 78.8055 - val_loss: 1033.5288 - val_vae_r_loss: 955.1607 - val_vae_kl_loss: 78.3676\n",
      "Epoch 274/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 272.2179 - vae_r_loss: 192.8242 - vae_kl_loss: 79.3937WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 272.2179 - vae_r_loss: 192.8242 - vae_kl_loss: 79.3937 - val_loss: 1018.2182 - val_vae_r_loss: 939.5435 - val_vae_kl_loss: 78.6749\n",
      "Epoch 275/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 267.7232 - vae_r_loss: 188.7492 - vae_kl_loss: 78.9737WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.7232 - vae_r_loss: 188.7492 - vae_kl_loss: 78.9737 - val_loss: 1029.8519 - val_vae_r_loss: 951.0345 - val_vae_kl_loss: 78.8180\n",
      "Epoch 276/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 268.6849 - vae_r_loss: 189.6300 - vae_kl_loss: 79.0550WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 268.6849 - vae_r_loss: 189.6300 - vae_kl_loss: 79.0550 - val_loss: 1030.4734 - val_vae_r_loss: 951.9070 - val_vae_kl_loss: 78.5661\n",
      "Epoch 277/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 266.6421 - vae_r_loss: 187.8036 - vae_kl_loss: 78.8386WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.6441 - vae_r_loss: 187.8047 - vae_kl_loss: 78.8394 - val_loss: 1027.2796 - val_vae_r_loss: 949.0667 - val_vae_kl_loss: 78.2127\n",
      "Epoch 278/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 267.5092 - vae_r_loss: 188.3843 - vae_kl_loss: 79.1251WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.4969 - vae_r_loss: 188.3721 - vae_kl_loss: 79.1250 - val_loss: 1043.1888 - val_vae_r_loss: 964.3747 - val_vae_kl_loss: 78.8145\n",
      "Epoch 279/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 264.7029 - vae_r_loss: 186.0560 - vae_kl_loss: 78.6468WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 264.6851 - vae_r_loss: 186.0392 - vae_kl_loss: 78.6459 - val_loss: 1028.8750 - val_vae_r_loss: 950.4009 - val_vae_kl_loss: 78.4743\n",
      "Epoch 280/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 266.4681 - vae_r_loss: 187.6653 - vae_kl_loss: 78.8030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1013.03861\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.4865 - vae_r_loss: 187.6831 - vae_kl_loss: 78.8036 - val_loss: 1021.8044 - val_vae_r_loss: 943.4454 - val_vae_kl_loss: 78.3596\n",
      "Epoch 281/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 266.1462 - vae_r_loss: 187.7515 - vae_kl_loss: 78.3946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00281: val_loss improved from 1013.03861 to 1008.49227, saving model to vae_kdh_ckpt.281-1008.492.h5\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.1462 - vae_r_loss: 187.7515 - vae_kl_loss: 78.3946 - val_loss: 1008.4923 - val_vae_r_loss: 929.6489 - val_vae_kl_loss: 78.8440\n",
      "Epoch 282/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 262.2237 - vae_r_loss: 184.0300 - vae_kl_loss: 78.1936WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1008.49227\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.2237 - vae_r_loss: 184.0300 - vae_kl_loss: 78.1936 - val_loss: 1010.5868 - val_vae_r_loss: 932.1068 - val_vae_kl_loss: 78.4802\n",
      "Epoch 283/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 267.7335 - vae_r_loss: 189.2682 - vae_kl_loss: 78.4653WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1008.49227\n",
      "3127/3127 [==============================] - 174s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.7335 - vae_r_loss: 189.2682 - vae_kl_loss: 78.4653 - val_loss: 1022.6917 - val_vae_r_loss: 944.1270 - val_vae_kl_loss: 78.5639\n",
      "Epoch 284/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 267.9929 - vae_r_loss: 189.3487 - vae_kl_loss: 78.6446WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1008.49227\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 267.9800 - vae_r_loss: 189.3359 - vae_kl_loss: 78.6445 - val_loss: 1026.3572 - val_vae_r_loss: 947.6254 - val_vae_kl_loss: 78.7326\n",
      "Epoch 285/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 269.8544 - vae_r_loss: 191.6711 - vae_kl_loss: 78.1833WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1008.49227\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 269.8544 - vae_r_loss: 191.6711 - vae_kl_loss: 78.1833 - val_loss: 1015.0983 - val_vae_r_loss: 937.0903 - val_vae_kl_loss: 78.0077\n",
      "Epoch 286/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 269.2128 - vae_r_loss: 190.7341 - vae_kl_loss: 78.4791WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00286: val_loss improved from 1008.49227 to 1006.14526, saving model to vae_kdh_ckpt.286-1006.145.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 269.1883 - vae_r_loss: 190.7110 - vae_kl_loss: 78.4777 - val_loss: 1006.1453 - val_vae_r_loss: 927.5721 - val_vae_kl_loss: 78.5731\n",
      "Epoch 287/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 270.3052 - vae_r_loss: 191.2934 - vae_kl_loss: 79.0118WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 270.3052 - vae_r_loss: 191.2934 - vae_kl_loss: 79.0118 - val_loss: 1023.7201 - val_vae_r_loss: 945.1465 - val_vae_kl_loss: 78.5741\n",
      "Epoch 288/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 264.6507 - vae_r_loss: 185.9178 - vae_kl_loss: 78.7330WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 264.6382 - vae_r_loss: 185.9054 - vae_kl_loss: 78.7328 - val_loss: 1016.2260 - val_vae_r_loss: 937.8768 - val_vae_kl_loss: 78.3492\n",
      "Epoch 289/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 262.9430 - vae_r_loss: 184.6513 - vae_kl_loss: 78.2916WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.9430 - vae_r_loss: 184.6513 - vae_kl_loss: 78.2916 - val_loss: 1014.7200 - val_vae_r_loss: 936.4460 - val_vae_kl_loss: 78.2743\n",
      "Epoch 290/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 266.8692 - vae_r_loss: 188.4867 - vae_kl_loss: 78.3824WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.8654 - vae_r_loss: 188.4823 - vae_kl_loss: 78.3829 - val_loss: 1018.0137 - val_vae_r_loss: 939.5545 - val_vae_kl_loss: 78.4587\n",
      "Epoch 291/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 260.7241 - vae_r_loss: 182.7684 - vae_kl_loss: 77.9557WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 260.7241 - vae_r_loss: 182.7684 - vae_kl_loss: 77.9557 - val_loss: 1010.1305 - val_vae_r_loss: 931.8385 - val_vae_kl_loss: 78.2911\n",
      "Epoch 292/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 263.0812 - vae_r_loss: 184.6707 - vae_kl_loss: 78.4107WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 263.0812 - vae_r_loss: 184.6707 - vae_kl_loss: 78.4107 - val_loss: 1020.4507 - val_vae_r_loss: 942.9948 - val_vae_kl_loss: 77.4553\n",
      "Epoch 293/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 258.3768 - vae_r_loss: 180.6291 - vae_kl_loss: 77.7477WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1006.14526\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 258.3947 - vae_r_loss: 180.6462 - vae_kl_loss: 77.7485 - val_loss: 1017.2635 - val_vae_r_loss: 939.1360 - val_vae_kl_loss: 78.1278\n",
      "Epoch 294/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 262.9879 - vae_r_loss: 184.8195 - vae_kl_loss: 78.1687WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00294: val_loss improved from 1006.14526 to 1004.10920, saving model to vae_kdh_ckpt.294-1004.109.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.9829 - vae_r_loss: 184.8142 - vae_kl_loss: 78.1690 - val_loss: 1004.1092 - val_vae_r_loss: 925.7154 - val_vae_kl_loss: 78.3941\n",
      "Epoch 295/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 266.7555 - vae_r_loss: 188.1859 - vae_kl_loss: 78.5693WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.7555 - vae_r_loss: 188.1859 - vae_kl_loss: 78.5693 - val_loss: 1031.3688 - val_vae_r_loss: 953.2557 - val_vae_kl_loss: 78.1126\n",
      "Epoch 296/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 260.4333 - vae_r_loss: 182.4375 - vae_kl_loss: 77.9958WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 260.4333 - vae_r_loss: 182.4375 - vae_kl_loss: 77.9958 - val_loss: 1037.3699 - val_vae_r_loss: 959.3326 - val_vae_kl_loss: 78.0386\n",
      "Epoch 297/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 262.6163 - vae_r_loss: 184.6700 - vae_kl_loss: 77.9464WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 262.6163 - vae_r_loss: 184.6700 - vae_kl_loss: 77.9464 - val_loss: 1024.6606 - val_vae_r_loss: 946.6475 - val_vae_kl_loss: 78.0135\n",
      "Epoch 298/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 255.2409 - vae_r_loss: 177.2401 - vae_kl_loss: 78.0008WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.2550 - vae_r_loss: 177.2531 - vae_kl_loss: 78.0019 - val_loss: 1009.2079 - val_vae_r_loss: 930.8725 - val_vae_kl_loss: 78.3363\n",
      "Epoch 299/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 261.9453 - vae_r_loss: 183.3658 - vae_kl_loss: 78.5798WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 261.9453 - vae_r_loss: 183.3658 - vae_kl_loss: 78.5798 - val_loss: 1034.2214 - val_vae_r_loss: 956.7158 - val_vae_kl_loss: 77.5048\n",
      "Epoch 300/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 261.0889 - vae_r_loss: 182.7692 - vae_kl_loss: 78.3197WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 261.0763 - vae_r_loss: 182.7573 - vae_kl_loss: 78.3190 - val_loss: 1044.5805 - val_vae_r_loss: 966.3127 - val_vae_kl_loss: 78.2676\n",
      "Epoch 301/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.3408 - vae_r_loss: 175.9045 - vae_kl_loss: 77.4361WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.3408 - vae_r_loss: 175.9045 - vae_kl_loss: 77.4361 - val_loss: 1032.3801 - val_vae_r_loss: 954.8112 - val_vae_kl_loss: 77.5691\n",
      "Epoch 302/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 256.2032 - vae_r_loss: 178.4649 - vae_kl_loss: 77.7382WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 256.2032 - vae_r_loss: 178.4649 - vae_kl_loss: 77.7382 - val_loss: 1042.9051 - val_vae_r_loss: 965.2509 - val_vae_kl_loss: 77.6538\n",
      "Epoch 303/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 266.7219 - vae_r_loss: 188.1197 - vae_kl_loss: 78.6022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 266.7219 - vae_r_loss: 188.1197 - vae_kl_loss: 78.6022 - val_loss: 1025.6801 - val_vae_r_loss: 948.4308 - val_vae_kl_loss: 77.2497\n",
      "Epoch 304/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 258.3480 - vae_r_loss: 180.5459 - vae_kl_loss: 77.8021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 258.3480 - vae_r_loss: 180.5459 - vae_kl_loss: 77.8021 - val_loss: 1033.8358 - val_vae_r_loss: 956.3248 - val_vae_kl_loss: 77.5102\n",
      "Epoch 305/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 254.6299 - vae_r_loss: 177.0160 - vae_kl_loss: 77.6140WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 254.6299 - vae_r_loss: 177.0160 - vae_kl_loss: 77.6140 - val_loss: 1034.8409 - val_vae_r_loss: 957.6649 - val_vae_kl_loss: 77.1769\n",
      "Epoch 306/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 260.1957 - vae_r_loss: 182.2858 - vae_kl_loss: 77.9097WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 260.1853 - vae_r_loss: 182.2758 - vae_kl_loss: 77.9093 - val_loss: 1043.9094 - val_vae_r_loss: 966.4769 - val_vae_kl_loss: 77.4320\n",
      "Epoch 307/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 259.2792 - vae_r_loss: 181.2299 - vae_kl_loss: 78.0495WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 259.2792 - vae_r_loss: 181.2299 - vae_kl_loss: 78.0495 - val_loss: 1038.5966 - val_vae_r_loss: 960.8083 - val_vae_kl_loss: 77.7894\n",
      "Epoch 308/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 258.1179 - vae_r_loss: 180.2338 - vae_kl_loss: 77.8842WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 258.1179 - vae_r_loss: 180.2338 - vae_kl_loss: 77.8842 - val_loss: 1032.8204 - val_vae_r_loss: 955.5934 - val_vae_kl_loss: 77.2265\n",
      "Epoch 309/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 250.1742 - vae_r_loss: 173.2680 - vae_kl_loss: 76.9062WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.1623 - vae_r_loss: 173.2558 - vae_kl_loss: 76.9064 - val_loss: 1019.6221 - val_vae_r_loss: 942.8644 - val_vae_kl_loss: 76.7575\n",
      "Epoch 310/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 258.4915 - vae_r_loss: 180.7759 - vae_kl_loss: 77.7157WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 258.4915 - vae_r_loss: 180.7759 - vae_kl_loss: 77.7157 - val_loss: 1020.3802 - val_vae_r_loss: 942.9396 - val_vae_kl_loss: 77.4405\n",
      "Epoch 311/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 255.2839 - vae_r_loss: 177.5469 - vae_kl_loss: 77.7368WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.2938 - vae_r_loss: 177.5547 - vae_kl_loss: 77.7389 - val_loss: 1029.2502 - val_vae_r_loss: 951.8803 - val_vae_kl_loss: 77.3704\n",
      "Epoch 312/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 254.9815 - vae_r_loss: 177.5974 - vae_kl_loss: 77.3844WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 254.9755 - vae_r_loss: 177.5925 - vae_kl_loss: 77.3832 - val_loss: 1020.2284 - val_vae_r_loss: 943.4686 - val_vae_kl_loss: 76.7607\n",
      "Epoch 313/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 256.8874 - vae_r_loss: 179.3661 - vae_kl_loss: 77.5211WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 256.8874 - vae_r_loss: 179.3661 - vae_kl_loss: 77.5211 - val_loss: 1043.4685 - val_vae_r_loss: 966.3088 - val_vae_kl_loss: 77.1592\n",
      "Epoch 314/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 255.8433 - vae_r_loss: 178.1326 - vae_kl_loss: 77.7107WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.8433 - vae_r_loss: 178.1326 - vae_kl_loss: 77.7107 - val_loss: 1023.2624 - val_vae_r_loss: 946.3079 - val_vae_kl_loss: 76.9549\n",
      "Epoch 315/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 257.7529 - vae_r_loss: 180.0286 - vae_kl_loss: 77.7243WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 257.8172 - vae_r_loss: 180.0932 - vae_kl_loss: 77.7240 - val_loss: 1018.7197 - val_vae_r_loss: 941.8378 - val_vae_kl_loss: 76.8816\n",
      "Epoch 316/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.2519 - vae_r_loss: 176.3290 - vae_kl_loss: 76.9228WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.2519 - vae_r_loss: 176.3290 - vae_kl_loss: 76.9228 - val_loss: 1007.3870 - val_vae_r_loss: 930.5754 - val_vae_kl_loss: 76.8105\n",
      "Epoch 317/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 252.4702 - vae_r_loss: 175.1486 - vae_kl_loss: 77.3218WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1004.10920\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 252.4702 - vae_r_loss: 175.1486 - vae_kl_loss: 77.3218 - val_loss: 1006.0484 - val_vae_r_loss: 929.1479 - val_vae_kl_loss: 76.8999\n",
      "Epoch 318/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 260.7366 - vae_r_loss: 183.1140 - vae_kl_loss: 77.6228WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00318: val_loss improved from 1004.10920 to 999.53832, saving model to vae_kdh_ckpt.318-999.538.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 260.7653 - vae_r_loss: 183.1415 - vae_kl_loss: 77.6240 - val_loss: 999.5383 - val_vae_r_loss: 921.5842 - val_vae_kl_loss: 77.9526\n",
      "Epoch 319/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 249.2850 - vae_r_loss: 172.5059 - vae_kl_loss: 76.7793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 249.2850 - vae_r_loss: 172.5059 - vae_kl_loss: 76.7793 - val_loss: 1006.3319 - val_vae_r_loss: 929.1332 - val_vae_kl_loss: 77.1993\n",
      "Epoch 320/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 255.4948 - vae_r_loss: 178.1238 - vae_kl_loss: 77.3710WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.4923 - vae_r_loss: 178.1207 - vae_kl_loss: 77.3716 - val_loss: 1016.6808 - val_vae_r_loss: 938.8036 - val_vae_kl_loss: 77.8777\n",
      "Epoch 321/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.8510 - vae_r_loss: 176.4138 - vae_kl_loss: 77.4374WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.8510 - vae_r_loss: 176.4138 - vae_kl_loss: 77.4374 - val_loss: 1020.5550 - val_vae_r_loss: 943.3168 - val_vae_kl_loss: 77.2390\n",
      "Epoch 322/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 260.6629 - vae_r_loss: 182.6093 - vae_kl_loss: 78.0535WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 260.6580 - vae_r_loss: 182.6042 - vae_kl_loss: 78.0537 - val_loss: 1010.8163 - val_vae_r_loss: 933.2958 - val_vae_kl_loss: 77.5204\n",
      "Epoch 323/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 254.9932 - vae_r_loss: 177.4981 - vae_kl_loss: 77.4951WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.0083 - vae_r_loss: 177.5116 - vae_kl_loss: 77.4968 - val_loss: 1014.7452 - val_vae_r_loss: 937.4039 - val_vae_kl_loss: 77.3409\n",
      "Epoch 324/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 256.2725 - vae_r_loss: 178.6590 - vae_kl_loss: 77.6133WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 256.2629 - vae_r_loss: 178.6498 - vae_kl_loss: 77.6128 - val_loss: 1016.0801 - val_vae_r_loss: 939.1806 - val_vae_kl_loss: 76.9009\n",
      "Epoch 325/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 254.6613 - vae_r_loss: 177.1234 - vae_kl_loss: 77.5381WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 254.6613 - vae_r_loss: 177.1234 - vae_kl_loss: 77.5381 - val_loss: 1017.0928 - val_vae_r_loss: 939.8881 - val_vae_kl_loss: 77.2043\n",
      "Epoch 326/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 255.6313 - vae_r_loss: 177.9238 - vae_kl_loss: 77.7074WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.6313 - vae_r_loss: 177.9238 - vae_kl_loss: 77.7074 - val_loss: 1027.7418 - val_vae_r_loss: 950.9392 - val_vae_kl_loss: 76.8029\n",
      "Epoch 327/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 252.7266 - vae_r_loss: 175.4102 - vae_kl_loss: 77.3162WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 252.7266 - vae_r_loss: 175.4102 - vae_kl_loss: 77.3162 - val_loss: 1010.7644 - val_vae_r_loss: 933.4717 - val_vae_kl_loss: 77.2922\n",
      "Epoch 328/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 254.5958 - vae_r_loss: 177.1253 - vae_kl_loss: 77.4706WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 999.53832\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 254.5881 - vae_r_loss: 177.1181 - vae_kl_loss: 77.4700 - val_loss: 1010.1141 - val_vae_r_loss: 932.8678 - val_vae_kl_loss: 77.2457\n",
      "Epoch 329/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.4142 - vae_r_loss: 176.3530 - vae_kl_loss: 77.0612WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00329: val_loss improved from 999.53832 to 989.35091, saving model to vae_kdh_ckpt.329-989.351.h5\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.4142 - vae_r_loss: 176.3530 - vae_kl_loss: 77.0612 - val_loss: 989.3509 - val_vae_r_loss: 912.2747 - val_vae_kl_loss: 77.0762\n",
      "Epoch 330/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 250.6410 - vae_r_loss: 173.7295 - vae_kl_loss: 76.9113WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 989.35091\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.6410 - vae_r_loss: 173.7295 - vae_kl_loss: 76.9113 - val_loss: 994.1045 - val_vae_r_loss: 916.8627 - val_vae_kl_loss: 77.2423\n",
      "Epoch 331/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 255.3513 - vae_r_loss: 178.0942 - vae_kl_loss: 77.2571WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 989.35091\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.3513 - vae_r_loss: 178.0942 - vae_kl_loss: 77.2571 - val_loss: 1000.4962 - val_vae_r_loss: 923.0863 - val_vae_kl_loss: 77.4098\n",
      "Epoch 332/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 256.1557 - vae_r_loss: 178.8246 - vae_kl_loss: 77.3313WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 989.35091\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 256.1557 - vae_r_loss: 178.8246 - vae_kl_loss: 77.3313 - val_loss: 1006.3883 - val_vae_r_loss: 929.5844 - val_vae_kl_loss: 76.8038\n",
      "Epoch 333/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 256.0772 - vae_r_loss: 179.2308 - vae_kl_loss: 76.8464WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 989.35091\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 256.0772 - vae_r_loss: 179.2308 - vae_kl_loss: 76.8464 - val_loss: 997.6065 - val_vae_r_loss: 921.0962 - val_vae_kl_loss: 76.5100\n",
      "Epoch 334/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 255.3572 - vae_r_loss: 178.2515 - vae_kl_loss: 77.1056WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00334: val_loss improved from 989.35091 to 989.13332, saving model to vae_kdh_ckpt.334-989.133.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 255.3572 - vae_r_loss: 178.2515 - vae_kl_loss: 77.1056 - val_loss: 989.1333 - val_vae_r_loss: 911.7608 - val_vae_kl_loss: 77.3726\n",
      "Epoch 335/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 258.5744 - vae_r_loss: 181.0340 - vae_kl_loss: 77.5405WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 258.5581 - vae_r_loss: 181.0175 - vae_kl_loss: 77.5407 - val_loss: 1003.3590 - val_vae_r_loss: 926.0023 - val_vae_kl_loss: 77.3572\n",
      "Epoch 336/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.3991 - vae_r_loss: 176.0087 - vae_kl_loss: 77.3905WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.3991 - vae_r_loss: 176.0087 - vae_kl_loss: 77.3905 - val_loss: 996.9174 - val_vae_r_loss: 920.3810 - val_vae_kl_loss: 76.5371\n",
      "Epoch 337/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 250.9898 - vae_r_loss: 174.0202 - vae_kl_loss: 76.9698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.9813 - vae_r_loss: 174.0119 - vae_kl_loss: 76.9696 - val_loss: 1001.9074 - val_vae_r_loss: 925.1103 - val_vae_kl_loss: 76.7967\n",
      "Epoch 338/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 252.2393 - vae_r_loss: 175.2358 - vae_kl_loss: 77.0035WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 252.2256 - vae_r_loss: 175.2225 - vae_kl_loss: 77.0031 - val_loss: 1010.3628 - val_vae_r_loss: 933.3322 - val_vae_kl_loss: 77.0314\n",
      "Epoch 339/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 251.2477 - vae_r_loss: 174.5525 - vae_kl_loss: 76.6952WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 251.2477 - vae_r_loss: 174.5525 - vae_kl_loss: 76.6952 - val_loss: 993.6599 - val_vae_r_loss: 916.5436 - val_vae_kl_loss: 77.1162\n",
      "Epoch 340/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 252.8171 - vae_r_loss: 175.7649 - vae_kl_loss: 77.0522WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 252.8171 - vae_r_loss: 175.7649 - vae_kl_loss: 77.0522 - val_loss: 1005.7349 - val_vae_r_loss: 929.5883 - val_vae_kl_loss: 76.1466\n",
      "Epoch 341/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 247.3941 - vae_r_loss: 170.9595 - vae_kl_loss: 76.4346WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 989.13332\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 247.3823 - vae_r_loss: 170.9490 - vae_kl_loss: 76.4333 - val_loss: 998.6544 - val_vae_r_loss: 922.0579 - val_vae_kl_loss: 76.5954\n",
      "Epoch 342/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 251.3652 - vae_r_loss: 174.5183 - vae_kl_loss: 76.8469WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00342: val_loss improved from 989.13332 to 986.98995, saving model to vae_kdh_ckpt.342-986.990.h5\n",
      "3127/3127 [==============================] - 170s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 251.3748 - vae_r_loss: 174.5262 - vae_kl_loss: 76.8486 - val_loss: 986.9899 - val_vae_r_loss: 910.4299 - val_vae_kl_loss: 76.5596\n",
      "Epoch 343/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 251.4365 - vae_r_loss: 174.2545 - vae_kl_loss: 77.1819WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 251.4252 - vae_r_loss: 174.2444 - vae_kl_loss: 77.1807 - val_loss: 1013.3645 - val_vae_r_loss: 936.7202 - val_vae_kl_loss: 76.6442\n",
      "Epoch 344/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 248.5334 - vae_r_loss: 171.8959 - vae_kl_loss: 76.6377WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 248.5313 - vae_r_loss: 171.8942 - vae_kl_loss: 76.6373 - val_loss: 1016.4667 - val_vae_r_loss: 939.8798 - val_vae_kl_loss: 76.5858\n",
      "Epoch 345/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 250.1054 - vae_r_loss: 173.4856 - vae_kl_loss: 76.6200WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.1108 - vae_r_loss: 173.4907 - vae_kl_loss: 76.6202 - val_loss: 1008.8450 - val_vae_r_loss: 932.0233 - val_vae_kl_loss: 76.8215\n",
      "Epoch 346/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.0885 - vae_r_loss: 167.4522 - vae_kl_loss: 76.6361 ETA: 2s - batch: 1532.5000 - size: 32.000WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.1179 - vae_r_loss: 167.4809 - vae_kl_loss: 76.6369 - val_loss: 1000.1170 - val_vae_r_loss: 923.1522 - val_vae_kl_loss: 76.9655\n",
      "Epoch 347/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 250.2715 - vae_r_loss: 173.0304 - vae_kl_loss: 77.2411WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.2715 - vae_r_loss: 173.0304 - vae_kl_loss: 77.2411 - val_loss: 1014.1700 - val_vae_r_loss: 937.8358 - val_vae_kl_loss: 76.3346\n",
      "Epoch 348/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 250.2805 - vae_r_loss: 173.2879 - vae_kl_loss: 76.9925WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.2764 - vae_r_loss: 173.2826 - vae_kl_loss: 76.9937 - val_loss: 1031.5553 - val_vae_r_loss: 955.0762 - val_vae_kl_loss: 76.4798\n",
      "Epoch 349/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 242.6099 - vae_r_loss: 166.5554 - vae_kl_loss: 76.0545WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 242.6123 - vae_r_loss: 166.5578 - vae_kl_loss: 76.0545 - val_loss: 1015.7321 - val_vae_r_loss: 939.2629 - val_vae_kl_loss: 76.4699\n",
      "Epoch 350/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 245.3740 - vae_r_loss: 169.0305 - vae_kl_loss: 76.3437WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.3740 - vae_r_loss: 169.0305 - vae_kl_loss: 76.3437 - val_loss: 1025.2575 - val_vae_r_loss: 948.9721 - val_vae_kl_loss: 76.2851\n",
      "Epoch 351/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 253.1165 - vae_r_loss: 175.8941 - vae_kl_loss: 77.2223WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 253.1165 - vae_r_loss: 175.8941 - vae_kl_loss: 77.2223 - val_loss: 1013.1569 - val_vae_r_loss: 937.1340 - val_vae_kl_loss: 76.0238\n",
      "Epoch 352/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 247.6099 - vae_r_loss: 171.1938 - vae_kl_loss: 76.4162WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 177s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 247.6099 - vae_r_loss: 171.1938 - vae_kl_loss: 76.4162 - val_loss: 1020.8563 - val_vae_r_loss: 944.7845 - val_vae_kl_loss: 76.0722\n",
      "Epoch 353/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.8196 - vae_r_loss: 168.5809 - vae_kl_loss: 76.2389WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.8056 - vae_r_loss: 168.5679 - vae_kl_loss: 76.2379 - val_loss: 1022.1787 - val_vae_r_loss: 946.2420 - val_vae_kl_loss: 75.9376\n",
      "Epoch 354/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 249.5848 - vae_r_loss: 172.9695 - vae_kl_loss: 76.6152WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 249.5848 - vae_r_loss: 172.9695 - vae_kl_loss: 76.6152 - val_loss: 1030.5421 - val_vae_r_loss: 954.3461 - val_vae_kl_loss: 76.1967\n",
      "Epoch 355/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 248.8560 - vae_r_loss: 172.1209 - vae_kl_loss: 76.7353WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 248.8560 - vae_r_loss: 172.1209 - vae_kl_loss: 76.7353 - val_loss: 1019.7018 - val_vae_r_loss: 943.4098 - val_vae_kl_loss: 76.2916\n",
      "Epoch 356/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 247.8815 - vae_r_loss: 171.3514 - vae_kl_loss: 76.5303WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 247.8690 - vae_r_loss: 171.3380 - vae_kl_loss: 76.5312 - val_loss: 1011.5576 - val_vae_r_loss: 935.3273 - val_vae_kl_loss: 76.2301\n",
      "Epoch 357/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 239.1753 - vae_r_loss: 163.5951 - vae_kl_loss: 75.5802WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 239.1675 - vae_r_loss: 163.5872 - vae_kl_loss: 75.5802 - val_loss: 1005.4267 - val_vae_r_loss: 929.7984 - val_vae_kl_loss: 75.6286\n",
      "Epoch 358/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 248.6088 - vae_r_loss: 172.1117 - vae_kl_loss: 76.4971WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 248.5927 - vae_r_loss: 172.0972 - vae_kl_loss: 76.4955 - val_loss: 1008.2375 - val_vae_r_loss: 932.0664 - val_vae_kl_loss: 76.1719\n",
      "Epoch 359/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 245.3266 - vae_r_loss: 168.8785 - vae_kl_loss: 76.4478WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.3266 - vae_r_loss: 168.8785 - vae_kl_loss: 76.4478 - val_loss: 1014.0565 - val_vae_r_loss: 937.6540 - val_vae_kl_loss: 76.4026\n",
      "Epoch 360/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 246.5566 - vae_r_loss: 170.5069 - vae_kl_loss: 76.0497WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 246.5566 - vae_r_loss: 170.5069 - vae_kl_loss: 76.0497 - val_loss: 1000.4125 - val_vae_r_loss: 924.6364 - val_vae_kl_loss: 75.7751\n",
      "Epoch 361/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 245.0127 - vae_r_loss: 168.8415 - vae_kl_loss: 76.1713WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.0126 - vae_r_loss: 168.8391 - vae_kl_loss: 76.1737 - val_loss: 1025.4441 - val_vae_r_loss: 949.6274 - val_vae_kl_loss: 75.8178\n",
      "Epoch 362/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 245.3707 - vae_r_loss: 168.9937 - vae_kl_loss: 76.3769WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.3606 - vae_r_loss: 168.9834 - vae_kl_loss: 76.3771 - val_loss: 1012.3462 - val_vae_r_loss: 936.5369 - val_vae_kl_loss: 75.8099\n",
      "Epoch 363/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 247.2779 - vae_r_loss: 170.8642 - vae_kl_loss: 76.4140WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 247.2779 - vae_r_loss: 170.8642 - vae_kl_loss: 76.4140 - val_loss: 1007.5864 - val_vae_r_loss: 932.3557 - val_vae_kl_loss: 75.2305\n",
      "Epoch 364/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 244.0606 - vae_r_loss: 168.4305 - vae_kl_loss: 75.6301WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.0606 - vae_r_loss: 168.4305 - vae_kl_loss: 75.6301 - val_loss: 992.7356 - val_vae_r_loss: 917.2681 - val_vae_kl_loss: 75.4677\n",
      "Epoch 365/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 242.4058 - vae_r_loss: 166.4001 - vae_kl_loss: 76.0057WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 242.4058 - vae_r_loss: 166.4001 - vae_kl_loss: 76.0057 - val_loss: 1000.7178 - val_vae_r_loss: 925.3183 - val_vae_kl_loss: 75.4001\n",
      "Epoch 366/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 250.3566 - vae_r_loss: 174.0847 - vae_kl_loss: 76.2718WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 250.3566 - vae_r_loss: 174.0847 - vae_kl_loss: 76.2718 - val_loss: 993.6139 - val_vae_r_loss: 917.4394 - val_vae_kl_loss: 76.1749\n",
      "Epoch 367/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 239.4964 - vae_r_loss: 164.1447 - vae_kl_loss: 75.3515WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 239.4964 - vae_r_loss: 164.1447 - vae_kl_loss: 75.3515 - val_loss: 1001.2206 - val_vae_r_loss: 925.1241 - val_vae_kl_loss: 76.0962\n",
      "Epoch 368/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 244.3809 - vae_r_loss: 168.4286 - vae_kl_loss: 75.9522WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.3809 - vae_r_loss: 168.4286 - vae_kl_loss: 75.9522 - val_loss: 1011.5466 - val_vae_r_loss: 935.1971 - val_vae_kl_loss: 76.3493\n",
      "Epoch 369/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 243.7875 - vae_r_loss: 167.8253 - vae_kl_loss: 75.9625WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.7875 - vae_r_loss: 167.8253 - vae_kl_loss: 75.9625 - val_loss: 1005.9435 - val_vae_r_loss: 930.1656 - val_vae_kl_loss: 75.7778\n",
      "Epoch 370/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 249.8093 - vae_r_loss: 173.1275 - vae_kl_loss: 76.6815WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 249.8032 - vae_r_loss: 173.1214 - vae_kl_loss: 76.6815 - val_loss: 996.4669 - val_vae_r_loss: 920.3777 - val_vae_kl_loss: 76.0890\n",
      "Epoch 371/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.6639 - vae_r_loss: 168.5943 - vae_kl_loss: 76.0694WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.6638 - vae_r_loss: 168.5918 - vae_kl_loss: 76.0718 - val_loss: 1000.4461 - val_vae_r_loss: 924.4938 - val_vae_kl_loss: 75.9513\n",
      "Epoch 372/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.9181 - vae_r_loss: 168.6463 - vae_kl_loss: 76.2718WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.9252 - vae_r_loss: 168.6530 - vae_kl_loss: 76.2723 - val_loss: 1007.3306 - val_vae_r_loss: 931.4392 - val_vae_kl_loss: 75.8908\n",
      "Epoch 373/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.6604 - vae_r_loss: 168.6311 - vae_kl_loss: 76.0295WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.6570 - vae_r_loss: 168.6276 - vae_kl_loss: 76.0294 - val_loss: 1003.8518 - val_vae_r_loss: 928.1019 - val_vae_kl_loss: 75.7489\n",
      "Epoch 374/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 245.8855 - vae_r_loss: 169.4909 - vae_kl_loss: 76.3946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.8855 - vae_r_loss: 169.4909 - vae_kl_loss: 76.3946 - val_loss: 1007.4694 - val_vae_r_loss: 931.8467 - val_vae_kl_loss: 75.6223\n",
      "Epoch 375/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 242.7690 - vae_r_loss: 166.8283 - vae_kl_loss: 75.9406WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 242.7690 - vae_r_loss: 166.8283 - vae_kl_loss: 75.9406 - val_loss: 1002.5985 - val_vae_r_loss: 927.0357 - val_vae_kl_loss: 75.5628\n",
      "Epoch 376/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 243.9705 - vae_r_loss: 167.9611 - vae_kl_loss: 76.0096WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 986.98995\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.9705 - vae_r_loss: 167.9611 - vae_kl_loss: 76.0096 - val_loss: 999.5022 - val_vae_r_loss: 923.5652 - val_vae_kl_loss: 75.9373\n",
      "Epoch 377/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 242.8874 - vae_r_loss: 167.2258 - vae_kl_loss: 75.6617WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00377: val_loss improved from 986.98995 to 979.94182, saving model to vae_kdh_ckpt.377-979.942.h5\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 242.8874 - vae_r_loss: 167.2258 - vae_kl_loss: 75.6617 - val_loss: 979.9418 - val_vae_r_loss: 904.1411 - val_vae_kl_loss: 75.8004\n",
      "Epoch 378/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 241.3700 - vae_r_loss: 165.8372 - vae_kl_loss: 75.5328WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00378: val_loss improved from 979.94182 to 977.78947, saving model to vae_kdh_ckpt.378-977.789.h5\n",
      "3127/3127 [==============================] - 170s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 241.3700 - vae_r_loss: 165.8372 - vae_kl_loss: 75.5328 - val_loss: 977.7895 - val_vae_r_loss: 901.9484 - val_vae_kl_loss: 75.8406\n",
      "Epoch 379/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.6690 - vae_r_loss: 168.7500 - vae_kl_loss: 75.9188WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.6639 - vae_r_loss: 168.7454 - vae_kl_loss: 75.9183 - val_loss: 994.7864 - val_vae_r_loss: 918.7845 - val_vae_kl_loss: 76.0010\n",
      "Epoch 380/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 246.5910 - vae_r_loss: 170.6760 - vae_kl_loss: 75.9150WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 246.5857 - vae_r_loss: 170.6699 - vae_kl_loss: 75.9158 - val_loss: 1000.6860 - val_vae_r_loss: 925.0669 - val_vae_kl_loss: 75.6186\n",
      "Epoch 381/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 244.7752 - vae_r_loss: 169.3224 - vae_kl_loss: 75.4529WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.7752 - vae_r_loss: 169.3224 - vae_kl_loss: 75.4529 - val_loss: 987.7720 - val_vae_r_loss: 912.3713 - val_vae_kl_loss: 75.4005\n",
      "Epoch 382/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 245.5212 - vae_r_loss: 169.8415 - vae_kl_loss: 75.6799WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 245.5212 - vae_r_loss: 169.8415 - vae_kl_loss: 75.6799 - val_loss: 978.6071 - val_vae_r_loss: 903.0618 - val_vae_kl_loss: 75.5449\n",
      "Epoch 383/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 246.9250 - vae_r_loss: 170.7656 - vae_kl_loss: 76.1596WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 166s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 246.9250 - vae_r_loss: 170.7656 - vae_kl_loss: 76.1596 - val_loss: 994.9405 - val_vae_r_loss: 918.9365 - val_vae_kl_loss: 76.0038\n",
      "Epoch 384/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 243.8547 - vae_r_loss: 167.8432 - vae_kl_loss: 76.0115WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.8455 - vae_r_loss: 167.8349 - vae_kl_loss: 76.0106 - val_loss: 983.6370 - val_vae_r_loss: 908.2934 - val_vae_kl_loss: 75.3445\n",
      "Epoch 385/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 240.5251 - vae_r_loss: 164.9409 - vae_kl_loss: 75.5842WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.5188 - vae_r_loss: 164.9343 - vae_kl_loss: 75.5845 - val_loss: 995.2222 - val_vae_r_loss: 919.4346 - val_vae_kl_loss: 75.7877\n",
      "Epoch 386/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 241.8931 - vae_r_loss: 166.3502 - vae_kl_loss: 75.5431WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 241.8931 - vae_r_loss: 166.3502 - vae_kl_loss: 75.5431 - val_loss: 993.4385 - val_vae_r_loss: 917.9437 - val_vae_kl_loss: 75.4946\n",
      "Epoch 387/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 239.9565 - vae_r_loss: 164.6069 - vae_kl_loss: 75.3496WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 239.9565 - vae_r_loss: 164.6069 - vae_kl_loss: 75.3496 - val_loss: 988.5792 - val_vae_r_loss: 912.4854 - val_vae_kl_loss: 76.0938\n",
      "Epoch 388/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 243.2910 - vae_r_loss: 167.4944 - vae_kl_loss: 75.7965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.2910 - vae_r_loss: 167.4944 - vae_kl_loss: 75.7965 - val_loss: 1001.4159 - val_vae_r_loss: 926.2422 - val_vae_kl_loss: 75.1743\n",
      "Epoch 389/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 238.9749 - vae_r_loss: 163.8804 - vae_kl_loss: 75.0942WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 977.78947\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 238.9749 - vae_r_loss: 163.8804 - vae_kl_loss: 75.0942 - val_loss: 992.7702 - val_vae_r_loss: 917.3148 - val_vae_kl_loss: 75.4550\n",
      "Epoch 390/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 243.2525 - vae_r_loss: 167.8133 - vae_kl_loss: 75.4392WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00390: val_loss improved from 977.78947 to 977.57101, saving model to vae_kdh_ckpt.390-977.571.h5\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.2525 - vae_r_loss: 167.8133 - vae_kl_loss: 75.4392 - val_loss: 977.5710 - val_vae_r_loss: 902.4493 - val_vae_kl_loss: 75.1223\n",
      "Epoch 391/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 243.3859 - vae_r_loss: 167.5581 - vae_kl_loss: 75.8276WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 243.4033 - vae_r_loss: 167.5760 - vae_kl_loss: 75.8271 - val_loss: 997.2651 - val_vae_r_loss: 922.1695 - val_vae_kl_loss: 75.0953\n",
      "Epoch 392/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 238.5198 - vae_r_loss: 163.3024 - vae_kl_loss: 75.2176WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 238.5198 - vae_r_loss: 163.3024 - vae_kl_loss: 75.2176 - val_loss: 1008.1297 - val_vae_r_loss: 932.5565 - val_vae_kl_loss: 75.5729\n",
      "Epoch 393/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 240.0900 - vae_r_loss: 164.8490 - vae_kl_loss: 75.2410WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.0985 - vae_r_loss: 164.8557 - vae_kl_loss: 75.2428 - val_loss: 994.8793 - val_vae_r_loss: 919.4194 - val_vae_kl_loss: 75.4596\n",
      "Epoch 394/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 234.8566 - vae_r_loss: 159.7104 - vae_kl_loss: 75.1462WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.8509 - vae_r_loss: 159.7044 - vae_kl_loss: 75.1465 - val_loss: 983.8646 - val_vae_r_loss: 908.7076 - val_vae_kl_loss: 75.1578\n",
      "Epoch 395/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 241.3595 - vae_r_loss: 165.5042 - vae_kl_loss: 75.8552WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 241.3595 - vae_r_loss: 165.5042 - vae_kl_loss: 75.8552 - val_loss: 997.6575 - val_vae_r_loss: 922.7154 - val_vae_kl_loss: 74.9418\n",
      "Epoch 396/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 240.9405 - vae_r_loss: 165.3095 - vae_kl_loss: 75.6311WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.9405 - vae_r_loss: 165.3095 - vae_kl_loss: 75.6311 - val_loss: 1020.1252 - val_vae_r_loss: 945.0524 - val_vae_kl_loss: 75.0722\n",
      "Epoch 397/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.3607 - vae_r_loss: 159.5326 - vae_kl_loss: 74.8279WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.3607 - vae_r_loss: 159.5326 - vae_kl_loss: 74.8279 - val_loss: 1006.6944 - val_vae_r_loss: 931.6544 - val_vae_kl_loss: 75.0397\n",
      "Epoch 398/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 236.2307 - vae_r_loss: 161.2134 - vae_kl_loss: 75.0172WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.2307 - vae_r_loss: 161.2134 - vae_kl_loss: 75.0172 - val_loss: 1018.7446 - val_vae_r_loss: 943.7621 - val_vae_kl_loss: 74.9827\n",
      "Epoch 399/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 244.6165 - vae_r_loss: 168.6901 - vae_kl_loss: 75.9263WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 244.6106 - vae_r_loss: 168.6844 - vae_kl_loss: 75.9262 - val_loss: 1009.2608 - val_vae_r_loss: 934.5945 - val_vae_kl_loss: 74.6676\n",
      "Epoch 400/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 240.5781 - vae_r_loss: 165.4475 - vae_kl_loss: 75.1306WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.5734 - vae_r_loss: 165.4427 - vae_kl_loss: 75.1307 - val_loss: 1013.5206 - val_vae_r_loss: 938.1607 - val_vae_kl_loss: 75.3593\n",
      "Epoch 401/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 237.2715 - vae_r_loss: 162.3429 - vae_kl_loss: 74.9286WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 237.2736 - vae_r_loss: 162.3443 - vae_kl_loss: 74.9294 - val_loss: 1016.3204 - val_vae_r_loss: 941.6685 - val_vae_kl_loss: 74.6519\n",
      "Epoch 402/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 241.9114 - vae_r_loss: 166.6242 - vae_kl_loss: 75.2873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 241.9167 - vae_r_loss: 166.6296 - vae_kl_loss: 75.2871 - val_loss: 1020.8544 - val_vae_r_loss: 945.9864 - val_vae_kl_loss: 74.8694\n",
      "Epoch 403/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 240.0694 - vae_r_loss: 164.6924 - vae_kl_loss: 75.3770WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.0694 - vae_r_loss: 164.6924 - vae_kl_loss: 75.3770 - val_loss: 1014.0690 - val_vae_r_loss: 939.0738 - val_vae_kl_loss: 74.9950\n",
      "Epoch 404/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 238.7674 - vae_r_loss: 163.6028 - vae_kl_loss: 75.1646WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 238.7629 - vae_r_loss: 163.5986 - vae_kl_loss: 75.1642 - val_loss: 1005.7647 - val_vae_r_loss: 931.0397 - val_vae_kl_loss: 74.7241\n",
      "Epoch 405/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 230.2244 - vae_r_loss: 156.0098 - vae_kl_loss: 74.2148WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.2244 - vae_r_loss: 156.0098 - vae_kl_loss: 74.2148 - val_loss: 996.8750 - val_vae_r_loss: 922.3205 - val_vae_kl_loss: 74.5548\n",
      "Epoch 406/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 238.2171 - vae_r_loss: 163.0552 - vae_kl_loss: 75.1619WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 238.2171 - vae_r_loss: 163.0552 - vae_kl_loss: 75.1619 - val_loss: 997.9098 - val_vae_r_loss: 922.8314 - val_vae_kl_loss: 75.0789\n",
      "Epoch 407/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 235.4194 - vae_r_loss: 160.3861 - vae_kl_loss: 75.0331WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 235.4195 - vae_r_loss: 160.3874 - vae_kl_loss: 75.0321 - val_loss: 1007.2724 - val_vae_r_loss: 932.1834 - val_vae_kl_loss: 75.0897\n",
      "Epoch 408/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.7617 - vae_r_loss: 162.0021 - vae_kl_loss: 74.7594WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.7461 - vae_r_loss: 161.9872 - vae_kl_loss: 74.7587 - val_loss: 1002.6168 - val_vae_r_loss: 928.2255 - val_vae_kl_loss: 74.3913\n",
      "Epoch 409/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.2866 - vae_r_loss: 161.3401 - vae_kl_loss: 74.9467WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.2705 - vae_r_loss: 161.3250 - vae_kl_loss: 74.9456 - val_loss: 1017.3779 - val_vae_r_loss: 942.9103 - val_vae_kl_loss: 74.4680\n",
      "Epoch 410/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 235.4416 - vae_r_loss: 160.4030 - vae_kl_loss: 75.0386WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 235.4368 - vae_r_loss: 160.3976 - vae_kl_loss: 75.0392 - val_loss: 1006.1407 - val_vae_r_loss: 931.4945 - val_vae_kl_loss: 74.6468\n",
      "Epoch 411/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 237.3176 - vae_r_loss: 162.1756 - vae_kl_loss: 75.1420WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 237.3036 - vae_r_loss: 162.1620 - vae_kl_loss: 75.1416 - val_loss: 1004.5976 - val_vae_r_loss: 930.4352 - val_vae_kl_loss: 74.1617\n",
      "Epoch 412/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 234.9671 - vae_r_loss: 160.6324 - vae_kl_loss: 74.3347WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.9653 - vae_r_loss: 160.6302 - vae_kl_loss: 74.3351 - val_loss: 990.9374 - val_vae_r_loss: 916.5166 - val_vae_kl_loss: 74.4213\n",
      "Epoch 413/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 233.1830 - vae_r_loss: 158.5049 - vae_kl_loss: 74.6780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 233.1830 - vae_r_loss: 158.5049 - vae_kl_loss: 74.6780 - val_loss: 992.8282 - val_vae_r_loss: 918.5793 - val_vae_kl_loss: 74.2483\n",
      "Epoch 414/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 241.0013 - vae_r_loss: 166.0938 - vae_kl_loss: 74.9075WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 241.0013 - vae_r_loss: 166.0938 - vae_kl_loss: 74.9075 - val_loss: 987.6318 - val_vae_r_loss: 912.9788 - val_vae_kl_loss: 74.6523\n",
      "Epoch 415/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 230.8784 - vae_r_loss: 156.8173 - vae_kl_loss: 74.0609WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.8710 - vae_r_loss: 156.8098 - vae_kl_loss: 74.0609 - val_loss: 988.0670 - val_vae_r_loss: 913.1988 - val_vae_kl_loss: 74.8679\n",
      "Epoch 416/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.4283 - vae_r_loss: 161.7365 - vae_kl_loss: 74.6919WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.4648 - vae_r_loss: 161.7732 - vae_kl_loss: 74.6917 - val_loss: 997.6326 - val_vae_r_loss: 922.7745 - val_vae_kl_loss: 74.8582\n",
      "Epoch 417/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 234.1159 - vae_r_loss: 159.4069 - vae_kl_loss: 74.7089WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.1181 - vae_r_loss: 159.4101 - vae_kl_loss: 74.7079 - val_loss: 993.2681 - val_vae_r_loss: 918.6638 - val_vae_kl_loss: 74.6043\n",
      "Epoch 418/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 240.4444 - vae_r_loss: 165.0404 - vae_kl_loss: 75.4040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 240.4444 - vae_r_loss: 165.0404 - vae_kl_loss: 75.4040 - val_loss: 988.7699 - val_vae_r_loss: 913.9643 - val_vae_kl_loss: 74.8056\n",
      "Epoch 419/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 236.7274 - vae_r_loss: 161.8612 - vae_kl_loss: 74.8661WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.7274 - vae_r_loss: 161.8612 - vae_kl_loss: 74.8661 - val_loss: 989.6098 - val_vae_r_loss: 915.0068 - val_vae_kl_loss: 74.6031\n",
      "Epoch 420/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.6752 - vae_r_loss: 161.6843 - vae_kl_loss: 74.9908WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.6747 - vae_r_loss: 161.6828 - vae_kl_loss: 74.9919 - val_loss: 1002.6603 - val_vae_r_loss: 928.1757 - val_vae_kl_loss: 74.4840\n",
      "Epoch 421/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 236.8821 - vae_r_loss: 162.0013 - vae_kl_loss: 74.8809WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.8821 - vae_r_loss: 162.0013 - vae_kl_loss: 74.8809 - val_loss: 998.0699 - val_vae_r_loss: 923.3308 - val_vae_kl_loss: 74.7386\n",
      "Epoch 422/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 236.3804 - vae_r_loss: 161.3355 - vae_kl_loss: 75.0448WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.3804 - vae_r_loss: 161.3355 - vae_kl_loss: 75.0448 - val_loss: 1002.3935 - val_vae_r_loss: 928.1921 - val_vae_kl_loss: 74.2014\n",
      "Epoch 423/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 233.6308 - vae_r_loss: 158.9681 - vae_kl_loss: 74.6627WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 233.6308 - vae_r_loss: 158.9681 - vae_kl_loss: 74.6627 - val_loss: 998.9660 - val_vae_r_loss: 924.3815 - val_vae_kl_loss: 74.5848\n",
      "Epoch 424/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 235.9264 - vae_r_loss: 161.1584 - vae_kl_loss: 74.7681WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 977.57101\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 235.9273 - vae_r_loss: 161.1589 - vae_kl_loss: 74.7685 - val_loss: 985.8873 - val_vae_r_loss: 910.9824 - val_vae_kl_loss: 74.9039\n",
      "Epoch 425/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.9750 - vae_r_loss: 160.4805 - vae_kl_loss: 74.4945WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00425: val_loss improved from 977.57101 to 974.39622, saving model to vae_kdh_ckpt.425-974.396.h5\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.9750 - vae_r_loss: 160.4805 - vae_kl_loss: 74.4945 - val_loss: 974.3962 - val_vae_r_loss: 899.7078 - val_vae_kl_loss: 74.6888\n",
      "Epoch 426/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.4980 - vae_r_loss: 160.2070 - vae_kl_loss: 74.2911WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00426: val_loss improved from 974.39622 to 973.73867, saving model to vae_kdh_ckpt.426-973.739.h5\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.4980 - vae_r_loss: 160.2070 - vae_kl_loss: 74.2911 - val_loss: 973.7387 - val_vae_r_loss: 899.0650 - val_vae_kl_loss: 74.6741\n",
      "Epoch 427/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 235.1839 - vae_r_loss: 160.4616 - vae_kl_loss: 74.7223WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 235.1980 - vae_r_loss: 160.4740 - vae_kl_loss: 74.7239 - val_loss: 977.8497 - val_vae_r_loss: 903.3268 - val_vae_kl_loss: 74.5228\n",
      "Epoch 428/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 237.5719 - vae_r_loss: 162.7089 - vae_kl_loss: 74.8629WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 237.5719 - vae_r_loss: 162.7089 - vae_kl_loss: 74.8629 - val_loss: 990.7419 - val_vae_r_loss: 916.5386 - val_vae_kl_loss: 74.2041\n",
      "Epoch 429/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 237.9104 - vae_r_loss: 163.5495 - vae_kl_loss: 74.3609WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 237.9104 - vae_r_loss: 163.5495 - vae_kl_loss: 74.3609 - val_loss: 978.9906 - val_vae_r_loss: 904.4089 - val_vae_kl_loss: 74.5820\n",
      "Epoch 430/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.9846 - vae_r_loss: 160.4839 - vae_kl_loss: 74.5008WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.9846 - vae_r_loss: 160.4839 - vae_kl_loss: 74.5008 - val_loss: 976.3279 - val_vae_r_loss: 901.4472 - val_vae_kl_loss: 74.8804\n",
      "Epoch 431/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 238.5201 - vae_r_loss: 163.5512 - vae_kl_loss: 74.9689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 238.5184 - vae_r_loss: 163.5497 - vae_kl_loss: 74.9688 - val_loss: 988.3897 - val_vae_r_loss: 913.7149 - val_vae_kl_loss: 74.6745\n",
      "Epoch 432/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.9587 - vae_r_loss: 160.1666 - vae_kl_loss: 74.7918WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.9587 - vae_r_loss: 160.1666 - vae_kl_loss: 74.7918 - val_loss: 983.0552 - val_vae_r_loss: 908.6144 - val_vae_kl_loss: 74.4404\n",
      "Epoch 433/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 232.1738 - vae_r_loss: 157.6976 - vae_kl_loss: 74.4762WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.1738 - vae_r_loss: 157.6976 - vae_kl_loss: 74.4762 - val_loss: 985.8577 - val_vae_r_loss: 911.6361 - val_vae_kl_loss: 74.2209\n",
      "Epoch 434/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 233.7112 - vae_r_loss: 159.2623 - vae_kl_loss: 74.4488WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 233.7112 - vae_r_loss: 159.2623 - vae_kl_loss: 74.4488 - val_loss: 994.1379 - val_vae_r_loss: 919.1981 - val_vae_kl_loss: 74.9394\n",
      "Epoch 435/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 232.0239 - vae_r_loss: 157.7395 - vae_kl_loss: 74.2845WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.0239 - vae_r_loss: 157.7395 - vae_kl_loss: 74.2845 - val_loss: 984.1587 - val_vae_r_loss: 909.4924 - val_vae_kl_loss: 74.6659\n",
      "Epoch 436/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 235.8875 - vae_r_loss: 161.2635 - vae_kl_loss: 74.6239WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 167s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 235.8875 - vae_r_loss: 161.2635 - vae_kl_loss: 74.6239 - val_loss: 988.2020 - val_vae_r_loss: 914.4721 - val_vae_kl_loss: 73.7298\n",
      "Epoch 437/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 232.2727 - vae_r_loss: 158.3418 - vae_kl_loss: 73.9308WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 973.73867\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.2727 - vae_r_loss: 158.3418 - vae_kl_loss: 73.9308 - val_loss: 989.3653 - val_vae_r_loss: 914.9481 - val_vae_kl_loss: 74.4170\n",
      "Epoch 438/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 234.9582 - vae_r_loss: 160.6833 - vae_kl_loss: 74.2748WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00438: val_loss improved from 973.73867 to 971.80339, saving model to vae_kdh_ckpt.438-971.803.h5\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.9748 - vae_r_loss: 160.6982 - vae_kl_loss: 74.2766 - val_loss: 971.8034 - val_vae_r_loss: 898.1198 - val_vae_kl_loss: 73.6836\n",
      "Epoch 439/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.1656 - vae_r_loss: 161.4894 - vae_kl_loss: 74.6762WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.1463 - vae_r_loss: 161.4707 - vae_kl_loss: 74.6756 - val_loss: 995.4266 - val_vae_r_loss: 921.5719 - val_vae_kl_loss: 73.8537\n",
      "Epoch 440/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 230.3096 - vae_r_loss: 156.2999 - vae_kl_loss: 74.0097WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 178s 57ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.3096 - vae_r_loss: 156.2999 - vae_kl_loss: 74.0097 - val_loss: 995.8018 - val_vae_r_loss: 921.2032 - val_vae_kl_loss: 74.5987\n",
      "Epoch 441/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 231.9270 - vae_r_loss: 157.8062 - vae_kl_loss: 74.1207WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 231.9270 - vae_r_loss: 157.8062 - vae_kl_loss: 74.1207 - val_loss: 989.1030 - val_vae_r_loss: 915.0165 - val_vae_kl_loss: 74.0866\n",
      "Epoch 442/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 228.7549 - vae_r_loss: 154.7802 - vae_kl_loss: 73.9747WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.7549 - vae_r_loss: 154.7802 - vae_kl_loss: 73.9747 - val_loss: 976.1982 - val_vae_r_loss: 902.1423 - val_vae_kl_loss: 74.0560\n",
      "Epoch 443/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 233.2789 - vae_r_loss: 158.6712 - vae_kl_loss: 74.6078WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 233.2789 - vae_r_loss: 158.6712 - vae_kl_loss: 74.6078 - val_loss: 991.4735 - val_vae_r_loss: 917.2181 - val_vae_kl_loss: 74.2556\n",
      "Epoch 444/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 232.3401 - vae_r_loss: 157.8594 - vae_kl_loss: 74.4807WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 167s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.3401 - vae_r_loss: 157.8594 - vae_kl_loss: 74.4807 - val_loss: 1012.4905 - val_vae_r_loss: 938.5452 - val_vae_kl_loss: 73.9443\n",
      "Epoch 445/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 226.5239 - vae_r_loss: 152.9134 - vae_kl_loss: 73.6103WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.5239 - vae_r_loss: 152.9134 - vae_kl_loss: 73.6103 - val_loss: 1003.4360 - val_vae_r_loss: 929.4520 - val_vae_kl_loss: 73.9835\n",
      "Epoch 446/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.6433 - vae_r_loss: 155.7643 - vae_kl_loss: 73.8788WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.6325 - vae_r_loss: 155.7544 - vae_kl_loss: 73.8779 - val_loss: 1010.6936 - val_vae_r_loss: 937.0114 - val_vae_kl_loss: 73.6831\n",
      "Epoch 447/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 236.6171 - vae_r_loss: 161.8331 - vae_kl_loss: 74.7839WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 236.6182 - vae_r_loss: 161.8353 - vae_kl_loss: 74.7827 - val_loss: 1003.9901 - val_vae_r_loss: 930.2628 - val_vae_kl_loss: 73.7272\n",
      "Epoch 448/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 232.2052 - vae_r_loss: 158.2113 - vae_kl_loss: 73.9938WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.2028 - vae_r_loss: 158.2088 - vae_kl_loss: 73.9939 - val_loss: 1007.0570 - val_vae_r_loss: 933.0987 - val_vae_kl_loss: 73.9577\n",
      "Epoch 449/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 229.5040 - vae_r_loss: 155.6204 - vae_kl_loss: 73.8837WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.5040 - vae_r_loss: 155.6204 - vae_kl_loss: 73.8837 - val_loss: 1002.7432 - val_vae_r_loss: 929.2830 - val_vae_kl_loss: 73.4604\n",
      "Epoch 450/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 234.2025 - vae_r_loss: 160.1066 - vae_kl_loss: 74.0958WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 234.2025 - vae_r_loss: 160.1066 - vae_kl_loss: 74.0958 - val_loss: 1013.1260 - val_vae_r_loss: 939.3141 - val_vae_kl_loss: 73.8107\n",
      "Epoch 451/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 232.2179 - vae_r_loss: 157.9183 - vae_kl_loss: 74.2998WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.2179 - vae_r_loss: 157.9183 - vae_kl_loss: 74.2998 - val_loss: 1007.8415 - val_vae_r_loss: 933.8724 - val_vae_kl_loss: 73.9697\n",
      "Epoch 452/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 231.5240 - vae_r_loss: 157.4682 - vae_kl_loss: 74.0560WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 231.5240 - vae_r_loss: 157.4682 - vae_kl_loss: 74.0560 - val_loss: 996.2558 - val_vae_r_loss: 922.5893 - val_vae_kl_loss: 73.6667\n",
      "Epoch 453/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 223.4712 - vae_r_loss: 150.2740 - vae_kl_loss: 73.1972WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 223.4712 - vae_r_loss: 150.2740 - vae_kl_loss: 73.1972 - val_loss: 979.6110 - val_vae_r_loss: 906.3976 - val_vae_kl_loss: 73.2134\n",
      "Epoch 454/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 230.4034 - vae_r_loss: 156.3801 - vae_kl_loss: 74.0235WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 172s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.4034 - vae_r_loss: 156.3801 - vae_kl_loss: 74.0235 - val_loss: 992.6750 - val_vae_r_loss: 918.8106 - val_vae_kl_loss: 73.8634\n",
      "Epoch 455/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 231.2850 - vae_r_loss: 157.2539 - vae_kl_loss: 74.0310WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 231.2684 - vae_r_loss: 157.2386 - vae_kl_loss: 74.0296 - val_loss: 1001.1206 - val_vae_r_loss: 927.2725 - val_vae_kl_loss: 73.8487\n",
      "Epoch 456/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 230.0578 - vae_r_loss: 156.3702 - vae_kl_loss: 73.6876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.0529 - vae_r_loss: 156.3661 - vae_kl_loss: 73.6867 - val_loss: 995.4884 - val_vae_r_loss: 921.8304 - val_vae_kl_loss: 73.6584\n",
      "Epoch 457/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.1692 - vae_r_loss: 155.2603 - vae_kl_loss: 73.9090WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.1831 - vae_r_loss: 155.2731 - vae_kl_loss: 73.9101 - val_loss: 1017.4354 - val_vae_r_loss: 944.3460 - val_vae_kl_loss: 73.0896\n",
      "Epoch 458/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.2516 - vae_r_loss: 155.3361 - vae_kl_loss: 73.9154WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 171s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.2862 - vae_r_loss: 155.3703 - vae_kl_loss: 73.9158 - val_loss: 1002.5316 - val_vae_r_loss: 929.1884 - val_vae_kl_loss: 73.3426\n",
      "Epoch 459/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 231.9079 - vae_r_loss: 157.8867 - vae_kl_loss: 74.0210WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 231.9079 - vae_r_loss: 157.8867 - vae_kl_loss: 74.0210 - val_loss: 998.7527 - val_vae_r_loss: 924.9585 - val_vae_kl_loss: 73.7949\n",
      "Epoch 460/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 227.0987 - vae_r_loss: 153.8032 - vae_kl_loss: 73.2955WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.0987 - vae_r_loss: 153.8032 - vae_kl_loss: 73.2955 - val_loss: 982.2816 - val_vae_r_loss: 908.9769 - val_vae_kl_loss: 73.3050\n",
      "Epoch 461/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 226.1102 - vae_r_loss: 152.5212 - vae_kl_loss: 73.5889WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 176s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.1102 - vae_r_loss: 152.5212 - vae_kl_loss: 73.5889 - val_loss: 993.5927 - val_vae_r_loss: 920.3810 - val_vae_kl_loss: 73.2118\n",
      "Epoch 462/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 233.4863 - vae_r_loss: 159.6473 - vae_kl_loss: 73.8390WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 173s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 233.4863 - vae_r_loss: 159.6473 - vae_kl_loss: 73.8390 - val_loss: 981.0068 - val_vae_r_loss: 907.0219 - val_vae_kl_loss: 73.9847\n",
      "Epoch 463/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 224.3961 - vae_r_loss: 151.4524 - vae_kl_loss: 72.9437WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 224.3876 - vae_r_loss: 151.4449 - vae_kl_loss: 72.9428 - val_loss: 980.4093 - val_vae_r_loss: 906.8657 - val_vae_kl_loss: 73.5432\n",
      "Epoch 464/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 228.7748 - vae_r_loss: 155.1818 - vae_kl_loss: 73.5931WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 175s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.7742 - vae_r_loss: 155.1799 - vae_kl_loss: 73.5944 - val_loss: 987.9042 - val_vae_r_loss: 914.3207 - val_vae_kl_loss: 73.5840\n",
      "Epoch 465/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 227.7725 - vae_r_loss: 154.2779 - vae_kl_loss: 73.4946WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 169s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.7618 - vae_r_loss: 154.2679 - vae_kl_loss: 73.4939 - val_loss: 986.3479 - val_vae_r_loss: 912.8748 - val_vae_kl_loss: 73.4728\n",
      "Epoch 466/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 232.1085 - vae_r_loss: 157.8402 - vae_kl_loss: 74.2684WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 170s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 232.1070 - vae_r_loss: 157.8379 - vae_kl_loss: 74.2693 - val_loss: 980.5728 - val_vae_r_loss: 906.9341 - val_vae_kl_loss: 73.6390\n",
      "Epoch 467/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 229.5437 - vae_r_loss: 155.8093 - vae_kl_loss: 73.7345WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.5437 - vae_r_loss: 155.8093 - vae_kl_loss: 73.7345 - val_loss: 983.8571 - val_vae_r_loss: 910.0498 - val_vae_kl_loss: 73.8060\n",
      "Epoch 468/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.8816 - vae_r_loss: 156.0326 - vae_kl_loss: 73.8492WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 168s 54ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.8758 - vae_r_loss: 156.0268 - vae_kl_loss: 73.8492 - val_loss: 997.3183 - val_vae_r_loss: 923.9779 - val_vae_kl_loss: 73.3397\n",
      "Epoch 469/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 230.5627 - vae_r_loss: 156.7980 - vae_kl_loss: 73.7648WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 174s 56ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.5422 - vae_r_loss: 156.7792 - vae_kl_loss: 73.7631 - val_loss: 991.9821 - val_vae_r_loss: 918.5114 - val_vae_kl_loss: 73.4717\n",
      "Epoch 470/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.6231 - vae_r_loss: 155.6730 - vae_kl_loss: 73.9502WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 170s 55ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.6250 - vae_r_loss: 155.6751 - vae_kl_loss: 73.9500 - val_loss: 995.0155 - val_vae_r_loss: 921.7620 - val_vae_kl_loss: 73.2541\n",
      "Epoch 471/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 226.6179 - vae_r_loss: 153.0553 - vae_kl_loss: 73.5626WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.6179 - vae_r_loss: 153.0553 - vae_kl_loss: 73.5626 - val_loss: 991.3683 - val_vae_r_loss: 917.6692 - val_vae_kl_loss: 73.6993\n",
      "Epoch 472/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 229.6153 - vae_r_loss: 155.8560 - vae_kl_loss: 73.7593WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 971.80339\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.6153 - vae_r_loss: 155.8560 - vae_kl_loss: 73.7593 - val_loss: 981.2828 - val_vae_r_loss: 907.9587 - val_vae_kl_loss: 73.3246\n",
      "Epoch 473/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 227.0432 - vae_r_loss: 153.6683 - vae_kl_loss: 73.3748WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00473: val_loss improved from 971.80339 to 970.61951, saving model to vae_kdh_ckpt.473-970.620.h5\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.0432 - vae_r_loss: 153.6683 - vae_kl_loss: 73.3748 - val_loss: 970.6195 - val_vae_r_loss: 896.8918 - val_vae_kl_loss: 73.7276\n",
      "Epoch 474/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 227.3820 - vae_r_loss: 154.2945 - vae_kl_loss: 73.0876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 970.61951\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.3820 - vae_r_loss: 154.2945 - vae_kl_loss: 73.0876 - val_loss: 978.2368 - val_vae_r_loss: 904.8460 - val_vae_kl_loss: 73.3907\n",
      "Epoch 475/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 228.1252 - vae_r_loss: 154.4982 - vae_kl_loss: 73.6272WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 970.61951\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.1241 - vae_r_loss: 154.4969 - vae_kl_loss: 73.6273 - val_loss: 975.6157 - val_vae_r_loss: 902.1753 - val_vae_kl_loss: 73.4398\n",
      "Epoch 476/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 230.2170 - vae_r_loss: 156.4836 - vae_kl_loss: 73.7333WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 970.61951\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.2142 - vae_r_loss: 156.4813 - vae_kl_loss: 73.7327 - val_loss: 984.9294 - val_vae_r_loss: 911.4649 - val_vae_kl_loss: 73.4642\n",
      "Epoch 477/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 229.1765 - vae_r_loss: 155.8974 - vae_kl_loss: 73.2791WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 970.61951\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.1765 - vae_r_loss: 155.8974 - vae_kl_loss: 73.2791 - val_loss: 971.1486 - val_vae_r_loss: 897.7004 - val_vae_kl_loss: 73.4479\n",
      "Epoch 478/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 228.0263 - vae_r_loss: 154.6186 - vae_kl_loss: 73.4078WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00478: val_loss improved from 970.61951 to 968.93828, saving model to vae_kdh_ckpt.478-968.938.h5\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.0263 - vae_r_loss: 154.6186 - vae_kl_loss: 73.4078 - val_loss: 968.9383 - val_vae_r_loss: 895.5768 - val_vae_kl_loss: 73.3612\n",
      "Epoch 479/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 230.3112 - vae_r_loss: 156.4873 - vae_kl_loss: 73.8238WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 230.3050 - vae_r_loss: 156.4811 - vae_kl_loss: 73.8238 - val_loss: 987.9843 - val_vae_r_loss: 914.2454 - val_vae_kl_loss: 73.7385\n",
      "Epoch 480/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 227.9493 - vae_r_loss: 154.2802 - vae_kl_loss: 73.6691WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.9493 - vae_r_loss: 154.2802 - vae_kl_loss: 73.6691 - val_loss: 977.0706 - val_vae_r_loss: 903.7440 - val_vae_kl_loss: 73.3262\n",
      "Epoch 481/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 226.6651 - vae_r_loss: 153.3332 - vae_kl_loss: 73.3317WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.6585 - vae_r_loss: 153.3261 - vae_kl_loss: 73.3322 - val_loss: 979.3749 - val_vae_r_loss: 906.0282 - val_vae_kl_loss: 73.3479\n",
      "Epoch 482/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 226.0999 - vae_r_loss: 152.8321 - vae_kl_loss: 73.2679WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.0999 - vae_r_loss: 152.8321 - vae_kl_loss: 73.2679 - val_loss: 985.0313 - val_vae_r_loss: 911.4045 - val_vae_kl_loss: 73.6274\n",
      "Epoch 483/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 225.7265 - vae_r_loss: 152.5777 - vae_kl_loss: 73.1489WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 225.7265 - vae_r_loss: 152.5777 - vae_kl_loss: 73.1489 - val_loss: 983.4204 - val_vae_r_loss: 909.7869 - val_vae_kl_loss: 73.6341\n",
      "Epoch 484/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.0307 - vae_r_loss: 155.5283 - vae_kl_loss: 73.5023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.0201 - vae_r_loss: 155.5181 - vae_kl_loss: 73.5020 - val_loss: 987.1095 - val_vae_r_loss: 914.3979 - val_vae_kl_loss: 72.7119\n",
      "Epoch 485/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 224.4015 - vae_r_loss: 151.5929 - vae_kl_loss: 72.8089WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 968.93828\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 224.4632 - vae_r_loss: 151.6554 - vae_kl_loss: 72.8080 - val_loss: 983.3237 - val_vae_r_loss: 910.3485 - val_vae_kl_loss: 72.9750\n",
      "Epoch 486/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 228.9157 - vae_r_loss: 155.7700 - vae_kl_loss: 73.1454WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00486: val_loss improved from 968.93828 to 967.84894, saving model to vae_kdh_ckpt.486-967.849.h5\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.9157 - vae_r_loss: 155.7700 - vae_kl_loss: 73.1454 - val_loss: 967.8489 - val_vae_r_loss: 894.8559 - val_vae_kl_loss: 72.9938\n",
      "Epoch 487/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 229.5649 - vae_r_loss: 156.0513 - vae_kl_loss: 73.5137WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 229.5588 - vae_r_loss: 156.0439 - vae_kl_loss: 73.5150 - val_loss: 987.7773 - val_vae_r_loss: 914.7897 - val_vae_kl_loss: 72.9880\n",
      "Epoch 488/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 223.2133 - vae_r_loss: 150.3008 - vae_kl_loss: 72.9128WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 223.2136 - vae_r_loss: 150.3016 - vae_kl_loss: 72.9123 - val_loss: 991.4573 - val_vae_r_loss: 918.0764 - val_vae_kl_loss: 73.3815\n",
      "Epoch 489/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 225.1042 - vae_r_loss: 152.1209 - vae_kl_loss: 72.9834WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 225.0911 - vae_r_loss: 152.1087 - vae_kl_loss: 72.9826 - val_loss: 982.1422 - val_vae_r_loss: 908.9525 - val_vae_kl_loss: 73.1897\n",
      "Epoch 490/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 221.7251 - vae_r_loss: 148.8586 - vae_kl_loss: 72.8665WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 221.7251 - vae_r_loss: 148.8586 - vae_kl_loss: 72.8665 - val_loss: 981.0861 - val_vae_r_loss: 908.3149 - val_vae_kl_loss: 72.7712\n",
      "Epoch 491/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 226.6243 - vae_r_loss: 153.1277 - vae_kl_loss: 73.4965WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 226.6243 - vae_r_loss: 153.1277 - vae_kl_loss: 73.4965 - val_loss: 988.0604 - val_vae_r_loss: 915.3688 - val_vae_kl_loss: 72.6924\n",
      "Epoch 492/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 225.4718 - vae_r_loss: 152.1324 - vae_kl_loss: 73.3394WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 225.4718 - vae_r_loss: 152.1324 - vae_kl_loss: 73.3394 - val_loss: 1005.2033 - val_vae_r_loss: 932.5290 - val_vae_kl_loss: 72.6738\n",
      "Epoch 493/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 220.5663 - vae_r_loss: 148.0685 - vae_kl_loss: 72.4976WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 220.5896 - vae_r_loss: 148.0919 - vae_kl_loss: 72.4975 - val_loss: 999.0421 - val_vae_r_loss: 926.2355 - val_vae_kl_loss: 72.8074\n",
      "Epoch 494/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 222.9153 - vae_r_loss: 150.1662 - vae_kl_loss: 72.7491WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 222.9153 - vae_r_loss: 150.1662 - vae_kl_loss: 72.7491 - val_loss: 1004.1355 - val_vae_r_loss: 931.3072 - val_vae_kl_loss: 72.8285\n",
      "Epoch 495/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 228.7411 - vae_r_loss: 155.0371 - vae_kl_loss: 73.7040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 228.7379 - vae_r_loss: 155.0337 - vae_kl_loss: 73.7042 - val_loss: 999.9363 - val_vae_r_loss: 927.3535 - val_vae_kl_loss: 72.5831\n",
      "Epoch 496/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 227.2784 - vae_r_loss: 154.3645 - vae_kl_loss: 72.9140WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.2664 - vae_r_loss: 154.3535 - vae_kl_loss: 72.9130 - val_loss: 998.7591 - val_vae_r_loss: 926.1938 - val_vae_kl_loss: 72.5637\n",
      "Epoch 497/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 223.5004 - vae_r_loss: 150.7061 - vae_kl_loss: 72.7944WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 165s 53ms/step - batch: 1563.0000 - size: 32.0000 - loss: 223.4870 - vae_r_loss: 150.6936 - vae_kl_loss: 72.7935 - val_loss: 999.5971 - val_vae_r_loss: 926.8498 - val_vae_kl_loss: 72.7479\n",
      "Epoch 498/500\n",
      "3126/3127 [============================>.] - ETA: 0s - batch: 1562.5000 - size: 32.0000 - loss: 227.0314 - vae_r_loss: 153.9760 - vae_kl_loss: 73.0556WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 163s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 227.0233 - vae_r_loss: 153.9679 - vae_kl_loss: 73.0555 - val_loss: 1009.3102 - val_vae_r_loss: 936.7558 - val_vae_kl_loss: 72.5547\n",
      "Epoch 499/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 225.4735 - vae_r_loss: 152.3140 - vae_kl_loss: 73.1593WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 225.4735 - vae_r_loss: 152.3140 - vae_kl_loss: 73.1593 - val_loss: 1002.2524 - val_vae_r_loss: 929.3812 - val_vae_kl_loss: 72.8709\n",
      "Epoch 500/500\n",
      "3127/3127 [==============================] - ETA: 0s - batch: 1563.0000 - size: 32.0000 - loss: 224.0186 - vae_r_loss: 151.0746 - vae_kl_loss: 72.9439WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 967.84894\n",
      "3127/3127 [==============================] - 164s 52ms/step - batch: 1563.0000 - size: 32.0000 - loss: 224.0186 - vae_r_loss: 151.0746 - vae_kl_loss: 72.9439 - val_loss: 992.6500 - val_vae_r_loss: 919.8057 - val_vae_kl_loss: 72.8437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Train the VAE\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "        # checkpoint\n",
    "callbacks = []\n",
    "#weight_filename = self.data_path + '_' + Config.config_yaml_name \\\n",
    "#    + '_N' + str(config['network_type']) + '_ckpt'\n",
    "model_ckpt_name = \"vae_kdh\"\n",
    "checkpoint = ModelCheckpoint(model_ckpt_name +'_ckpt.{epoch:02d}-{val_loss:.3f}.h5',\n",
    "                                monitor='val_loss', \n",
    "                                verbose=1, save_best_only=True, mode='min')\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "# early stopping\n",
    "patience = 50000\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, \n",
    "                            verbose=1, mode='min')\n",
    "callbacks.append(earlystop)\n",
    "\n",
    "# validation_steps = len(valid_data)//config['batch_size']\n",
    "# print(validation_steps)\n",
    "train_hist = VarAE.fit( train_generator,  \n",
    "                        steps_per_epoch=len(train_data)//config['batch_size'], \n",
    "                        epochs=config['num_epochs'], \n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=len(valid_data)//config['batch_size'],\n",
    "                        # shuffle=True,\n",
    "                        verbose=1, \n",
    "                        callbacks=callbacks, \n",
    "                        use_multiprocessing=True,\n",
    "                        workers=48\n",
    "                        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB42UlEQVR4nO29e6x1S3IX9qtea+29zznf8947vh7POMzYHogcFIJlOZYgCOEk2I7jIQqyTBAYsGRFMQkEIrDxH/BHkHBIICAlIBM7MZGDIWDERCIJjmOCIsUG2/g5xngwNp5h7szcx/c45+zHWt2VP6q7V3evXq+99znf/u49de/59nr06q5+VVdVV1cRM+MO7uAO3rugXjQCd3AHd/Bi4Y4I3MEdvMfhjgjcwR28x+GOCNzBHbzH4Y4I3MEdvMfhjgjcwR28x+HGiAARfTUR/QIRfYKIvu2myrmDO7iDw4Buwk6AiAoA/xTAvwPgkwD+EYDfxcwfP3phd3AHd3AQ3BQn8BUAPsHMv8TMOwDfD+CjN1TWHdzBHRwA5Q3l+wEAvxrcfxLAv9mXuCgKLsoSYIbjSwgAiOKElmtJeZckVZs886yT1pZBJB/k+aKxEjn61r9N8Z8NnMWJ3L8u+6DdpkKmBtnnGYz2gmx/5vK/Cc40LDvNP8SJgaGWJP9Pmz746ZYVJI9zZQAEAkBEqMoSRVGgLAusVhUePHiAsqqgFGGz3mKz3aKuGzSNxm67QaM1tDbQWsMk9SEiKKVQqAKlzdeV+c47T95k5vel9bopIjAKRPQtAL4FAIqiwPs+7zUwZBBI46h2gvqvGMa4bmIwMxQpOx/spAhGM7u0tqEUEZikDDaSvVIKiuRbYwyICCDpIHaDIshTyklGAjOMIG+7FzYf19U2HQhEACkV5EnyHRtbnuTjx6xhaG5xUIpaHMNxzRxNICL49kwJFPl/kvZiBpHN333b5tg2LzMY7OuWThwK28e2pe8f+17SBD3LRupqjK+UlOHKRNC2FmEl+XbohiuKg7QU9oNriQRX24a+F5mjPiTVNniLE/u2IhAUEVRZuE+DPmIY10fMko4IpSrw2muv4tHDh3j1lUf40l/7fvyOb/govuCDH8RyeY6f+emP46f/8U/jU5/8l3jjjTfxy7/8y3jn6VM8v7zC86s1mkYGMikCgbCoKpytVrg4v8Drn/86Hjx4BAKw3azxA3/nf/sVZOCmiMCnAHxhcP9B+8wDM38XgO8CgGpRMdvODyd8ONVkMDDIdyJLGt+nwTVs/3GY1oKxL5kBJoBspxshAkopP4H8twmppyBLtkSA7IBocWjzb1FgMBGIwjzZzVYZtA75oCIUckg2T3LXNg0n7QVLTBHi5WYRkKQNqmfLDuvobgIyYPPi6JuAR2lvHR4U4AtXRtDKzL6utqV807lSHdkgW7bk5yZsUHDSjhSg7TIkf9l+yEE6cvfu+yStxxHhN/bCGNv3AeLG+DFAtr8YBKOBpq5R1zXqeod616AoSlTVAlW1gFIF6u0O66trXF0+x/X1FbabDZq6BhttCZ30jCL5IzcmASgl7WBMjT64KSLwjwB8hIg+DJn83wjgP+pNzbLiUdDATlsRr6RyLw0fkwgK+qclAG1Xw35DMJLecxkENycLKtrVjdvyQjyTceAYAZ/WfcccDL5wELpJ6UaWyfCUICFW9lOVDGLiCKsWr+hZ227kJklUTjJh3cQJ6FYnjc2XORz8lJk9QZ420w6+FDekI1Jp2ZLeEZIAH25XcU9T0zYI6k3dNy1hsh1Ffho7DsfhFuAZkIKwzGh0mpZgORyES3CFwo5DAWM0mqZGvaux3dYwWoFNAeYSxhAur67w9OkzPHnyDFdX19hsdmhqA4JCoYRDIaWgCCiVQkHC3RZEKBTBGAMOykvhRogAMzdE9AcB/J8ACgDfw8w/N/xV2NAhu9w+DYckdxNEOcVvw3VStRTbs4KWTXe0YhjReGInidNFJ86QMs/ihT+PQDwI06mZEsox/Clts7Cx/DVl07op0Ao+iD92K6DP262ICQuSpksIdvyKOqm8yBbhlabiTA0CXAK0ZbWOkzlBpgtkOy3AgClEMyg9zC3GkUAiu6sKhSoABq6vd3j+/BKXl1fQhnB5vcFu16BuNOpGY9swdhpoGCAqALIirZLyi6L0f8vlCqvVGRpdg64L9MGN6QSY+e8C+LtT0lIwtKM8gn/9kCS3ynanWyijEsUDIZq4FA7AkL0L88rUyf7jCVBndQ1x7cnJzZWQFXYiQRZk8LBbRVwm6RxEPgvfrrkKISFArm3AXsZl4mzfpJOaW3aoFY1cliEObvKE8yf4N5LRo0q6ScYBzo4QZCZ71F7tNVvK7b7ggEVP06YQj7iQerQ1IG7XXIdbfoS13zAYxhjUusH1Zos333oH9x48wgNNuL68hDEAqUL+qLB9RICyZErJCkZWX6SUEJfFokJZKBjjuJA8vDDFYAhM8cLQKp1C9VMLRMlKlPRfqozzrDkAptxgSxGagnR6MeEjj26fUi3Ng/xgHsA2XzYlr9L7nq8pwMjhma76qSIwrUPYInGfxiVGT1LmLEI6JDjtiprV5FOSfmC3gZ32LsIvXNHTelL7XVAeZ4diQKwGVhTDouWv6xqb7Q7Pr9Z4443PYXV+H7sGePb0GXaNlp5QSv5gJz0pnz2lbURWEe6Unaa/HU6CCDiIhlpn5ifXHcJNnTHTmQDhsxRi3jKDgHvMmdVzgACkjECGMZBsEu4ieJlbzbt8EHeqnSu/wz0MUxeZHIHM7/EMJk+Ma7xaukUr5dwCpiPGK7sgJ2yPm3g9dYrHSpddCheFMCOHU44zc1xIL0sV5tUzfmI0ZEfJ1A2eX15hs93iar3GZrfDP/7Jf4K3n1zj8z//dXzyVz+Nt588x+V6h11j5BtbB7er5TlUI/pHrQ3qRuP55RoNE+qmxvXm9hWDNwT9nRCI99NW8lzW+wClIzJ4tWeWUzPzVe3bAz8GMGKRYEYR8fxLRbcbgpBW9HZNTMhDrrAleskX3KUn7ovsIxomGE4MYGastxtsa4Viu8W2rvHxj/8C3vjM5/D48UPs1lu8/eQdPL+8xOXVFXa72m/ltmW1lddaY0cNsFnjc29+DuXTBQADrU+cCPRyS8G7kLXqigfxbyAyBg+mjt5QQpVMYhxyVCbHapBdAfPpemlVrjFyAyrQlDu2tiOhRMlbQpFfRIdl4snmSJSTzfvIN3c7eAJ18DxJIkKEmoHYBqiLu3sW7uj4+2ivuS2DQ46oh+DGfZCM4szYdXmJBp+x3W7x9ttvY7PZ4Mk774C1weX1Nba7LbbWaMgYIR4mEGFsRmhgYLiGNgZMBKUKW+4t7w7sA6EYEOpR842Wz+MY62A379wQiid9vOKkcktPOVGaWHrO4UQjK8tkoFYb4f/lERLA6U1IzNzIHmn9ZDeA438mQLh6c9QrHCopc22VK8JLX0FPkFvE85xAJBL1NlisphRiIWwEcWYPI5DbYYC6rvH82XNcX1+jKMToqK5raKPBzNC6nczMxtoIWHUnA9oARBpKazTaWBGHUBT9Y+dkiABimjZzuPelToXOG2CXXe79UsGUr3Ewbn2fT5BPDy/ElZFjjXuWvxtDJSYAeSVmzyrO+eaK8hjZRWD/yy1xzebbEi5lFXwMMVi73qz9Pft/Wm7O7QI4LoYS61G2FqjGGDjrU1b9x4ROhgh0FWZ7jJxe/nqIEHD+u+lLo0+QkxljwsDo25Vo+YD8+3AlSvMIWdvw3j8LRiD5FTXmPNJd7CnQNS/u4Wac5WRoQemxQdBI3b32gdK75QQ4eJwy3T0HJolB3HM9AI4LiLkqDra/0U7gME0g+0Q7alG5aRsQBjYHTokITJ/06arb0v5+lnqonDwNSCYSEMitByxtfXmMo55k05Vb+xP3oxzvtI8B5S+zZw3CdH259xDg4HVQSPAgTwDyEtP8w1UdWb6XxesSP0rextO8C8nRhaAtx/osLtnd5N708z4CJ0MExlji4X39gRbrpA2Km1CuZB+/T6lvf9FddqJTfJprctagW6oM6yFOqY++tHdJfSncew+/yXMcXezznNE0CL7NcQlewp46lVu+aAj6N1S41TFEeocQz5RTjd91HvuyOO4b6quV44iGV4ZIdB4Z/0OnM0+ICPTDIQvvywvH0F/s33B9a/etdkV0KCCdXUfU74xUqm+bcUoGg2M3qdZeNTrC5DgZIhArTnrXyREI5dvpTdo5Thpn11UUJaNimkIwL8+3b1MFFpJxlu7V80CjpCs4WrPYiYMmx2kcMtx6Wdu0bTNXQKATcdUIOKvOKeERPPpsBPIwxJ2GuEVvovd7Zh+Uk4qjKQ5tedwZOMkHGTgZItCrxQ5kpChp9+MABlr2lLmKbAceMWtgKsVCLwUcfdeTW5/EFj0LdQQUNUW7LdcS+tAmgRKimK7TnHneKT95GXUHtfhQIraE7/zTvVdoOWqe7abwFGVy73kjexMTOgwOq5MhAh2N94z9tvbTQK7edy5Zcprp15uFdBB1lGLBbefZlOUkn7Tv8FI79kO5OIPOmL5uiF4MPQsJgPcxEBcT2fhH5c6bgDGR6GoU4uGVdhTGjAMHIOF7pg7bcMFkIKPCmAV3LscH4L2pizh1GBH0DmDv+4WRvtTHHSD7zOFjLFQnwQmkmlbmYP+Yu3vrKZPgHYAkolOOm0j31O1NfjXsEv3ZjT6XLcxppjsrTU79H/Ou0Qqf4SPQrUle0RVm2x5yajmurnVdRrfhtemxTBf1OgeTKi0vm3emnADz/G5HnG/uOHqAnsU9MwgCboE6FUFScudjm46DdDkxGJkuyWhqJuha+iRtBydBBEI/be5JdLorOIM+pmztu0sfRwMhmzQzQGZSgdkEIETQFhh2YG9+HE+YHNfai+NQ0vSln1ExsenXT3J03Rnu1BK9QZ8K7vh3QiRywHO2i6n1JuRtmWL0Yrrlh4o0DJErKiCOHRo7pKTm6DeR+Htpg0cmfBgR/JGJksBJEAEgkPuGDDOY2nbuaD4QNPyAkJspN9Qud0RLDtrTXVMwcJGlz1EWMth7k/Si576dtKPAPc8DfDO526vBqdyDHaKxH5fVlavTPMYtQoeIy5RnfRwPIbKgJVgXY7YdusnjW6+Ma71RReMndEzIbp1vE7SGjEOEIbWcTO0GMjCy8g+19skQAWCIAISJsKcSZkK+U54dK+8EcivyTVV1UuG3pA/pSDK3UWAWulwf9b+VJI4AeBnEznozpfH6eLC+b2+uQ/ZWDBLRFxLRDxPRx4no54joD9nnrxDRDxLRL9rfx1PyCzkBf/Kqm6rn+fh75981X3b8pTuEkeZ61HGaYbP7urmXOM5Cqh2tFN46WdOvau3hlBSfaNXrBesJOSPWUFSm8yZsK9FZcQEitn89Bfv6pz2U6TGbRzeXzJLZqTiiVT9FJ7yPVuGovhjpq6B/ooYKqZG7p/gyxSvLKfV33CG7Aw2AP8rMXwrgKwF8KxF9KYBvA/BDzPwRAD9k70fBu0GyBMBPxOxA56ib2+8OhywBSvqkTUz2D70TUvADnJrDXwcfxQ65gmKpzTRsn7S+042VuC3Fz73QcenQKtT+tf/ZRxxULlnWO/M3aKuYTAxdu1gU/XXqfUbsWX1y17m+TGtMcT2yFegRx1L8XR2kaYYpt6cf4cT2zyxR9IQ2QWkAhubH3kSAmT/NzD9hr58D+HlI5KGPAvhem+x7AfyO8czsIPcDfl+sThA4+omuPVEI4EaYPnZ8UD83dLPQLdMRx4gQBOJ0xGVn0uQgN/kcV5LLs+VYOPpOubSOG0H4l/YRe4LGJpxseQLiF4UOxgkXkfm2lwCFSdIMqe9lC0fRCRDRhwD8RgA/CuB1Zv60ffUGgNcnZzSxXv26Qw5SYdqM8qtyHqZlEQ+iIOskp4HVO8ft+jRuNUudrUyb0MninGd300WNgCieQPjtRDriJt6k5DYhhbM0QNVz1DZNekTbgfPt3/XZyIAVe9L28LrMYPUPDdBCT8pJccF2tntFluh2kLTlJ8eFowbIEJjwjrmTwucb5BJVeQIcTASI6B6AvwXgDzPzs8hfGzMTpRut/rsoDFl4HHV/k8uJMNA4nUGbRaU/g34uhruf9VOMns/jkXtUjmlIEoguY4pBFpcssXDJ7SWHz1P7As6thEkaR1R6vH+ksnlnzliDC6FvyYKBkLg4ShMk4TgtgvydI9acNiTFj4P4BE7jP3ysI21XDnBpK5j1KZElNl04iAgQUQUhAN/HzD9gH3+GiN7PzJ8movcD+Gzu2zAM2WKxYFepLtKOxE5wOLEP8fCdGD2aPfkHso++zPop2AOm6kC6Q71dTT1Gg0Sx2x/9TIUdiMpddmZhpglbApLFNUjW6RduOSQAfuvPhXlro7SlAcQ8KchUJHmWm/xZ7NtFLOIKkuzHz0/kIVpLyXEbMQYhKXAi9hQicMjuAAH4bgA/z8x/Lnj1MQDfZK+/CcDfmZgfxI96JMhE8K7SFbyboSN/hM9DSJn9NllH6u1hNProMimGIoaNy9EzokYmCGd+UzYxXEB6RPUpMG05yCFiovuuCDoOh3ACvwnA7wHwM0T0k/bZnwDwZwD8DSL6ZgC/AuAbpmTmWLH+45mBjNdhP/sJRwdyy83kBXmyhNspLv8yWZ86HPJMrmGyeBGwkaMCZCDeyfKSvHYcXDsQxcGtcBgSrXkA90DMCURyX6zDNOouoiwn5HZ2nFiglJRPpg35GLPSbVGypkkQQR/J2VszImyyPlYgwyOx/zhWKdr6BqJL1CD2IYX3aOsW95lju9ry2NanNYoa3j3bmwgw8//bwb+Fr5qfH5AbiJRreE6aOxUdewlJ0FFeDpvLkscMICNmzdPhlZ64G4pTcihQOmHR30Fda8M+Jp8HiaSzuAzl3MJGlTcMsE4GbcQqR53aSrUEdIKcdnAI69p9TURQBQDt3qeyeuZ7W2RkgBqjiLSHpQ2ShJy0b1hHm7ar3HR4p/2WJor7qWX5nVl2RmwYYaFPyGIw5b1yq31/ZTp70eEXQ40w09lGm7MrYOasDssJB48bhZxP2s0m1z7db4essCdDNL4pM0Dlt1CAKghlJfhpLcNSu9WQ007KVbB1hEqdtgovwwfUVfTZlVDi+EHCgfuFOea+XEsSCEoF6UweR4ouwgntPuyvVy+HS10z6dBWoT0UF9xYzIWhDPUP1pZEh/n0wwkRgT1hmNOMfu/gOBBODccFVBWjKhnVgrFYEQgGdU3YbICNbokmmySjoXLcqpyZi25CRZwiAS70PBugrmHtTwBSCtBpmQnhgIaIBAxwMDV615808C28OOE5j546Cu6JSNK5DriCiHMgV1m0QVXjmqQ1G4KTIQLcuQD6mKLcjlQ2r1nlthzBbAEhYUP6vu+gPVrQREyyPT6DWxkY5N2Mg4EbPFYKKEtCVTGWCwIzwRhAKacvUHDafAbsoZ1gTU/KTx17IgncYeUwL1aE+/qGKVgFnXDN7UId6GIcI80suozghJp/K5MwFnvcx0SEQhEM2yPwtt6tZWiu5Vp8oJwhk7STImkzZ9ZodFuYsy8Ij3Q7rinsqqg9R+YKcEJEoDtQU/aufcRpy1rqu88EziASl5uBkNXuKqmGeHh0jXLyaiF5M5RtHzfdKZKjMXIYW5QSOFsDEiJQFIyyAMpS2PBCMZQK2dqetgrbpEMM4LfsOzY7kSTXigHMrUghyjE3cJKyorJjcUWunZJArAWLUuqjnI0GyWpeFArGBwNtCUCQcyAmdMmCIwBEgCoYZSEyDDOBjcXLfs/Jb5tTyDu4fMnSmuFOPx0iMIVk9YEn2hyJZFNIQruAtIxUv8Y8PtJJAetnvxwvzRcYLxPdAB5p+bm6UP+rfMoBDKl72avVj9lYRSwTvtBQBaMoCASNogCKQkJgadMSANfTKQfAnDec8RPSvjT2O9ftREpWZLtDwWSNfFki+qQycTjZjc8DMMZiFryXSc8oCo2zc0ZVEUqloA0sdyBjYrdj1LWUqf3qHdc39CzgTJkdF6OUEqVqqbFcKAAKWis0tXYYBrTMsVOBKBAsTN0Bkd9NcXBCRGAYDiARg3n2Q6603PJrl/djI/cSgD/gogB3UEcGHEEb5Vdx2aozlpWdx6tRJC23wMH7NgwXITZ9cdwHBdxIFzwxYvjv2/wYpAyWK4N79wmrFVCVwHZnxQsWAq4boGYDowE2hddFpCUFUgu8iMIAGyPt6AQcOYgANhJ41Jsnh8QgU51whObErBycGBGYE4aqhYmcsZQwbnYY5Nr3LsyvFTEp1t5kB0GbRw9ZO9IeYrhW9wscmUcUfEHJQA5GlRVZ4U62MVhYYmZoI2GvnA6QFPyNy8Jp0zkY1D5ffx3K7e5KvvPSejCrwjTklncEKz0YZA0GTHJ6KUecnCijFLBYMBZLoFoAhTIoNMMY0T3UNVDXjKaRgKBh3ulooMg8z4ouRpgPwwA1wM6iorXdZk3q1tY1gGgS5LjJ/nF/MkSgNZyYylqHH8cXnbU6srPP5xtO/b493N7iQ1asj5vvL9rj2K31AMGaSvUSEWniR/kPErrV6huMl4mbBlA1wAayKjJDlILkFWdeEvIrmpQXRxMO5V33iP1PPs6pIwBkuQ54a0FnDMRsrAgnrd2xfYqLhlKMQgFVJbqOooB0NMnkbRpgszHYboUYGC1yfCiqhXkK92TbgBnGnTtgR9aUr7DpiyHYxxb7YsPyxzv+ZIjAjfD7R4cpPMdhFTmdZhjGwm/R2ZVMa2C7JdQ7he1a2HIZ5MIqGy1/PtuIALgHcyiVmzxtHrEzDreKl4FW3y4GbKCHInRafMhyOqqQyU8g6IZQ18B6Q6hrQr0lXF8RdjvZlkw5CseFOK6ClF3kjNVBeIIhv1oD2oQc8Yw22YOLBk6ICOS8tubSZDkEz4/3sz4dy8MOhezwb5ny8zCVa4iHeb+4MUpmJnT2kFAz5TsvDycZsP239eYr101jZWmWGddaEDK0ZmhNibHMOJs6btIs74xh0dgHYgyIQIVs34nSjWBgYLSZ5P3LbdUVBaMs5ZeU8dt5MARuCForGFMgpGVWE+HzIsWeGjhCZTqWfI4Dti0/ZGrd3xRBVrZ/xpv5dIhAFxx7RJ5QsvMOOzbrvBVJbip0W2NM9Eipst3uRqICmA1zV33KXI1l3BfG3CcdpChdESXdJwccV+BW2Xgldmx5L+0FRW0YTfyeBsphzACcYxrlymdZOIgUlBI2nbyCIpayO6uEXb2VIihF7QruU1gRxqYNdUNt2wf5BZg6O4K8Jj8Yvv3LzmCLzB2TJ0MERhV2AwO7H7qtwTG5FIqdbbShMjgYAvtSAWrlRYvqHD1IruSQWPXlNduSIirIydmtuy9ZGcVAxmglyq1ANlcKABk4P4EhIWMI55A3p40rmK1NNNmsQs7+KiV6iNZfogKRCdogkNlTDjRYtUkZqEJsA1rjHNHkq4LkT3GbEbs2sY+ShUjaiXsJwDDsy98Nl3QyROC9A3Nl3z3hppQL7GRcRlHCW2+KaGs1dhlUSNlpH8jngNUVMAAzfQVLW5AtAVWO+JGw2zCMuhbbBVVYi8VgLSd00WX/j9XMuz8ATAZKARUYtAKqwqAoGHVdoqlD+4BWcenya5WkFJtOnwCcDBHoZ/Fb6ucG3F5jO2eKhr68htmtDkucz3oImU6eqUoEObGnjwOKVpwWLVdS98UMCsHpTcsuhzmFuo7QfMqlImo9DnvWmi2b7exhAlO70E6eCJ1G7WDPgLH7kO5knTtarIyC0nLkVmuD1jORa47uwBJDIzFyahqFemesMY9YEpAiv3NQFMIdyeEjstxQm48QEfJ4RsxoT0cFwkautnlwYyiZI2NLzskQAYEc6smzzIDo5BLsD6c5x5rkXLm5DAMpcMJ2Yxb8JB+TwcO7IJhWbsVy6bibZvKq6lnqcAYkQbx8IvaDXakwaGsgX7tP0MrJbo7FHZJWKJ387pPpnFOLj5AiNi5PUR4SGMZtEQaik/sNYyS5yWs0QTfAbkei4GMAhfWZoODbQim3BRr2czDbMyJPq8qMfUeG259Sp4HOD6sQ3M/hNU+GCHQ5ATdZ3f1QOKdOZgg/znMZYbOPZJdcp19MDZriJoYDQngENi4o3gmRARX5LaB2kKUx/DpMBqUDMN0fH7qXpUuMgozVlgOk3KpLvYouRwBkVQ10CNyWoQ3b7TKXR9gIQ/2X1pFQqMJiy2Bj8TNG9uK90xMOKFPKXNl2ttUW9l5ad1vAEgHBpSgZRQGY0hKCQlkHKu0yHPpM8CJAdj63RMlxTO7aN2T4MXW5xH5dz3jbnQwRuIMMTObap6+Wk3LLcDpELMeFF0C1YBgNNA3BGHd4hjrbWiFhYKuk88yce2+sB6Lcvn0wWYdAkYgVqlD2MwMD8nkajwgH3wheIXhiaecxm/ZPkew5GC3bjK3nHifqtL6DpMrt+p3uGvRBu5tAmXofr39TOHkikGVXp3/deTKlKTtfhRQ5GpjDTjqnlNOJjuxfcvfRnMxDmXeGDsDVx/0qYqjCoKoMlishBEUJNDVDa2UtA1NlVyrCZQKc2Lbs3Rnw+Aw7yxQPQgWKosByuQAD0E2DpmnArAPikhkLyuEk+HR4UbfbYAh1A9DOTnVWKCpGWbC16EtWZYqvHYMU6wO52/+Z710do9EQ6Tyk+JCj7BiKj3T9yRCB1h4gkkY9jG0hjYraHVaZkgT9mc9Rz0yfbi7HPOIytkKBILQis0xvl3MO8Ej1C+GXvoRM+fHqrwqDsmSsVozlSkQBVbTWfyIO5M1b3S6A26bzLDh7pjtSAKblhxh1W8mJiwWUKlCWJarFIpi4ogQc6g1vvuuQ9RO6dQMm3Io1h1YtESt3DK4Q1aHDtUM4DscZwIo9cWVS/PLjgYK02RkSNFI3DsbwiDxG3IECwI8B+BQzfx0RfRjA9wN4FcCPA/g9zLwby6d1D+EesFWQ9EySAZmozxjQpRyD7kR2Ay79vufA0yz2oEvJuIcQDuYSrpjcHQgcJ47KD0tzDkPl+CyjWhgslwb37gPLJQASHcD6qj0/b0ww6sPakFjrKaX8vcexAbQJjHb8IjeH5AKkFIqyQFlVWC6XMMaAGWgaHaWLCKaS71orVfYKPS+mBNKDAWAawUvrAtqKA2UtY7beKVE8EtutUEcARGQgxTDGQGugaRTc0ejxGsZUJW9UFSeP+nriinRILEIHfwgSgszBdwL488z8JQDeAfDN+2Sa4bJeGriNeAL7w3j+SjEWC8b5BeP+A8bDR4z7D+Q4bVlqMAwMGxir1OstyU4mY9ivzFob6EZDG7N/XUmsAEkplGWBoiihihKihO/yPF3ExHpQTjzaelg88+KJIwBA0zB2NbDdApsNY72Re7ED8NMfDAUGWaUkgZRwLM6E2RsUoWdZcroJG9psSlP1L37D4/EgIkBEHwTw7wH4H+w9AfhtAP6mTfK9mBKL0EKuorlAnGODx+/NjsibNwaEtqP9X+I4M4truyZnJNT2v5569bWVD/IaiBBuinC7kS2yppIdgOXK4Ozc4OyMcXYmXnVAIgO71T9QhPcCM3tlmqyGWvbqDWfqiNjau23OJA0JB2B1AUoRiGW1NbqBMXpknFgCoI0nUMYSpY49P8UkXbz9iAiktbJnB8g/9wFqLQEwNm1Y1d7JH4gVjiPxzzucb9ooMdmLlJQjcKg48N8C+GMA7tv7VwE8YebG3n8SEqS0A2kYsomK4DzcnOJUwLfsSEGdVh9On/Of37cNeggty3JVocjhlJDWi05ZGiyWjNWZwWolXAEUy+TXogg0wYk5DgoKm2hoIg41JQ0kICteuL+iLHw76kajaRroRsNo05XVw6qzyWh9ItVlZra6DnY7D6LrYKNkxXezN2BGGABpBNu0bguyVZVm9nDd5xkM3YPYiXp3yeh80HniYG8iQERfB+CzzPzjRPRb536fhiHbmwDcEMxT8L3E5SaFFSVQVozFwmC5EKUgSAiAbuD9BjjOJUdb8n0Zy7fzQfQL1aJCVVUSv9KGDzaaUWuNxmjUTQPTNNDWhrePGeg8H0Ary5W5ZZeEO3DigDABDPhjTMI5ue2/NEaFVyJOWWCyDwdGy8TBdGgEoq8noq8FsALwAMBfAPCIiErLDXwQwKemZTd9+KeE8xjuRfswOm7CGFIeIM2O868PB89mxnKzstaAhTs/rxw7y6g10GwJdUOoG2VZeupBcmqDzOlzstuAS6xWK8s9Mra7LbSu0dQazEZ0DV7fML/RGCkRC/qFQuVwa1REaKMdgZ1uwJpPB4pHn5v9xsdXicqbO5gCjsJfzHLJs79OgJm/nZk/yMwfAvCNAP5vZv7dAH4YwO+0yb4JE2MRBiMTQ53nq+z4tpviIGKBPhoZnWItyoRApk3+Dt1F6F0IJtQ/1ZG03m8dzq0pcKFk/7ssWis2Y4DGutCqa0A31IoEk6sQIxvqQMY/JRSFQlmVWC5XWCwWqMoSiqzjEsPQRkMbDaOFGHQQS8dL2nZBA8Uj0J1CDDOyq3/EFXlUo687+qlgZyDchXBel9KdCZ+Pxzn0qdgDwry1bh9H4CbsBP44gO8nov8SwD+GBC2dCLlBYaf9iLIofkdRgpvXuLclt//moB+PWKttc0uF05D7Sf3/DUJiU+BKtCNFTgUCRWlQlLIDUFWta22jxThotyM0TWsp2HoHbuXjTsk9xgyUe4/M4CaCIkJRllgslzg7O0NZFmA2qBstykC78hu75RhGBg6aIM7W8+F5QtatSVtXBgHGWR3CuxNr+RoRB1LoFBOuey068igziOL2jduq1cvM4wKAIxEBZv77AP6+vf4lAF9xjHwdnJq+4Hbh2JVvR57sBBi7lw1UpcZiAVQLBVUIYdIGqBvGdivuw5pGoa6FGHStBKfjysG/Y1AWBZaLCudnK5ydrQAAdV1Da6cEdBwA52f0TBiuhYhARstEpYiwySElpSCTMQ2Y0gOejtrsc+XflMgLnJDFoEDQoAfUOTzMGud6uGidO3w4S3cQfpPZHYhVwnHO6WGXkFGYw+246VqWznmm+NGrKvGoW1aSl2yDWb93dmdAa9gtMlgnmV3UszqNPaEoCiyWSyyWKywWS4AUjNFy8CgojzC/DWLIrP2+f2IxRvh3kfHcib9CCTFVBQPe8aoTmcJ+dtxiD4FggGnClJ+uThmFEyMCwHzlUtv5IVWOj4uOw+SBm01wuCLs6HQ+KiYtl0GKJdpNKX+qBBaVOyHI0AbQ2rL/NfxBIXZ74lmsk74bmZSR2JZjya0ysKwqVFWJsiy80ZEx4bmAuO/nwr6fOitDkHBSZekcrVi/igYwDdA4h6ITOIO8IOExTVKmX+4HJ0ME2vhq7ROBQPbxjzIy356Qit2DOy49+7ndGdwz0XuFwqiQfgR6YGgFjFhNq3kgxVDWKKis5FBQWYlbbVUAAGG7g2X7CbomNLXshTNEFxBO4G7f5YESeZXD6pL/R25JbPWrqsRiUaEsSxAR6noLrTWauobRjdWVkf9zfgaH19Jk/PS2eTeAeicFA0oZCb9WyQnLQmmxLtSERhGosTEZDFtdSqADilUirb4m4BRaHWY/60kDXfDyhCYfwNNT3Ds4GIpS9ABlpXF2xlguWSa/AkBiCNRoYH0tREBrgmnIWgnKsVw2dAzRuxfI7gYU9lBQWVUgpdBojbpuRBegtUzAooCyykEgIEg3CumKTAAZMbJaaKyWBgYM3SjUO8Jmq9BYglo3wh1Mzz/DGx+5iidDBPrVSmETtOSu0w7Bx92DPiNDg5Jr7qH/yUrmUrmn5PeHXyy0GntEbSXBMw0WSzkHcH5BdhdA5HvxqU/Y7YDNWg67aHtM2G9hWcVYCFPdYI2tqC6FKpScDCxKlGVpFXEy0et6Z82DrS1Auk+ZSiT232hsZTmy/ZcZZnjCqBRQLSU73RgoEqJqjIIyQYAVjjFLPShleZBepUs75vYhzidDBMYg1EGlbHVXHqQ0AcJJEeXr8qO2MzgtoIfVOniyz8wgIkCzetvpTBhlZbBYGKzOGKszQqEgwUNqOS672xG2W8JuC2sX7wbWlEkSMa2DaVo6nVHR2bMBpJTdpmR/HkA3jffZ76IJ+b8ewg0E46cnSeyvIlHI9n5q82YnhghUlbCuyrZtUTh3bG6iy28fLeojSbGkfLyl5mSIQHisE8FPmsr/ZCbBkBy4t8Z6zgdH1NgOwohKJFRdtIuHuAdbLhhn5wb37mmsVgZGS0SdpiZsNgqbDbDdSEQdoOstaFABN2kxTZezXM+4WAVkdwG0TxNOBGY5jqy19keI0wM/nWJHsOrDCAh3C4Lv7K2s9gyQKFqh5Gi3LmX199EXOI9LTB76EJ4yuOYPwJMhAn2rwh0cA9jKrIxyASyWhOVKVNp1I/v/mw1hsy6w2xF0YxUELwpbFh+BWjeod2idksAaAlkqx8bIgSF7GvDF4eu2Uws0NaPeSayCRotOxTseIwDEICXEpA2kEwQxkRzR1QuMKTv3h9MhAg465Df6GYaBRIPyKGLmrIfRmJA5d1aiIc3sEOPQcZqSFXnyX3PnwinbgpBakIM3jdUBbLfyK9aAThk7M0p0slXb05XtO+5RzFtTYGiNmro6B7dLo8MjwIcuILGsBc+XR2hxJrHcs6CLuiZstwqqNNbpCossQsIZKCLxsB56NQrYgHyg1SDNRGidtIwzqKdDBHoq2RdecPa+8Bg7yG0xfYN3bMOoK6odeXWKTqB1ZcqQcHCQXlxjywnBomBv7qobOQ+w2xHqbUsAUiOg40JP3p7Yt0FDjWY03PHHFQ1wbQycV6rjwpxZJ4espD0J6zWhrKR/5HSh5KTstmdE0pzY5vQSVqRJjZSE7iU9Hu6dc+45WvPygaF4OkTAwRjZui25+yUGmUQBwSDxFlSWZMNpiQ5ATIEVdluF3a4Ua0BvqvIixQHjTZJ1GMnYAbXcwM1tVQ7VP79UNI3CZk0AE6qFVQZC7IRcPERFQKHspgZyk5scRYhy7z+ifTicGBHoUfwlOqSczc5Q+xxmTho+O55iputTvpNgUj7j5XBwRLg9YOP8A7r9/7TsYC2J8sotRq1FbF6rHt9Y7iQb/ytIx8kKluwOhQslJyvhIdaDncLSx5xLIw+NAeoaYBa7irKU+AQuwjEzbITiwo9xhvHtNpPjH5RZ5xDHkyECab9x7kWPaADkZKkjLRHdvs49OjpkGZ6eSeaPB/vn1kmrn/xt3EB3KAjeSYjdAbCaqW7TziOBXXz7iNzwp51BzOmlk9vHsOrT9e8BmSyinRhLnLTdcXHJVeWCt4h1oVKqXdkzeTLQRpUKCmqPK+coY/DxTPboZIjAGJ+fHzPhyGgj9vi0IQex5xig4N/YLy/gosXsdVSZuwYeowtYKvN3E3gts1v93fkAZxXI9kwAozViYVbwFusDhDbax3JJplY9s9KjVYejbeMZMKXdO4Oh+90Q5xBHfXL5DMur4klItDYKBlUFa6gFFIVBUWgwt4Qgkv+pve4bF0Nd1MGGhDMZGlsnQwTIKWPfY/L+UWVaEi7A7QAsFkBRahTukJAyMoQNYFihsfYBWodimEMML1It8FIDOUUhMZQxUEp8NgJAURJUAdmJqQm8Y++0NWruW5wHJ0UEotW8Y5gxRoEDCho+cnk7uWv2rBs4+cXIOn+YAtk804kXscDDeLvPlDIoK2C5ZJxdGFSllki6BaAbO+CMOAVpajEV1tZLUEfJPBnxw6HDtPtVwfV8t2DqX9w7+YYQJT2qtq0b8oVZWS5AjmuXJaDIoFBAXRAUMXZ1Yd2dE9xJQx7It28vJDdDpgz3kyECrgoUTNaITct2eDp08kOYWyFrDxhQvqSz5qC8cxqNkcydLOoJpyieylIOBp2txEy4KEUU2G2tezDrGqtpRDQwGtkIQuMwRc6Klb2RvjczliNpIZT+s2508hBq0nMs9RzF4XhaipBuWXUnw5P33FQWDJSyrCgCikJ2C0AspzU14D2jBWJBWBS6T0FDupcJcDJEwPvc34M/niRTHzBZQ7HycPY9yWDfhShRBlqNEArFEjdwKfECylKs15SSwdfuCijUjegFtGljCXqx9wiQetYdbLpJZfYTzb5T3vMk6EOhrWWLi/D5pCR2g1KMUsmxbd0Q6oXYDmy3Suw1vGIvZQmn4e/0Fl2vxv3fH0QEiOgRJPDIr4dg+gcA/AKAvw7gQwB+GcA3MPM7U/J7j6kDjg5EwvbLuXb7W5L1diODjVkCZmy3JM5C7OoD4OXqgJPUV8SKW3e6sGkUdMPQhfhwKGz/ECSC02KhcXUNXF8D5qrwuwwebriuh4Yh+wsA/g9m/lcB/AZIOLJvA/BDzPwRAD9k70ehZfy6EhEAuFBMMbWP07r33XQHwDHzZO5Uj4K/tNyhfJwoIni1PIGysqcqxChFObt7tv4ANLy3IHc8eLS8fkQGFAfTdBi97wldZyGdyRG3nHwT7FocYwxkhmQ0Hpi9Z9/Op2wjGu8Imw3kcNYOMLBbtyWjWjKWZxLxabEUIiHfjkTbonbchG3jxkOnCgODd28iQEQPAfwWWG/CzLxj5icAPgoJPwbMCUM2pdOCmu47MTnzXxcCfcK87OcgEpQ1qr7KvomdY8tIVAr+1Jrb3nQhssTbjdgHNE1iHtxLjSZUYQoEE5rcbL0FSB2G32hZnTaUUGR1bc9m2PMZYpnJ3pS7WrD8VfZcRxRmHMiqnpL1ZHg8D8Mh4sCHAXwOwP9IRL8BEoH4DwF4nZk/bdO8AeD1edn2dFiuFdIvD+nr4wr+PaJoVzIOZcf95XH2hkGkWvm40eyV7FrLllS9U6h3sjMgjEl35nc09YMwUSmVDmSaUtVAzZZTfs3ZEtgTYiOsvCaz414tUEoaA2y3BRjWJgMaVWFQKjnHUZDsGCwqg3rBqCqF7baIfKV4jcAB6o2hTw4RB0oAXwbgLzHzbwRwhYT154EwMET0LUT0Y0T0Y8YYz/71wknKgD1wi7J1e/CJURYaVaVFGajkdF2jGU3DaLSYtDaN5Qas1+BeXE+yvfdgV14ERKKDWGjutgU2a4WrS4X12p7YrO0pQzBUYVAt5Ki3OCBJ8rvBMXUIEfgkgE8y84/a+78JIQqfIaL3A4D9/WzuY2b+Lmb+cmb+che/fhha5jdPVSa2VScRBb83PLgIgeDaLW8W7qFegcQy0BkFuZNj2sr/u1pY0bq2UXR16COwW2ceoA1xdfq4AMr8hRWYknuwAhPJ4RtFUWjvo8HEvPKMR8/AC++ZbDRn62dwR35L0EUxkmPGljuwnogck4/gqp9mU+B3YR4cEobsDQC/SkS/zj76KgAfB/AxSPgxYFYYsgN7NRhfuc7qNKBP73iuPZUMaTmhrObmSDp5XbmcvuxHwZ2Zd9F1WtuA9nyAdx+upCBtV//a+guoawXdKB89qL8SLUpDrRGGOs+BU9JRcB9VdKhsx+EQ2QjEhTgVtcQg1dukuc3iGbKi5tjMngdhOPOmsa7cnZGWw1kRSsWBOzJXqiUEdrykIeeH0ZMBNaQYPNRO4D8F8H1EtADwSwB+P4Sw/A0i+mYAvwLgGw4sA8Ctcti3BrPr1JmYBookZNhyyTi/MFidi616oQimYey2hO1O9qE3G+VDiQ0SgX3xOzIQCGVZoaxKfwTasPgZBIyPPPyiIed2zEPw2BgAWohxXTMWjZP22RsTVZXBYtHuhmjt1gr22XUMp0a6cqwfDyICzPyTAL488+qrDsk3KCF7eXKQXUkyi91AHXIBVIYLErl/udQ4PwdWZ4yLC8b5uRJloAE0FHZ16z5su1E2ohDZ3G5Bbz6iGM2m55YDqKoKi8XCrv6MetfAbZEaq2X3xNE7i7394TJICNpUYCPOW5paicVmY4BSCJwiwnLFONfacwPbbQHdANopCq1H6/Yw0whMaIiTsRjMwSGceS+B7HNEeSQITN6PNhJDLbFUTAZIVRmcnzPOL4DVirFYGJSFDDRthBPwcmhtCYBxEfMm1GVKGgr1C5aQwRGZbiljZrhubJMVAcpS3I47ImA0w7CBYhWUHYh0UshgGWOmy5HtQebxVLPjnIgi0YzJR3fSDUkwGKsPWCzk8JEiI/UzjK3VKbBxbUo+wwiVHuo3Ri9OiAj0KZjG0kyDG13xOpl3N9l6V6fkYffQlCRqdQUMggQQWawM7t1nnJ8Di4U4DSEEMQQbUQJqO9hap5c92117QbdWB/n7I1gvPAqqUD72gCgEJQSZNsZuh2qQ9TE4iCGPbx/nWr17MxPSvrXZGVZotLHEmUGFc/0GUOFEA4lvaHQh4cwMwO6QEXrcjman0DhfdDpEoHOW8t0Dx62WcACrM8b9B8ArryosKtlibbRsO9U7xm7njqsqf0joZQFSCkVRoqoqVAsrDhQFAEC7oCNgaFNAvJFzr7fhox7VPgI4MaapFXZbYF0akCIU1t9AVQJVwViUjEVl9QKmAEDYGAVoIQRuoymE/vMTw3AyRCBkKQ/tuFsyRuuHkN30F/N6KDpFZwc92VBXqzOD8wvG/XtyUIisxlhrwq5m2RLcSTzBXW0diHK7FRWtDfYmdp4xvQFvYpIpIpRlgaqqsFwusVwuQXYbualrienHjMLGG5ikBeiV0ajDBuQdifTkF7wawqIVE+WiaSTIC6kCZdlIhGgABazzl5JRgnF2RtjV7swHw5iiv4q9TTDcn6dDBAIFz8F5Obb5JqhBlm/MSX/Jm8wpSaLWf0KuoHb30rmnEi7g7Ex0AWdnDFIGMG6/2cn/ZAmBsvvRcRCRMNxlduCMC803Ck4pWJYFqrJEWZUgUmBmu00o4kLkCXFfPPfZBdxznHpdCYvNgARYdTYDwiGgYDjz77JgLJaM5UqMvnY7tj4M3R/bXJ0uxOEX7cXe7O7AC4UXoQKeCl2VwGSI5Vv2v0SiBzhbady7B9y7J7oAGVAM3RCMFg5gtxWDlO1W2aCiQiAkf3hjohzKtw7JwX8nvytFKAvhBqpSHCQaI7H92gkvs2F8KMTGv31p+p72qnxydUmoakubWgMnhg38CgVVkw9YUpUGi8r6IiSW3YKlwco6f9ltgN3OwBgXG8JvpSRVmDfwXl4i8B4DpRiLhcb9B4wHD6yvgALY7ZxREGO7JayvFDZbSwx26HABA/smJwMyjwggBSIFogJkgyWQUmA2MFqj0TrQEZwADKIRtzszWd2AxH1YLCQYDOAMwACQyP+LitEsDVYrhfUW4Pq4aJ8MEehErRnr2LHt5ptiY0e2lHof+92rqXiFYoPoApZLtxNgoApxENLUQLOTLcDdVmG7k3DYTW1XC2c35/fQ8+VHUk5ki5KuobdAQMIifES01krOGCOhx/YiAEn6ziraTR66vMsjy51Llz50fptD1RglZzsa2S3QDJTWUMhZlyslOwdVZVCV5D1Ei7VhGs84QCus8kAznQwR8NDbqVP4/2nDdJIk0btnNA6eWc0UklPAcZI43XcvCjlmulwyVmeMspQyGhvxZlcrG03YeqexIcXdIJGp31+JXrE4VX5xQhSOQWhHV083GcLt0pGz9gGM62P34SLChhn4PuxTANRxGSY2AWJGrFBrluCqZZuKSAhAWTLKSsaB9qHibWATDrcM7S5bEIZ5jPc7PSLQB5lVtZNk4pjkIO3QAMkogA+CzmRLnT909AHOa7DG2Zm1CbiQcFZai9y/3igfRfj6GlbRhIgAJEv7BMxiON7an5s0wb3TCxh3RsISAXtoqCiUYwoAloCkY7AXQxkQnO6ywhGRnuP7MC3ZrfbGiCK32hHqHbCoxDkMAYAiFBWjMsBKG6zOAOYCBMbWAKaxW4aUFp9yPP2YvDxE4JbhVqXMnpEqpwMNzi4M7j1kPHgkDii2G8ZmDVw+Jzx9SthtZRdgV4tY4GVqhL8vEzCM0XI2gNkqA8Ujj9EGxhi7NfjyA7MQbiIFRYzVssBiCbDzDwHLDZRAVTFWSxeijdE00u9ykIugKIkd4WBkCJweEUhktMmEdi5rGuTPY5nP3jLL7rtlrnPx7p0MabcES43zM4OLc+D8TJ41DbDZik+69ZrsDoDbCpSvXf7yb7sC5zCLt8KTje804UFKuKnfyqQQoyG7JUgAVKsgPAwCjsQrIds3cbp52c61xGSQdf4abu3KuCidFSFkt0BOigJlQSiU80JkRQPEjH8Hi4EDYydHBHJjsX3U9tS+xi0OxnZTOk4d9sk7+yJHDNKPGCAbtGKh7cEgYLls493ttuK3bmfPpvtwYm0NZlQgZNOHJcjRtuZ+JeMouMR2G9DZAzgiwMq5JrMoesMnHunHWAzpeOKdtWPSzatdtyhKlfs0tBVwYKOwCze3k74Vpw7sg5i6eIZlAZSFQVmSPWRk3cQFOoAQlxaP/jFwckRgKriuuBVm12mXbsFwRoJ+MopCY7HUuHef8fAR4eJCHIdu1oTdlq0SsIDWBSSMGNAVAV4+UUBWvdZ5CIi8OMCRHbwd5JaV4yCsd4cS+fQyYpzOfv/WCUffuD5lSlnOgGizLlAUovRdLm2wkoL8tuGiAvTSwED8EdQ1AIgx0b41OlkiMOVo7a0O8SEC0HuWPBUj+k2ivcMQAEXRKgJf/3zG48eyAogyUMKJ1zvq8RBEiXZ4PgefHmKKan7Dje52s9gaAVVliWpR2eZnFGUJVVixgKwS0X0oyOfz9c9jjX16M9zNeaVmtsicVJXsroRgWM5+bLbONbx4jLZGgVBk3ZQXgFYMQwZ102CxW8h2ofMczeOEKYWTIQKzNfEv/ICAQH6bKmORN2lwyp8zDX5wz+DBfcZyYV1XN44AWHNg4wKJul0AWxamHRVOMAzwSGsTp+iDTrp9uyjwmENKoShLEABd6Eym/aLAzELtbxfpccPbhPXeo97iERpewVuUCk3NPsQ5KeEEieSAUeP0AyWjriX8vLEEIzp34oj4AE4nQwRSuDFjnxuFZFWK3nRftH4C2CsCiQwWC8bFuVgG3r8nmuFmK/L/euPMgcVNmFUh2hwpU8o0vCfBlC7pSZPzMRD2ccv5BXkQoOyJQiJANQ1EmTrM3RAoEJG7HGX87WEUpG+c9pPUtNy2siISiPFQbc9+1LUYCXFhxaRCzhS4v6J0CkJjz1f0lDZQzZMlAu8VCJlTpSR24L37Bg8eGTx8zFidyRZSvSNs1oT1WljGXS2OQ96tQKRQKIVFWaIqK4AAU2k/0I0xk+wEXiZwDFBdw54fADZr8S1ADCgbVaosCFVJqCpCVQA7JVaF+zbHQRGIiOg/J6KfI6KfJaK/RkQrIvowEf0oEX2CiP669T84nhcAKxkj9KzaMoYvHg5YCOMEnvhzu3Zbm4DlosGD+wb37jFWKwkVvNkwrq+BqyvCdlugaZQ/EHR8iIOEeEW8fdueYBuu2ryX8OUBst9dlAWKqoKqClAh24VylqAn7+R+qDhnjktWW09BnfOo7xHCxO5ejEJnkBPYKDSNxB9Yr8U13K5uI0cXBdmtQtgdAgOCSTPKFJKHQyIQfQDAfwbgy5n510OOQn8jgO8E8OeZ+UsAvAPgm6fk57zoBpqh+RqtG4Y+bFoz1hnfu4FK9tSYYpSF6AIu7hmcn8tZAcOM7QbCAWzEGCiMH+hWj1iVN6dO/dGcUoJ8DGocRSHqSxO4FivKKtopcO7GyeHTM77nLB5OKTvoLHRu3d0Y7vk8CgGXe2e9Q9XWbqCugcYIIZJzBGI8VFpxoCgg7EIny3GdyaGxCEsAZ0RUAjgH8GkAvw0SgwCYE4asB3IUPae66cjbnaf5EeP7anJHt4kPo1HSYW5FEvNgg3v3DB48kJ2B1Urcgl2vCddXhOtrGRQuOk3rb2Aq7vNRbC/kzy1wN3Y+y2ZelAUWiwWWixWKomiJhiMgx0Ji0mI9P8BXRDjtIOu6Cu9RFgNwvgh3OzkVutkR6oYABYlhuADOzuQw2cKGMFPKNcst7Q4w86eI6L8G8C8ArAH8PUgosifM3NhknwTwgX3LeLeDixlYKIPV0uDigvHoMfDwEbBaAUzA9Rp4/lzh+SXh6loURtqQjyN4WrzScaAoFKpqgcXyDIuzMxRVBW4aYFsj2g3B6dd/X/wME6AJm60o/AjAojTYLAnLpRABVQCrtUHdyPbxbgfUhmFm7g4dIg48hgQf/TCALwBwAeCrZ3wfhSHLJACIpi/QJw8Bz82BbRmJg9Dl0u4I3GeslvaQUE24vlK4vhK5UAKHtFtAToJqtwbn70757SP/cbe1KU03Kdf0T2BIpxAipFSBarHAYrlCtVigrCqUZSXbhaS8vuIYMEVE6UV1FPYZwdJmhp0VoewIXV8TNhvZNgQYVckoS3E2owo5Xk7WDwFgoryGUDhkd+DfBvDPmflzAEBEPwDgNwF4RESl5QY+COBTuY+Z+bsAfBcALBYLTjugI5+F7wldATuBKU/809kanxYlZ8wxHxx7LTLdcimOQs7PRd4zhtDUcjZguyE0OwWj+7eA9p8RtjGz+VL0Mx3S7a852Mh/RVGgXCxQLRZQSoENi47AniXwyrxA7s5gfpQFpFOLYCyG7/Yra0APQe25Ahc/YrsRLnGxcEeM3ZahQVlK3El3zNgPzRGFziE6gX8B4CuJ6JxkBrswZD8M4HfaNN+EyWHIYhgcPsdkDTqy2pRvYBf2jiYtg1v4MK4VQRSCVamxWmmcXxgxDy7EndR6Tbi6FC2x+AhQ4ns+UCpRWEwPjE1Fp/nO6V4OE7tD/UkqC9tn6DZboRQWVYXVconFYoGqKj0BcL9FoVoEMwvIrP6MsMpB0DpJe8xSJ+XKzXFFIXvHYhTW1MINrtfK6oUkHFtVERYVUJVy5LysJC6l0zfB6giGzl0dEovwRyEKwJ8A8DM2r+8C8McB/BEi+gSAVwF8917574vYTUMfYiOKZRmQ4TZO6zfw/gODV15hvPYa49EDCUhT74CrK4XLSwkj1jTKDpjUVDgMMf4uApKtQkWFEEtyPgdLFKU9Wfhuq3MPGA3UDWGzVbi6dmKB9PtyIdGnzi4MFkuDsmxQFAaFAvz0HqHmh4Yh+5MA/mTy+JcAfMUh+YaQQ/1FEYjQHDN+kbvk4KfVLHstBxsoMqgqjXv3DO4/YOECKmBzCVyvCZeXwHojQSxNaB8O26cBN8D+KixtBkxY8v3KSgkXMgVyKBHyygHncYkZzMYfKFJFYQmD1QkcYiEzB6hzcXRIj5kwRLRn+4CtWOBCyi2XjN0ZoygJqxVgDGO91tiWNtCMUjA8rW0O3SK8edhH2zUr/9YUZLaqqVfBxd1rK6TJBDWeC1gtZTvw4kJcSwPAegtcXQOXV4TtViwDHRfgs072mIf2zfdTS6U53DzpjWis45NtXAEiZbcKVaTEmyyu9GwrOgOlrgpzOhx7iLYt3Sr1pClki3izsQZEO4AUo1rIdvJyaVBVpjUgsjYoY/idjNlwv34tr+I76pCc3INZ4W3Gly3TXlaiCHz8mPHqa8D5ucht62vC0ycKT94hPH0CbDdyuiwmAMM4xweI5rdUlH2Gys1tLsa8GBDMrdhEYBREABUoVYmiKFvjoV6FZhei0juEYGC3YjIcYVQmHnTCA4EMQDFQ1yU2G7ELuD4jLBYsTkbOgIcPYD1M20NFKqjXDe0OHB32VrS/BED+V7Z1zs8NHj4yePV9wMU9BohxtQYunwFvvKHwzjtiHNQ0RUbev/lW2uNEaj4fR/54OiEogkluWINZzIWpEKWpUmQDlNKxZvAR4AZwSDk6Fsek261CWTKur7UEoVnJjtL9e8IhNDWw3TLqZtouzUkRgalwG13e57koq3FO2jq3aeCulBK27f59g4cP5aRgVcl+8GYDPH0KPHumcH2trL9ACjKnJNP8RtioTiB83Tc+OPqJXyXy69RvO34KsmXbHQPDMFrD6EasYsAg1l7H1UoNmV2AhEEQOhFoTdIVN1LqZHgovzFww8S3p2FFPyDcnTGt7cB6LceNzYJBJWO5JKxWst1clrDHi8WFyhDuJ0ME+pn+vgE93iHT94rjwTk8eOPP4gGUvo6VBnJGwODsTOPRI8bjRxJPsFCMTU1YXwFPnyhcXipsNnJQSPLpKuI4+Dcq74jQn1tSbqCfiCf2fqIIM6CNhm4amKYGFyUYDNYNXNxFZCZ/e5v0J7d4cZww+Ha/tqOQIt3U8mRFA4IohrUNSbbZFNjtGKulBhbWEaklAlUlBmfG8dcDpsQnQwTefZA2uoFSGotFjVdeMfj89zMePRa9wOUV8OwZ8M4ThSdP5eTYbicHSATerUJSHpgNtNbY7mpstzWKogIzY7ersd1s0Owa6OaEIg914Ohaqwi0Vqh3wPU14/kloaogMQsvgPMLjfUaWC61JXyFxad/D+C0dgcouR4c+z2q8Ci/rjb4NiA+bOK02OI09N49g/e9rvH4FY2LCw0ig82acfmccPmMcH3t3Egjqf+ceoy0zSGq8EGMpMxpx23y7wmEsiixqBYSkXixxKJaYFGWKElZU4ugbn7zpa/Oh+9sjO4c+bbsNupeu05jwARjxMfk1ZXC1TVhvQHAjNWSrdGZHCxSKsczxnBanADnbnJM/TxKO5467STOFtvJY7K8IecDVis5IfjwkcbZuZh8bjfwzkKcNVh8zDRwD9UpZ/82mQJjOToUKWiHvsXZCTRDxMF5GHYWgmVR+ijETrEYWgOKxeEeIkePvmcA8ak5T3iSvAjyH8SFW8U5kxww0kZ5u4HtRgK2yulCg3v3gNVKoW7seBowGTgtIhDAdIm/Hyaxi4kBTPs8m7irPcik6y7gBotKqPMrrxg8fsVguQJYA7taIgddX5EVA8RtWOs00mYyUJX8MYvb4oAmnlibQKNaIlChqiqUZSnRhxwRsLavgYcDaZoDxYLBz0UrF1Qi/Zazz+MMJgC5emX0PwyAyBsPuXfGANudjJvrlXgoPj8Tm5O6Bu7da7CrZRw5/VIOTpYInCSEnOWMzXKlGBf3DF55jfH+D4gugCAcwHancHlZ4Pq6wGYTEoAbqcFJg5vMDKf1N1AElEqBATRFgWpZoSiLlisw77aG6iEqoXYT0j7GiKMZpQqQAh49bXD/gcbqHHhUGLx+DRCJ6fn6+iVRDMaLxXH3xjsK3CS72Urtgb7yeZJYbVULjXsPDB4+FPPgsgC2WzEJfv5ciMBmo+SQkHEUv0/jPoQnBY+Tlgz2uyJuJqE3c1t5shCS8aKTZ8tla7BpGjRNA+NcihOBVJE/QjybMOegX7brYxYPgowEGt0MFBYaAOlGYbdhXBeM588VthuN1YqxWgCvPNbQtUJVEkr1EnAC3gwUiLbeoi3doxD9dMRM6dlwQk2Vwx3+BsuleAy6uBDzTkWAboDtRvwFrNcKu52cEgQT5h4GEu6/xeOYh4nCLbDhEN2QiRred+QU/0/3HdsSWCLzai1EgJ0wS+gQgGS7P5o7AQnN1ynNJ7dt2HmSg8Pa2kem7t3uHNYVGJYo1NstcHmpcXVJ1haFce8c2D0wIGiAXwIiAGs8wszxYIngCFTAzVtOJ/M0iBe0Hnwsl0BkUJYGFxcaDx4w7t2TPVwAElH4ivDsicL6urS+A9vdjEkY9c3FBLNwp4HQ3TIe3oTJrYzxCt77/dDSSYn0a5WK2hjUdY16V6Opa7AWh4qyONjDRKSggnZKrRtzLZhzeR7VqR/TERjWCYyVO645bHPqpLD6CFEQAk/eKfDWWwZGGzx4wLhYGTx+bLCwXor74ISIQAzH13XfFrQcQFVpnJ01eOVVxqNHjOUZQzNjuxE/Ac+fF7i8lK2eRiu0RkGTtx3eXWCrbYyBNhqNblBrjcYIEdDsRGMbsJSUULQxFvG2dKQvCIwBGihcXxV487MGugZ0Y7B4nXFxX2N1rnB23t8IJ0ME2kWjj3JmOnrOYj6mAvZSQo7iDqGRZ8NVwVgsRSH48JEWLmABgGVL5/JSWRfiLohIriJjlYrbKpvasQGeC48rMLaHfSwy5Ju3b0EM8NNGjIXEbNiAtfE7A6TcKcI2PZy7NsdaxyVmdE171irZDGqHyiF8xPi33FbFfxXqecien9Ba4eq6gCrF0vrePWB5JuHLzqh/j/BkiEDWSw+43YsezaA/0VQ9X3ix37ZTu20lLsPEffjDhwZngduw9Rq4vCRcXSlst+1uwP4L1oSB3VufEa1atFfV/2oudGmpCPSi9TbCDWjhCIwxIO8gg9q/znQfKOxFcQM3xNQ5UYA8NRAHtOuNgirEFfnVmvDQAOWCsSj68zoZItALQz18Iw08N7NUcynhxKpS4+Jc49EjjcePgdVKBvluS3jyVOGddwo8fVpgs1XQ5jBlXlaLkGqb986bwpu9cxrQdQeX7LcHtTFo7C6BZvEpYAAYNjB2e8ypj/rbLreC9NQg3SYB0Hr1mFKPduHIKfKIEnuKCYtMPLw5ocdOoSjXxAxjCuEsSFyMXV4p7LTBAhh0L3b6ROClBMZiwbh33+DxY8bDhwaqAHZbCSv17InCs2clrq8K1LsCzIUnIHcgOgHjxIFGi4LQGDS7Bk3dQDfCHQBjLTaDBThi0885Nn20Mu1v0ygZZyXw/GmB508MSIuL8j4YPTtARN9DRJ8lop8Nnr1CRD9IRL9ofx/b50REf9GGIPtpIvqyyZXoOPzs3zLpIonBvp4Zi2EQQm406mfHBUDiCCyXBmdnjLNzcQDBzGgasQ+4vlbYumhCRu0levQ5Bw1T5Bom9DRDUbqp5Xa/cE6AutXg4M896TH1TTI1zGh0g229w3a3lb96i129Q6MbGKODlXd4IyLGZbxe/o9tG7v8k7/umA3bxK7fvm3cxSAagxj71sx+L0gxi1iw28lx9KvnhKtLwua6v5wpB4j+J3TjCXwbgB9i5o8A+CF7DwBfA+Aj9u9bAPylCfkLMGeHS29yjLVnOzKPecSWk5EQHVEF+23BszP2f0UpziJ3O3EhfnXlnIeK19ip6IUlD9c/fNMlpuNtd3wYLS9CuTUYWm/WWK+vsV5fY7NZY7vdomlqGKMB5FnvNON4sraEKBoXbmJTt/Vi1KZ7Mh6LNHQ04HhsGCNmwuu1wvPnZC0GD9gdYOZ/QEQfSh5/FMBvtdffC+DvQ7wMfxTAX2Wp/Y8Q0SMiej8zf3pmnU4ShgiOOG6QIBCrM41HD50oAJRKjIPW18CTp4SnT4HtRk4LviiMTxm01thut7h8fol33noHum5QFAWM1ri8fC6EQGuYiZPxvQXiP6FpGJeXBd55p4DWBnV9/C3C14OJ/QaA1+31BwD8apDOhSEbJQKyGeCoZoswW15eHCp0NDc2zaASezZMH1gxs1YoRlWJZeCDR4zzC6CqCNowNhuFyyuFJ08ULq9clFk6QGw9zuBn5FyWzITeT4fzDLf1Qh7XGIOmbrBVW1xeXgFEKAoFow02mw3qukY2atUk4KDNJ+yIHBX6d3HaN4ePZDYEDYXtrsDz5wXYKOiaAGyz6Q9WDDIz09wIiACI6FsgIgOKYmD/YnD/h/0PR5Zr6UcT0MvKsx7bbL4ybtuuUwVjUTEuLsRM+OxM3DxpIxFkNhvCZk2od0IA/Fj0VpLHgglbhg5mEKGh0qam4QGTY48SM4wRccBZD5qi8M/cFqKIX+6bfXGO2yrFrns/fBx6GLrfUc9d9iQotxdRTpRLIq7qN9vCeh4+PifwGcfmE9H7AXzWPv8UgC8M0k0OQ9a+sesSUdyxPDKlk1NW+8NUWS9Ibl07l9Y24MED8SF4dmbEZ8AW2G3lzPdmo6AbBTZWgqNWgZRCakA1C+bQv4ObLkcw3ZsYAepJ1z62tgLOXkDLhCciGC22A8bsIwY4fif9biyfHJ4zGncGTO+DYcLlnjIX2O2KUb3Jvp6FPgYJMQbEocY+BuD32l2CrwTwdK4+4Jhw47s0Iekig8WScX7BuP8AOL9glJWYdEpk4QJXVyW22wqGCxtI5Ibxe0mBQH5Hx7BsF+qmsVaEwaGiO+gFx0gYXaDellhf9XPbo5wAEf01iBLwNSL6JCTi0J8B8DeI6JsB/AqAb7DJ/y6ArwXwCQDXAH7/vpXoGF5MmjCxVDVtteDsZBz6NLfuyY6Awb17jAf3DapKgkleXwNvvqnw9lsKz57JaUGY4HTADEIQnywbSzw934MgbQzOv8omz9Qh7DujNXZ1jV1do7ARdQyLb8EOSz7m8PMQrioAOazUx/mMNXrmuznoTCkq4eokZgXAmaPcDqbsDvyunldflUnLAL51LM8cdAy2MjrAqRMmENW77w4xB05RIlFkkjJYLIQIXJwbrFZCWCSAJOHtNxWePlW4vlJo6vagUE+m8rMHlodBP0s/DsfFlsEwAMgYrxcwRQGwiAY+loH7h9qVr33RLgmHYJf6kkrh4LAHgzqvIRj4gOFPVrJTPg8geUIWg0lrRodBprXRsdjrqVIiQaIKF4XB+ZnG/fsG9x4yqqU4DLm6Ijx5QviX/7LA228XWK9FRovyolzOw+XeBCQqz6jUyIfgGFLBfcbqtn03NIbt7NYwaOoa9W4LraTdjDZgYz0KuQ5Pt4dmENK+8/y96TN1mq6cHMJoZu8O0wAvTjETzKGcwO3CDK32CQCDQUqUga++pvG+z9N45RXGogLefhv43OcIn/tsgc99ZoH1uoDWRdAZL089bxP8vLaEgJmxqxur4RZ/A8acsrvxEwOrYB/yBHk6RCDZJescn7ztPs+V63GSC0WM0hoHPXhgcH4hTkOMITx/XuDpE4WnTwtst+I1yIcV79vfmYjT3hzkEPQsqofD3H3vmAtx5wjcFoazD4g4iRtkkWL7lLHNwfl7/K0aI9lFOVir3bInsg/1knACnJ9xM3KYTzFkwUl2KDu7SPl8STGKUs4JnF9I9JeiBJpa/AVcXiobR0CBOXYgSsjPtlYPOiBsOrv0RGl6U7sh0xfdpM+oh7BPAT+G5Tix8zYcnisZmiicXPVNgk7/p+9HkOaBu5sEimll94Yzr3rgZIhAv/uldoR7OWckp6FsRl9MVQgAUEpiB6xWwOqcUZQMNoTNWuHZ0wJXlwW2GwWtC+QcbQ5iP2XGdLThueVxbO1KjF8SmXcWYRmi23Pnh1X4aa3BLOHblGkHeDqp91ZrHipW8NwCB7IKiDlzYsk5uQynNI21O0O1PBkicBy4TZlBQymNojA2PDRDa+C6Ad5+h/DsmcLaEYAXoOt/N4BbhY1uwIZgSNxrwzIDh1nvnS7ExluHU5mxr18uIhA6l8zsJJBjk28SB98nFBYNowm7nUSMvbpsvQd3tbLJ9pYDZ/Z8JOR73bWxPAtXeEpEj5tqvz4RaAwilj00FCL0cliUudoLknbiTseNfcjBk1A915/HJO5rRrXC3YIcnAwRSI2CWgrf08mJp5aj+QzoiLV5vWp4Ll9Obck57u1W3IY1tTUNTnym96I5g+B3ZOEJoga1FerLNEg7BAOM9xF3wHKlRuqaY28kpXqhsGB/mdEvhN0bkh5PA+KKDwlp/UGwGOCg1FltmSwCGTgZInCakB/kRCKjVpX4cgMB15eEuiGsNwWePS2xqxW0GTEMuoPJEDBfL9tO8guHl08cmKHg90n7VtiO4qwnk2Dbzpsr2xc+yhVxMBANypJRVgxVihOHp88kitB6LWGfxGFIUnTHvGyONVts3kyBo814htwgcMZ+LqeZbpNHb6JYzXO3MqJThvvr8xw73xWXwkQjeUTsQR9FsvlSxEoM5Jl+mSs1z60NoUvJbw5OiAgcl7zPtwBLN3ti6Y1sYkUMRRJgtKoYhZJQUNc1Y32tsN4U1o34TAU/5k3jIyqlR0rpuzskp/1AdAoE5y3KeQoC9iAqB2AR12ZGzcaGeKC2odwsDxfIjqqpZyRNaJYTIgIpRBskWbhZo7EuaVAkJsKlDTO+XAgRqGuF7QZYb0QhKL4DXTixIdZmzlSmDvnngddHgR61zFTZ1EeU8vfzMXTn6p1HRSKS1ZXDvKfnmz2nPwuh4PsJA7DD6/lP5w/ebgi89Cross7D/jqfMBEYgRsiANlhZW/KkrFaGZyfN3j0iKFIFIKXV6IM3NUSSUgm6J0u4DhAKFQBFQYdGVKwngTcQN8fkuUIB3IyRCD0HGuf2N8+CelYYFvIbz+msrdEFi4L4GzV4P49iSXw4LHEE7y+IhijUDcEGzZPcvE7WZyUFmhr9+3YI86AkT2Y5I5zjwehu/jPE4CKokBZlCiLEkVReOvB1r0YTdtSOwbYbdzuIj4DgeTbfiO2bvaDLTd45H6YTTwZItALg+07fTbE++TD2YSEiAgolHUbdm5w/4HBo8cG9x4Al88VNhtRABoDhAfb4goE+oWEl3YTiy33MBLDM0E3fLKnliA0U+srMLifNIUHBvA+87UoCpRViUW1EHfjbKMSaTe4b4cKBKrJnhT7anj6yulPIGrC/pRzMDkZIuD8CcyZ1v4q4SLaichd2bmTTU4t2OallJwHODtjPHwEvPoq8Nr7DKolsN2KosqwEpdXxp3YCld8oJcfG8OtB1KZPOOftR8OmY17fZShJCPgesRpApRSWFQVzs/PoI0Bsxwn1rqBVfYfzhwd5Big+12vy7aEks/hYqb415nlg8fCyRCB48M+I8MRkzbGW1kwlgvxFfD4lQaPHmvcu5A4b1eXwNUlsF2LGyc2oWb3dvT3JwkHbPTEene5U0QoywqrswssFqUPBtI0NRqtD0bXw8EeQl5OOGEiYFdSL4Zy+qoDe3WfY3FDZZOl4gSGUmIQtFgaLOyWIBvg+lqUgetrhaYRPwHsP3cEIPzNo97ZmJyy5dUVCKfW9mCYXJKrdrri9fCpub5z5sxO/q/KAvfv30dd79DUNa6vrsTv4ACOs8bE1G3lpG9uy7dB3HTDPdHhvwbG075hyP4sEf0TG2rsbxPRo+Ddt9swZL9ARL99LP8Ucb+pNmdc+4/Sh+nVWCYOHEfAKGyE18VCrgGgbhSu7THhzUYsA+H2sDuKzbEBkkV+FkwLw9VT3KyPx8DOemvNk430MxE9L06x9SIE0Q1cXFzg/Pwcq9UKZVHYUOVpJjS/XgMTeayHhHPskvfhCES2ltT968cx/ON58vNA/fYNQ/aDAH49M//rAP4pgG8HACL6UgDfCOBfs9/890Q0EFSgH8g2oO/LDHn3AyxqnDCTdGIil8i/9gOQQgJgsFxqrFYMVdgtwUtxF3b5XAyDmia0CYhIWZBzrpL99W+dac7TlMyFFtOgLE7+PFI3h4q0YEa2tv8qAoqywMXFPVzcu4+ziwuUi5VsHfrtw2ALkXvckgfvIhuG7Noat0ybRZCHe9/TLm0z5nozDZGWzyRnITmvG4YJ8SgRYOZ/AODt5NnfY+bG3v4IJL4AIGHIvp+Zt8z8zyFeh79iFr4e7duDlEMVToSgCka1MFiubExBpbDdFnjnbYUnTwqs12IYFH03WsL+uL0XwQUicVuDFxfnePToIR49fISLiwuUZQlF+3rOj0p6IZ92snoBOolj6AT+AIC/bq8/ACEKDlwYslGYopOJXodHX0dcMwXeoWyCOFcRX1sRgBRQKDEOKktGVTKKAqhtFKFnzxXW14TahhILjwvPZqxzsvJMSN2zD1nppTuCPu2gCqJHkM+ktLn2p5/ZQMzieZjtt9VygQt9gc3FBsvVEhQQAPb/dHIZLyhC/Rji0Zh29Jb0CBOIykFEgIi+A0AD4Pv2+HYkDFnSEclBjXlN2FKYlg7EemgfSY3EY1ChgLIAqhIoS4JSjJ01Drq8FPsArak9YLQneDuBDMrzB2MOma5yMpvv1PFKLr8BGPL224tGPs9UDC6KCssVY7VaoSorIXKEVizMZDBR3ReiPohXR24PFZypOJokS3HxhLvz8SAKw89nJt6bCBDR7wPwdQC+iltyc4QwZC8QCCDr1bYoFaqKUFUKZcloajEOevqU8OwpUDelBBQ95W3AE0ZtFrC4Gq+bBtoGK212OzT1FsZo6378RSMZwvEb/ia7ci9hioi+GsAfA/D1zHwdvPoYgG8koiURfRjARwD8w4l5RhS2owzsfpG5lo/yBDW/OoVKZDkcJMrAsmywWMhJQaUITVPi6lrheq2w2RIME0CyK3Bj+rKJekHXVB0FUr9SelrGo4jdDrANOtI0DTbrK1yvr3C92WC3rSUGwQAut3vKIFBO2jFF7P4SpavDzykER3YnpoJXRCbKwKE89g1D9u0AlgB+0E7cH2Hm/5iZf46I/gaAj0PEhG9l5knWHNxhlix1dzM0eR3rEFKh370Lqp5ehveeCDCq0qAqGYslsFwaVBVQKEJTkz0hKGKAdx/uDQ32hUSOnuzhp4Xx4hMNP3jeyPL6g/RTtvjGPH7G81snrzkgBKDGdr3G86fPUNc1Nus1dNPA8MQz2x0IefiYWOx7LDkvjaRtfzi0wz7WBQ3CgOutfcOQffdA+j8N4E+PY5X5Nsonftqd8Pvk3qWMnsaQHBFeLuWI8HIFnK0YiwVQFBJRuPZEAFYZeHNBReepBMaUUL0leOvG4XrEhCpVEQyIwUcBYwx2ux2uri7x9ltvgQ1jfX0lZsPeyCuvqxhzRjqo4dinWQ//tAtZhXZPuT6N1TW4DhpA5qQsBscb7kjNatk1AqDcNQGLhcQSPDuTI8OrhYEqCAxxFrLeALudnBV4GYA6q/QtlXvkUg0z6rrG1fU13njjDZRlhaapoV1sQmNGZvMcODyTU1LFTPHIfDpEYMBQovtwcqb2N+wWgzTMDllnIaszg7Nzg4tzxuqMsSil/F1NqGvIboChTJ6HwyGecYY12omGOlvM8LTt32ZK28ItOeRznLGIDYJhRtPUWF9fY1Et5BCRPa89hL1lmKN6hwFMALLDIbdjkttVmS67H0YM+7+e25ZjJsYnQwTcQJtqLDGYqjPyBlITg8igKAyWC2C5ZLsFxSgVo66F5dca3mUYeyLyYlbam4FENzGSKrzpiJs3sBQ6HwJ1XXsSwyawMryR5Tet2GF9nVuVQ7RjYZU7iUKJWIbfcSp9MkQg6y2m7zymb6O+JuU0of9lTnzuk4FSzmUY4+xMjg2vzkRV2djJ72wC3MriFWyDdcqhFn/TiXA2tMc+CPsPiFDSD9WSrQFVMlR9k9r+8XWgYd3NIdwOADaMpml8edpYDN059L4Ph/I9FquSQG545NjyqWQlR466Nib7jZ3TIQIJtF5/D4Xuas0MwBCIGMxyAEUVhMVSgoueXzAuzgmbNdBohevrEpeX4knI6JdDH3A4HLLqHZ87MswACyfALGdKRDG45+bAuxL2U4ycDBEY1t8CncplOfGUNRwaHRw0mT3+Y92IlSVAilHXCptrwuUlY7uV4CJzxltHmsweaEnvQzbwllRMA7tYo07Rwz3vsSI4WbNm1o+ZoY0GtHAnxlOAect5zB+2OoxjwGx6lJPCxqTMUOHSSWtrNKNtT4YI9EGgvum86G2nlBcbaBCf1P7ZzQKAgd2WsNkQ1teEXXBOIIzmw0NiwQEj62jK7mNDr5/9mdkgqd/oPGZrmyG6AYlANcEUKJNv1ibFA0VX0RuiDjGbA+HE7KDV0SoGI54H3NYeYaCcLBGYMtQCUXQwcX6ekrXWIhhTQGsD3Sg0mqE1o9kRrq8Vri7lt9GFFR1ocqPT+Mg+CRhsvgHU09p19qhnTJZsiK9MKkcAWg4ulIxz7T2tD6JzVEMzLkc7nOIuYkS7BCrbHj0L1GjTDVRnLl9zskTgmGJevmNDhtCAwWgaYLeTk4I7ksjCV9eE7Y7BRh0wl092XX+pgIhAypqXk3BkRATKKZVfILxsvX1CRKBvPeoKTX2qgN6Vh/Nhp9waopSYDCslzkJ3W6CuCzx/DqzXBN2o4MsUgRSvPjll/jBNj/3eKvSVmZoIBsBZGbUfmLvTJQxEG79x3EW6AHOG08vpXlJN+gT8Ru6TrDE4Ro8I6dHxzvvpzCqAkyICQyMLo7XKs1pxtl6f4ieX9VhTsIQUqwA2wG6r8Px5IU5ErUIwxHMSm3frMERARyBtpzGq41Ui9kPOvJwMXV2Pu/CTPRDBnJeeUDfmPjsKrRzLJGyrnFJvcubDH8XGTVPzDz9o9VZj8O7d74qW7TCYKAMwIGgQMaqqwdmqwcMHDS4uZOBdXxPefEvh+aWEFeMXaCZ8GBcwffQcFMsv3bi5Mc7Frv0GMMY6IPVUPUMGbouFepl4/wycECeQh5yutiXAwVWkee0Ofh+sgUQ0UAQsKo2LC4ko9AVfYHB+3+DZkwKXl4T1ukTdAJoVboJWCi7DXMSxxvA077iByDTrGGC74oRv5JTncXYSJPugf9ltgwF+S8dZXfWxyEN5h8ZGQyxFrzwwkHlYjv/Htc1EmMuphcD5+RDC6RCBDOueXnV7J185Z54ZcW7UDhpFbC0ENe7d13j4SOPxYw21AC6fMbQm1A0sB+A/lPFxLL7z6KvHdFbztuB4JCAEbvsjVEIQfJ/PbtyMbmI2TlMgKGIWgR8hPh27WUrMk0fQOx0ikNvCkx8EP0HyHgIQKgAtm+gcPZBiKJZzAtVC4949g0eWADx6bLBtZDlrtJwViKMK96C9pz5g/LtDZOvk2ynac85vbFGf6XZQbpdx2H9CDYnZ2e1ZIsF9ou6oD2IHHG65TpBKvjgEuJN3rFs5LNT6PKJ2sjqBfZtYtMfh5LWruf2jglAugIsL4NErBq+9ZvD4FcbqTKIJPX1KeP7MmQfTBDLw7obb5ynGCI54H5Y/G5Is8tRz8xieCqd1LDgdTiAL+S0X6uwJtY4lQv/xnKyOBNkNKAtGVRmcn2ksVwylgPUV4XOfKfDkHbEN0FpyCkW32yQGxyxr2pDtT9XHteQW/UELysmQZ/8cGqGP/qmcWM4Tc/ByJvWIBZ0pYs9hR8UpwbsVgeQuFQVTBelw/idOBJBlybwOJxxw7Bolz8O1FmmiFBSX4rJNqBvgckt4+qTA1ZXsCJgck5RpzG4HjUGq6jzWqnIg2Qjm3dTqHHs9dMrSAJ1umZ4A9HhDGmmGvsmYfT6YV7w6TGn9cKxkfUAMZNLrRj+DV6gXmTK+9gpDFrz7o0TERPSavSci+os2DNlPE9GXjWLQC+Fk7lK20Jo6Ygf9N/aXbHQgtn4BhQx4PYFugPU18NabhLffKXB9XaJuSlCQJnRGeihE+Q3kOUd5/ELhEEowSznmtgFD64BD4Jh5TYfRUGNHKQSZadNf5r5hyEBEXwjg3wXwL4LHXwPxMPwRSEyBvzQh/72AAH+UPfJSDCDsYGL7BwbBoCCDwvoPKEhiCTx7rvCZz0pYsd22AJsiLOWmqnAHe8MQ9bw9LN4tsFcYMgt/HuJ2PGz2jwL4qyzwIwAeEdH7p6HS7VhOb/xfEgvOu3N2OCcZ2KyVMlgsNVZnGmfnBkUBbLcKzy8LPHlqxQC7LejcNh8T0lNkLdeSGdTed/QLUM3d5Grl7P4d9xtUf8whaOxOGxO5NFfAsTmJ/SAtPezm6A+t6OP1H2jbYayQodiGKeylEyCijwL4FDP/VDJYPgDgV4N7F4bs0+O5cveOgdh3lVMGpenZP4u2qMLtF2cbsNQ4PxfHIYUCrtYKV5cKV1eERit7VLiLz77gUcgpdwbcQIcY3MR07CrKuqWk+83xib28/mA+8chvCuYGcHqagHu+nd51B7Ts3p1zTB1QPq85T4E9iAARnQP4ExBRYG9Iw5Cl27zZ+RE8625ft73inosHGoYCoyDGctng4cMGjx4bPHrE4Bq4fk54/lRhfaVgfIjxpDD3bK9V2SPTrcwJsK5jivH8MZ5U/JoP6Rya1hQ3pYAYmFChIxQ/sPbDIE/YgveprUJgpBbp/LsXw27dRmAfO4EvBvBhAD9FRL8MCTX2E0T0+ZgZhoyZv5yZv1ypaZr4bh7tb4fNshkoYhSlxmLZ4MFDjfd/QOMLPqjx2usG2gBX1wqXVwV2dQnmEr1NcgIT9g5ODN4l6qLZRICZf4aZP4+ZP8TMH4Kw/F/GzG9AwpD9XrtL8JUAnjLzBFGgB4a2TAQbWemVmAITtWcI2mPCBouFwdm5Mw9mPHjIOFsxtCE0jfz5Q0JZkbFfjpwgnt2YFHocteURR/JRshpu6/nteMzWl7z6/st+cZBaJ9Vj9NdlTD8y5GhkyhbhXwPw/wH4dUT0SSL65oHkfxfALwH4BIC/AuA/Gcu/WyACRVEMfU1AJD4BlN8tkNQERlFoLJYaF/cMHj4yuPdAgotIqHFC04gnYccSDvaX0z+GOrspWppDB2FPGXHO88hNqnS6aQiVWuFu3wvSfQYwvNPg2XKKY0521FLd2/hdxK4HhMNv53V1YlFvhuMu8z5s37nV3DcMWfj+Q8E1A/jWsTynQIcAdExDA7nUihNk4O0CGASQRrUAzi8YDx9pvPo+xurMwDDh+XOFt94irNcKRqub37u9g4nQL593Uo7oM24K5hR5fByPP05Px2JwYPWPyGH0a5WAlkQaZhCHyj0RB6qFwcrGEmgawvpK4Y03CO+8o7DZEJooipXzVJPlOQ6v5w1AF9WMMusFAEfKzzl4BP2KHu7P/drdoLgNOJOyp6Q+vW0uu2xW4/Xaqwuy+Ozfl0Mc3+kQAT8LOX7mLrN1sIPE2IMlAJRjsbiVkRQBBQnDtF0Tnj0lvPNWgetrhbpR7dnu6YtQL3iPtBbpWPt7AIye5psIx1yaeGS6DfRZF3J1G9g7OFo1WvKfLT4sJOcfIbd7MAjp/kpU2IQvjw8nQgScgJg8mqB2Ezfg8CbB0k/OGEUUhcpeswaurghP31F4+60C600BbcRpiKKWEHQHF0WXoflBNAlGBsG+BGFwIZoIrfXDMWZOOvW5fdyvmRqs9OAiO0Q3co0znRGwR07yCw8oLZqnZBllEOUdOC/J9UPnfEC6vTykKO+Yzncx6YMTIQJAL0X2q7pd9QPi0CoAJZGs+u4DuS+U7B6QArY7wltvlXjzzQJPnxTQTQFG2vB38FLBEbi39zqcEBFwEFM0Cv3HEYFg4NxWiTiowDCRcYUzS1VKdgEUEVgTrp4rvPUm8M47hPVGya6AosziNTCqeOBtSsfG2MM5/OyBvGAn5uExwHFFk/PMJYzl/tSNWL7chKVOkZjZVh0GNHszJZ9wSenbbRoeWy6fFPbV7Xgm4pDdgduBcMfbNZ4bHEIERL4XXt03dTQK2vTK6gEUtSKwbgiXzwnPn0tEobqhoNyWxx9aWPq6NZeuD6aPq2A45SZwVEiGTU2RGCM4s2SVJHPKt1rOPeFNavPDAd/RJY/S40MUwRMp7EjlB8dWsMDkq9RPfsZqcSJEwE3WdDCx/5OpasDW7327FrD9n9rnLOKA7BwyjAa2G8K2LnB5Cay3BG3j2bnjwgk2EV4RDPXjHGLd49zippQ/U2Eed02BnjH3ZYYK7MmKjK2Esxx3dj6e+qKLf4zXrAEQf9M9hDFMNDr6qPiFv51gDngyRGDYfr3V9LOliN5Qx2nj/XO2jwmFAhQVqHfAc024vC5wfU2o6wJA1UMA7uAO3ltwIkSAk98WHAFIn7lV069CgVyorClxWYpoYIzI/5uNgtYK4MLlnNVH3ihhGKHug4tJzzvKygszgaOfbHEdNjSRygZLn4LaEdv9hlQgg/mFXZsu5P349OSYjBPvMn/om7SwiXAiRABwUgzZaw+WCsQ7AYECMM7CPUZhiQCRsP5NQ6h9IBEaogHDMCA7y6nFQ0ZyL483E44zm/qGWitvH1fA70pl+7DX2ZxGvkyVk13YX1CL8z4EOnqO8F1SfUrTDhxbPxEi4Nx+hQcxnD4gp/BK5TC3ZSgyQ1EAZamwqAwMK9Q7xmbD2NUKDAUoBRVQVd6zi1trteNNhv2H8guCoyLcp+q6QchwQL7sDBGibH9bDdWQfwhL36fRtVhMPcr4GsjiRIhANJXRXWKTazaSjtJlmVEQUBUGVWGgCNhsGdutxBRsGhIikM34Du6g3S+annoa7LMrdFtwMkQAAFqzTBdDKHiFlFBQ9M4/JTEMIgUYBupGoW4koEirKs3tQkxr/BzPMFUEmEdyhlfFfF63OIC85JJuRfUpLtxPss+Vvg9dsPWdnjzGwphkEnOb0d5TkMZGtroBpVFkW5jTgSUPvDK8J68WxhvrZIhAJI9ZpYqPepuOm7ATKP6YFIMKIQTaAI1W0AYw3HIBHV4jFMWH+jfQOewFswZvTJgOGvcUVyuVH2dlzv272Z3jDUOigi03G/lnOjLdR3mBfjIM4tDbVj0kOVAO9lpTTxlMGYOLjlQ8htNAOSdDBNJKkTVAkW08J7hRYAjS5QsKxVgsGFUJqIKgGxtOjC1rcBLc/9xZ9y6GlvE7PJ/8jUBuBwg9vRDueIRHDPek/F2edijtcZpjLpwIEWgVgm0DtPsEBDHqaW2JrHIm7Bt7VqCsAFUKa7XbSXBRbejW5l2f0ig/UPuRyo05P5j86jJlFem2aZvB8Kdtn+zHkcR9OiwmdHOfwJJ1bslykdPyGeoFBmwcRpdwwvQMDvpMjcjsg5GEOI0s804Ma/FvWQ5Kvh1sewsnQgRyaLYNGBkGORaSQ7bW7iSQ2AXAEAzLtqAJCAABYHL+AmKRgsKs8gjZDALZgdw59qHObjNM52xs5cadDuzkk479vmOs0SVF9XOGVHHOPfhn2iJc2QZDeyXZ9NVq6qqXN6BLp3G3jXpLj9Xv/dhMoCed+t/agjNUYNg2wwTspIiAVzS5iWUnhbMCRNJv7Ci1H5TiU8hoEn1AI8SAgUwbcHSZHTv2Oy+NBLh28hgDWVp6X4+bxc4oyrZfSwCGnG7ET0JikZWQhZJmC+3UgcgfcQ1dm8fJcsqCFLMWf59PYCMy5VhEtGom9Q+Vcox4+kSYpE5OJngi6fCFqUVRtqxh7ch0AQN5RjSB0yACnGlghKxM6+3HdZj3TWdCVopgDEMbtg5EgRMOvHxcYCM/CMammqNqC9o/po9gE7CtBBBJm3pC7MWUlkNgMyBy9C3O2Sfs63b70vILgAOrmFdfvATiAAMwWsuqRSp4Tu1Cz+0wDQeqc/9IYIA12DCMVmgaiChAdsRRUuAc5PoeZYXJPKXPwbhIP4QoQSmgLBdYLCqoohDNigG2mw12u21nRHSCYSpCVS2gVAEQoJvaM2DGGKyWCxAp6R+jwQwopVCWJUJHpcYwytIRBsl8u90CBBS+MOP7arfV0Ox7Mq6l5SiKokBZliirBcASjrxpGqw3m3Zld1t5Y2JJpBLKpJk18XJsY/Q2yDYjwoXvczN2mHPfA4JFtAdOgggQAFKuQ+VZzHI5ttZeWzFA2fRkJ4RYDAZSkB3AOb4xz/7aNxQzZGHaQQYwUfIkbxMZrsv2tu7SY0LTLdMFSiU8fPAAj155jLOzM4AYumF85jNv4K033/R18JPDiiROL0AAzs7PsTo7Q1UV2G13gDFCSI3Ba688RlFV/gi3NoxCFVgsKzSN9gRA6war5dJyIQxmwptvfg7MDFUogCXuI9hA6xpvv/Mc3BgrqnXtNYkIq9UK9+7dx+NXXwGYsd1ucXl5ifpznwMbgxx0IkQHY2lsXsU6oVAWzLd9u1XaFRLnQZ73HU7nJeW8RBIpKGPuLQcnQQRAhLIsZFCxPTZMsRwrHoPsoLasJll2VxGJA5ESlhgYqbhSHfltbCIP42mJQ+dwR7c+WYiIUMs6d3KKDke1z/1ksXgQEV7/vPfhi77kS/Dqq6+CCsJu2+Cnfuqn8PTJUztxDay81eYZyIkP79/H49dexb1759isN9B1A9NogBlf/MVfjLPzM6iiQKEKNE2DoihwtjrDeruxopeB0TUuzu/Jis0Gxij8/D/5OGqbHqxRFQzT1Nhs1nh+uYbhGqw5GKRuuZZ6Xdy7hy/4wBfgI7/2IyAAz549xxuffgPPnj1DXddCCILBbquINHRaO0Upave2q+xKOcx0xe1v+wjGdBYIyn3oP+lO+L7RSGESdCe7E4vdmZrwfbSAMINIoSj6pzrdlt/5ISCizwG4AvDmi8YFwGu4wyOEOzxieJnx+DXM/L704UkQAQAgoh9j5i+/w+MOjzs8bheP94jq/A7u4A764I4I3MEdvMfhlIjAd71oBCzc4RHDHR4xvOvwOBmdwB3cwR28GDglTuAO7uAOXgC8cCJARF9NRL9ARJ8gom+7xXK/kIh+mIg+TkQ/R0R/yD7/U0T0KSL6Sfv3tbeAyy8T0c/Y8n7MPnuFiH6QiH7R/j6+YRx+XVDnnySiZ0T0h2+jPYjoe4jos0T0s8GzbP1J4C/a8fLTRPRlN4zHnyWif2LL+ttE9Mg+/xARrYN2+cs3jEdvPxDRt9v2+AUi+u2zCwzNP2/7D0AB4J8B+CIACwA/BeBLb6ns9wP4Mnt9H8A/BfClAP4UgP/iltvhlwG8ljz7rwB8m73+NgDfecv98gaAX3Mb7QHgtwD4MgA/O1Z/AF8L4H+HmNJ8JYAfvWE8/l0Apb3+zgCPD4XpbqE9sv1gx+xPAVgC+LCdT8Wc8l40J/AVAD7BzL/EzDsA3w/go7dRMDN/mpl/wl4/B/DzAD5wG2VPhI8C+F57/b0Afsctlv1VAP4ZM//KbRTGzP8AwNvJ4776fxTAX2WBHwHwiIjef1N4MPPfY+bG3v4IgA8eo6y5eAzARwF8PzNvmfmfA/gEZF5NhhdNBD4A4FeD+0/iBUxEIvoQgN8I4Eftoz9o2b/vuWk23AID+HtE9ONE9C322evM/Gl7/QaA128BDwffCOCvBfe33R5Af/1f5Jj5AxAuxMGHiegfE9H/Q0T/1i2Un+uHg9vjRROBFw5EdA/A3wLwh5n5GYC/BOCLAfwbAD4N4L+5BTR+MzN/GYCvAfCtRPRbwpcsfN+tbOMQ0QLA1wP4X+2jF9EeEdxm/fuAiL4DQAPg++yjTwP4V5j5NwL4IwD+FyJ6cIMo3Fg/vGgi8CkAXxjcf9A+uxUgogpCAL6PmX8AAJj5M8ysmdkA+CuYyVrtA8z8Kfv7WQB/25b5Gcfm2t/P3jQeFr4GwE8w82csTrfeHhb66n/rY4aIfh+ArwPwuy1BgmW/37LXPw6RxX/tTeEw0A8Ht8eLJgL/CMBHiOjDdgX6RgAfu42CSY6PfTeAn2fmPxc8D+XL/wDAz6bfHhmPCyK6764hiqifhbTDN9lk3wTg79wkHgH8LgSiwG23RwB99f8YgN9rdwm+EsDTQGw4OhDRVwP4YwC+npmvg+fvI6LCXn8RgI8A+KUbxKOvHz4G4BuJaElEH7Z4/MNZmd+EdnOmJvRrIZr5fwbgO26x3N8MYTF/GsBP2r+vBfA/A/gZ+/xjAN5/w3h8EUS7+1MAfs61AYBXAfwQgF8E8H8BeOUW2uQCwFsAHgbPbrw9IETn0wBqiEz7zX31h+wK/Hd2vPwMgC+/YTw+AZG53Rj5yzbtf2j76ycB/ASAf/+G8ejtBwDfYdvjFwB8zdzy7iwG7+AO3uPwosWBO7iDO3jBcEcE7uAO3uNwRwTu4A7e43BHBO7gDt7jcEcE7uAO3uNwRwTu4A7e43BHBO7gDt7jcEcE7uAO3uPw/wOpNM0Xz2meDgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def plot_latent_space(trained_decoder, pimage, n=50, figsize=15):\n",
    "\n",
    "\n",
    "    image = pimage[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "    image = cv2.resize(image, \n",
    "                        (config['input_image_width'],\n",
    "                        config['input_image_height']))\n",
    "    image = np.array(image).astype(\"float32\")/255.0\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # vel = np.array()\n",
    "\n",
    "\n",
    "    X_tvel = np.array([14.5])\n",
    "    X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "    X_tstr = np.array([0.3])\n",
    "    X_tvel = np.expand_dims(X_tstr, axis=0)\n",
    "    X_ttime = np.array([0.1])\n",
    "    X_tvel = np.expand_dims(X_ttime, axis=0)\n",
    "    # print(X_tvel.shape)\n",
    "    X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "    x_encoded = VarAE.predict(X_train)*255.0\n",
    "    # print(x_encoded)\n",
    "    x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "    # pred_image = np.zeros([160,160,3], np.uint8)\n",
    "    pred_image = array_to_img(x_encoded_out)\n",
    "    pred_image = np.array(pred_image)\n",
    "    pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "    # pred_img = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "    # print(type(pred_img))\n",
    "    # print(pred_image.shape)\n",
    "    plt.imshow(pred_image)\n",
    "    # plt.imshow(cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    origin_image_name = '/home2/kdh/vae/vae_test/'+\n",
    "    cv2.imwrite('/')\n",
    "    # plt.xticks(pixel_range, sample_range_x)\n",
    "    # plt.yticks(pixel_range, sample_range_y)\n",
    "    # plt.xlabel(\"z[0]\")\n",
    "    # plt.ylabel(\"z[1]\")\n",
    "\n",
    "# test_img = cv2.imread('/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-30-12-332957.jpg')\n",
    "# plot_latent_space(decoder, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def save_latent_space(trained_decoder, valid_data, n=50, figsize=15):\n",
    "        \n",
    "    for image_name, velocity, measurement, tar_image_name, tar_steering_angle, tar_vel, tar_time in valid_data:\n",
    "        # self.data.image_names, self.data.velocities, self.data.measurements, \n",
    "        # self.data.tar_image_names, self.data.tar_steering_angle, self.data.tar_vel, self.data.tar_time\n",
    "        \n",
    "        image_path = data_path + '/' + image_name\n",
    "        # print(data_path, tar_image_name)\n",
    "        tar_image_path = data_path + '/' + tar_image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "\n",
    "        # if collected data is not cropped then crop here\n",
    "        # otherwise do not crop.\n",
    "        image = image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                    Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        image = cv2.resize(image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        tar_image = tar_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                    Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        tar_image = cv2.resize(tar_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "\n",
    "        cv2.imwrite('/home2/kdh/vae/vae_test/'+image_name, image)\n",
    "        image = np.array(image).astype(\"float32\")/255.0\n",
    "        # image = image_process.process(image)\n",
    "        steering_angle, throttle, brake = measurement\n",
    "        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        X_tvel = np.array([velocity])\n",
    "        X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "        X_tstr = np.array([steering_angle])\n",
    "        X_tstr = np.expand_dims(X_tstr, axis=0)\n",
    "        X_ttime = np.array([tar_time])\n",
    "        X_ttime = np.expand_dims(X_ttime, axis=0)\n",
    "        \n",
    "        X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "        x_encoded = VarAE.predict(X_train)*255.0\n",
    "        x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "        pred_image = array_to_img(x_encoded_out)\n",
    "        pred_image = np.array(pred_image)\n",
    "        # pred_image = cv2.cvtColor(pred_image)\n",
    "        # plt.imshow(pred_image)\n",
    "        # plt.show()\n",
    "\n",
    "        # image_name = '/home2/kdh/vae/vae_test/'+image_name\n",
    "        pred_image_name = '/home2/kdh/vae/vae_test/'+image_name[:-4]+'_'+str(int(steering_angle*1000))+'_'+str(int(velocity))+'_'+str(tar_time)[:4]+'.jpg'\n",
    "        gt_tar_image_name = '/home2/kdh/vae/vae_test/'+image_name[:-4]+'_'+str(int(steering_angle*1000))+'_'+str(int(velocity))+'_'+str(tar_time)[:4]+'_gt.jpg'\n",
    "        cv2.imwrite(pred_image_name, pred_image)\n",
    "        cv2.imwrite(gt_tar_image_name, tar_image)\n",
    "\n",
    "        # print(pred_image_name,' done')\n",
    "        # cv2.imwrite('/')\n",
    "\n",
    "\n",
    "# save_latent_space(decoder, valid_data[3423:4422])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "def save_latent_space_diff_steer(trained_decoder, pimage, save_image_name, n=50, figsize=15):\n",
    "\n",
    "\n",
    "    image = pimage[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "    image = cv2.resize(image, \n",
    "                        (config['input_image_width'],\n",
    "                        config['input_image_height']))\n",
    "    cv2.imwrite('/home2/kdh/vae/vae_diff_steer_test/'+save_image_name+'.jpg', image)\n",
    "    image = np.array(image).astype(\"float32\")/255.0\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.show()\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # vel = np.array()\n",
    "\n",
    "\n",
    "    X_tvel = np.array([14.85])\n",
    "    X_tvel = np.expand_dims(X_tvel, axis=0)\n",
    "    X_ttime = np.array([0.8])\n",
    "    X_ttime = np.expand_dims(X_ttime, axis=0)\n",
    "    # print(X_tvel.shape)\n",
    "    for s in np.arange(0, 0.8, 0.0125):\n",
    "        X_tstr = np.array([s-0.4])\n",
    "        X_tstr = np.expand_dims(X_tstr, axis=0)\n",
    "        X_train = [image, X_tstr, X_tvel, X_ttime]\n",
    "\n",
    "        x_encoded = VarAE.predict(X_train)*255.0\n",
    "        x_encoded_out = np.squeeze(x_encoded,axis=0)\n",
    "        pred_image = array_to_img(x_encoded_out)\n",
    "        pred_image = np.array(pred_image)\n",
    "        # pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2RGB)\n",
    "        s_str = \"{:.3f}\".format(s)\n",
    "        pred_image_name = ('/home2/kdh/vae/vae_diff_steer_test/'\n",
    "                            +save_image_name\n",
    "                            +'_'+str(s_str)\n",
    "                            +'.jpg'\n",
    "        )\n",
    "        cv2.imwrite(pred_image_name, pred_image)\n",
    "    \n",
    "        \n",
    "\n",
    "# test_img = cv2.imread('/home2/kdh/vae/2022-12-08-14-25-28/2022-12-08-14-35-43-708754.jpg')\n",
    "# save_latent_space_diff_steer(decoder, test_img, '2022-12-08-14-35-43-708754')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06e874fbf5df5387c03d37e60b157d9aec9842d39ece54c5a1a7aaa8e8f1e8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
