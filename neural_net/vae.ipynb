{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Activation, LeakyReLU, Dropout, BatchNormalization, MaxPooling2D, Lambda\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from progressbar import ProgressBar\n",
    "from image_process import ImageProcess\n",
    "import const, cv2\n",
    "from drive_data import DriveData\n",
    "from config import Config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.setrecursionlimit(10**7)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Dataset\n",
    "\"\"\"\n",
    "image_process = ImageProcess()\n",
    "config = Config.neural_net\n",
    "# data_path = \"/mnt/exData/internal_simulation/test/2022-03-08-17-18-14/\"\n",
    "data_path = \"/mnt/exData/internal_simulation/2022-12-08-14-25-28/\"\n",
    "if data_path[-1] == '/':\n",
    "    data_path = data_path[:-1]\n",
    "\n",
    "    loc_slash = data_path.rfind('/')\n",
    "    if loc_slash != -1: # there is '/' in the data path\n",
    "        model_name = data_path[loc_slash + 1:] # get folder name\n",
    "        #model_name = model_name.strip('/')\n",
    "    else:\n",
    "        model_name = data_path\n",
    "csv_path = data_path + '/' + model_name + const.DATA_EXT \n",
    "# data = DriveData(csv_path)\n",
    "print(csv_path)\n",
    "# data_path = data_path\n",
    "# data.read()\n",
    "\n",
    "csv_header = ['image_fname', \n",
    "                  'steering_angle', 'throttle', 'brake', 'linux_time', \n",
    "                  'vel', 'vel_x', 'vel_y', 'vel_z', \n",
    "                  'pos_x', 'pos_y', 'pos_z', \n",
    "                  'tar_image_fname', 'tar_steering_angle', 'tar_vel', 'tar_time']\n",
    "\n",
    "df = pd.read_csv(csv_path, names=csv_header, index_col=False)\n",
    "num_data = len(df)\n",
    "\n",
    "bar = ProgressBar()\n",
    "df_image_names = []\n",
    "df_measurements = []\n",
    "df_time_stamps= []\n",
    "df_velocities= []\n",
    "df_velocities_xyz= []\n",
    "df_positions_xyz= []\n",
    "df_tar_image_names= []\n",
    "df_tar_steering_angle= []\n",
    "df_tar_vel= []\n",
    "df_tar_time= []\n",
    "for i in bar(range(num_data)): # we don't have a title\n",
    "    df_image_names.append(df.loc[i]['image_fname'])\n",
    "    # if Config.data_collection['brake'] is True:\n",
    "    df_measurements.append((float(df.loc[i]['steering_angle']),\n",
    "                            float(df.loc[i]['throttle']), \n",
    "                            float(df.loc[i]['brake'])))\n",
    "    df_time_stamps.append(float(df.loc[i]['linux_time']))\n",
    "    df_velocities.append(float(df.loc[i]['vel']))\n",
    "    df_velocities_xyz.append((float(df.loc[i]['vel_x']), \n",
    "                                float(df.loc[i]['vel_y']), \n",
    "                                float(df.loc[i]['vel_z'])))\n",
    "    df_positions_xyz.append((float(df.loc[i]['pos_x']), \n",
    "                                float(df.loc[i]['pos_y']), \n",
    "                                float(df.loc[i]['pos_z'])))\n",
    "    df_tar_image_names.append(df.loc[i]['tar_image_fname'])\n",
    "    df_tar_steering_angle.append(float(df.loc[i]['tar_steering_angle']))\n",
    "    df_tar_vel.append(float(df.loc[i]['tar_vel']))\n",
    "    df_tar_time.append(float(df.loc[i]['tar_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(zip( df_image_names, df_velocities, df_measurements, \n",
    "                    df_tar_image_names, df_tar_steering_angle, df_tar_vel, df_tar_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vae_batch_samples(batch_samples):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    vels = []\n",
    "    tar_images = []\n",
    "    tar_steering_angles = []\n",
    "    tar_vels = []\n",
    "    tar_times = []\n",
    "        \n",
    "    for image_name, velocity, measurement, tar_image_name, tar_steering_angle, tar_vel, tar_time in batch_samples:\n",
    "        # self.data.image_names, self.data.velocities, self.data.measurements, \n",
    "        # self.data.tar_image_names, self.data.tar_steering_angle, self.data.tar_vel, self.data.tar_time\n",
    "        \n",
    "        image_path = data_path + '/' + image_name\n",
    "        # print(data_path, tar_image_name)\n",
    "        tar_image_path = data_path + '/' + tar_image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        tar_image = cv2.imread(tar_image_path)\n",
    "\n",
    "        # if collected data is not cropped then crop here\n",
    "        # otherwise do not crop.\n",
    "        if Config.data_collection['crop'] is not True:\n",
    "            image = image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "            tar_image = tar_image[Config.data_collection['image_crop_y1']:Config.data_collection['image_crop_y2'],\n",
    "                        Config.data_collection['image_crop_x1']:Config.data_collection['image_crop_x2']]\n",
    "        image = cv2.resize(image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        tar_image = cv2.resize(tar_image, \n",
    "                            (config['input_image_width'],\n",
    "                            config['input_image_height']))\n",
    "        image = image_process.process(image)\n",
    "        tar_image = image_process.process(tar_image)\n",
    "\n",
    "        vels.append(tar_vels)\n",
    "        tar_vels.append(tar_vel)\n",
    "        tar_times.append(tar_time)\n",
    "        tar_steering_angles.append(tar_steering_angle)\n",
    "        # if no brake data in collected data, brake values are dummy\n",
    "        steering_angle, throttle, brake = measurement\n",
    "        steering_angles.append(steering_angle)\n",
    "        # cv2.imwrite('/home/kdh/oscar/oscar/e2e_fusion_data/test/aug/'+image_name, image)\n",
    "        # if data == 'train':\n",
    "        #     cv2.imwrite('/mnt/Data/oscar/train_data/'+image_name, image)\n",
    "        # print(image.shape)\n",
    "        images.append(image)\n",
    "        tar_images.append(tar_image)\n",
    "        # segimgs.append(segimg)\n",
    "\n",
    "\n",
    "    return images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Encoder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "encoder_inputs_img = tf.keras.Input(shape=(160, 160, 3))\n",
    "encoder_inputs_str = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_vel = tf.keras.Input(shape=(1))\n",
    "encoder_inputs_time = tf.keras.Input(shape=(1))\n",
    "x = layers.Conv2D(24, (5, 5), padding='same', name='conv2d_1')(encoder_inputs_img)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_1')(x)\n",
    "\n",
    "x = layers.Conv2D(36, (5, 5), padding='same', name='conv2d_2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), name='pool2d_2')(x)\n",
    "\n",
    "x = layers.Conv2D(48, (5, 5), padding='same', name='conv2d_3')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), padding='same', name='conv2d_5')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('elu')(x)\n",
    "\n",
    "latent = layers.Flatten()(x)\n",
    "fc_s1  = layers.Dense(100)(encoder_inputs_str)\n",
    "fc_s1  = layers.Activation('elu')(fc_s1)\n",
    "fc_s2  = layers.Dense(50)(fc_s1)\n",
    "fc_s2  = layers.Activation('elu')(fc_s2)\n",
    "fc_v1  = layers.Dense(100)(encoder_inputs_vel)\n",
    "fc_v1  = layers.Activation('elu')(fc_v1)\n",
    "fc_v2  = layers.Dense(50)(fc_v1)\n",
    "fc_v2  = layers.Activation('elu')(fc_v2)\n",
    "fc_t1  = layers.Dense(100)(encoder_inputs_time)\n",
    "fc_t1  = layers.Activation('elu')(fc_t1)\n",
    "fc_t2  = layers.Dense(50)(fc_t1)\n",
    "fc_t2  = layers.Activation('elu')(fc_t2)\n",
    "conc_1 = layers.concatenate([latent, fc_s2, fc_v2, fc_t2])\n",
    "fc_1   = layers.Dense(100)(conc_1)\n",
    "x   = layers.Activation('elu')(fc_1)\n",
    "\n",
    "z_mean = layers.Dense(50, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(50, name=\"z_log_var\")(x)\n",
    "encoder_output = Sampling()([z_mean, z_log_var])\n",
    "encoder = tf.keras.Model([ encoder_inputs_img, encoder_inputs_str,\n",
    "                        encoder_inputs_vel, encoder_inputs_time], \n",
    "                        [z_mean, z_log_var, encoder_output], \n",
    "                        name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Decoder\n",
    "\"\"\"\n",
    "\n",
    "latent_inputs = tf.keras.Input(shape=(50,))\n",
    "x = layers.Dense(40 * 40 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((40, 40, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## VAE\n",
    "\"\"\"\n",
    "model_input = [ encoder_inputs_img, encoder_inputs_str,\n",
    "                        encoder_inputs_vel, encoder_inputs_time]\n",
    "model_output = decoder(encoder_output)\n",
    "\n",
    "VarAE=Model(model_input, model_output)\n",
    "# VarAE.run_eagerly = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VAE loss\n",
    "\"\"\"\n",
    "optimizer=tf.keras.optimizers.Adam(lr=0.0005)\n",
    "r_loss_factor=1000   # This is a Hyperparameter\n",
    "\n",
    "def vae_r_loss(y_true, y_pred):    ## MSE\n",
    "    r_loss = tf.keras.backend.mean(tf.keras.backend.square(y_true-y_pred), axis=[1,2,3])\n",
    "    return r_loss_factor * r_loss\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):   ## KL-Divergence\n",
    "    kl_loss=( -0.5 * tf.keras.backend.sum(1+z_log_var \n",
    "                - tf.keras.backend.square(z_mean) \n",
    "                - tf.keras.backend.exp(z_log_var), axis=1)\n",
    "    )\n",
    "    return kl_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred): \n",
    "    r_loss=vae_r_loss(y_true, y_pred) #Loss of Decoder\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred) #Loss of Encoder\n",
    "    return r_loss + kl_loss #Sum of these two\n",
    "\n",
    "\n",
    "VarAE.compile(optimizer=optimizer,\n",
    "                loss= vae_loss, \n",
    "                metrics=[vae_r_loss, vae_kl_loss])\n",
    "VarAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data generator\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _generator(samples, batch_size=config['batch_size']):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, (num_samples//batch_size)*batch_size, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images, vels, steering_angles, tar_images, tar_steering_angles, tar_vels, tar_times = prepare_vae_batch_samples(batch_samples)\n",
    "\n",
    "            X_img = np.array(images).astype(\"float64\")/255.0\n",
    "            X_tvel = np.array(tar_vels)\n",
    "            X_tstr = np.array(tar_steering_angles)\n",
    "            X_ttime = np.array(tar_times)\n",
    "\n",
    "            y_train = np.array(tar_images).astype(\"float64\")/255.0\n",
    "            # if config['num_outputs'] == 1:\n",
    "            # y_train = np.array(segimg)\n",
    "            # print(y_train.max())\n",
    "            # y_train = np.repeat(y_train[..., np.newaxis], 1, -1)/y_train.max()\n",
    "            X_train = [X_img, X_tstr, X_tvel, X_ttime]\n",
    "            # print(X_train_vel.shape)\n",
    "            # print(y_train.shape)\n",
    "            yield X_train, y_train\n",
    "\n",
    "train_data, valid_data = train_test_split(samples, test_size=config['validation_rate'])\n",
    "\n",
    "train_generator = _generator(train_data)\n",
    "valid_generator = _generator(valid_data)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Train the VAE\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "        # checkpoint\n",
    "callbacks = []\n",
    "#weight_filename = self.data_path + '_' + Config.config_yaml_name \\\n",
    "#    + '_N' + str(config['network_type']) + '_ckpt'\n",
    "model_ckpt_name = \"vae_kdh\"\n",
    "checkpoint = ModelCheckpoint(model_ckpt_name +'_ckpt.{epoch:02d}-{val_loss:.3f}.h5',\n",
    "                                monitor='val_loss', \n",
    "                                verbose=1, save_best_only=True, mode='min')\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "# early stopping\n",
    "patience = config['early_stopping_patience']\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, \n",
    "                            verbose=1, mode='min')\n",
    "callbacks.append(earlystop)\n",
    "\n",
    "# validation_steps = len(valid_data)//config['batch_size']\n",
    "# print(config['batch_size'])\n",
    "train_hist = VarAE.fit( train_generator,  \n",
    "                        steps_per_epoch=len(train_data)//config['batch_size'], \n",
    "                        epochs=config['num_epochs'], \n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=len(valid_data)//config['batch_size'],\n",
    "                        shuffle=True,\n",
    "                        verbose=1, \n",
    "                        callbacks=callbacks, \n",
    "                        use_multiprocessing=True,\n",
    "                        workers=48\n",
    "                        )\n",
    "\n",
    "\n",
    "# train_hist = VarAE.fit( train_generator,  \n",
    "#                         batch_size=config['batch_size'],\n",
    "#                         steps_per_epoch=len(train_data)//config['batch_size'], \n",
    "#                         epochs=config['num_epochs'], \n",
    "#                         validation_data=valid_generator,\n",
    "#                         validation_steps=len(valid_data)//config['batch_size'],\n",
    "#                         shuffle=True,\n",
    "#                         verbose=1, \n",
    "#                         callbacks=callbacks, \n",
    "#                         use_multiprocessing=True,\n",
    "#                         workers=48\n",
    "#                         )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d844cf9ecc22d3eee525a168aa14c6cacdc8fca2c81f71564faaa29de48fa0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
